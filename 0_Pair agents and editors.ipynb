{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Conference Set-Up\n",
    "*Becky Hodge*\n",
    "\n",
    "#### Summary\n",
    "Every May and November, the Atlanta Writer's Club holds a Writing Conference at the Westin hotel by the Atlanta airport. There are 16-18 agents and editors who offer query letter critiques, manuscript critiques, and hold pitch sessions, two or more speakers who hold workshops throughout the two days on various writing topics, author coaching, and then several other paid events, like the Friday night social, or the morning Q&A panels with editors and agents.\n",
    "\n",
    "**This code can be run as soon as all the editors and agents are confirmed and announced on the Atlanta Writers Conference website when it opens for registration for the next conference.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Steps to set up for the latest conference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, is it time already for the next conference? Didn't we just finish the last one??\n",
    "\n",
    "Yeps, it's time! And there's a few things to do to finish out the old one and set up for the new one..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Close out the prior conference\n",
    "\n",
    "To close out the old conference, rename the *Outputs* folder to the conference we just left behind (e.g., *May_2025*). \n",
    "    \n",
    "Also, go ahead and duplicate the *Email scheduling dates.xlsx*, *List_of_genres_agents_editors.xlsx*, and *People to hardcode.xlsx* excel files and copy them into that folder - you'll want to make copies because we'll go ahead and reuse those (with any requisite updates) for the next conference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update the Excel files\n",
    "\n",
    "There's a couple different excel files that will need updating:\n",
    "\n",
    "1. *Email scheduling dates.xlsx* --> ou can update this in communication with George. The number of days that each of the tasks should be done prior to the conference should be largely the same.\n",
    "\n",
    "2. *People to hardcode.xlsx* --> you can just wipe the data in it in preparation for the requests we'll undoubtedly get in the coming months prior to the conference.\n",
    "\n",
    "3. *List_of_genres_agents_editors.xlsx* --> This one's got the biggeer changes needed now for the rest of the code to work.\n",
    "\n",
    "    * *fiction* and *nonfiction* --> You can keep these as they are. These shouldn't need to change unless we change these listings on the conference registration form\n",
    "\n",
    "    * *rooms_fri*, *rooms_sat*, and *timeslots* --> These shouldn't need any updates (and were designed to be that way). **The only exception is if we have fewer or more than 18 editors/agents**. In that case, you'll need to update the *rooms_fri* and *rooms_sat* sheets to drop or add rooms.\n",
    "\n",
    "    * *Agents_and_editors* --> Update everything in here. Make sure you type the genres exactly as they're found in the 'fiction' and 'nonfiction' sheets, separated by commas. Also, you may want to download the Cvent report to get every agent and editor's names, so they're spelled exactly as they're output - like with any accents, etc.\n",
    "\n",
    "    * *Coaches* --> Change the name of the coaches. But you can keep everything else the same.\n",
    "\n",
    "    * *minis_fri* and *minis_sat* --> You should only need to update the designation, speaker and topic columns.\n",
    "    \n",
    "    * *timekeepers* --> You can't update this one yet... But that's because we have to run the code below first, so we can get the final pairings of the agents and editors, as well as their room assignments on both days. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update the templates\n",
    "\n",
    "First, copy everything in the templates folder and add it to the prior conference folder (it's part of closing out the prior one). \n",
    "\n",
    "Then update each of the templates to fix the dates. That should be the only thing you need to change - but make sure to fix it everywhere it's applicable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and clean the different files/reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Install any needed packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os \n",
    "\n",
    "today = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Set the conference dates\n",
    "date_str_fri = '2025-05-02'\n",
    "date_str_sat = '2025-05-03'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Before continuing, you need to create a new folder for this latest conference! Go ahead and reference the name below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "current_conference_folder= \"May2025\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Select the file with the most recent date\n",
    "directory = f'{current_conference_folder}/Cvent_report_downloads'\n",
    "\n",
    "most_recent_file = max(\n",
    "    (f for f in os.listdir(directory) if f.startswith('Registered_') and f.endswith('.csv')),\n",
    "    key=lambda x: datetime.datetime.strptime(x.split('_')[1].split('.')[0], '%m-%d-%y'),\n",
    ")\n",
    "\n",
    "# Load the most recent file\n",
    "most_recent_path = os.path.join(directory, most_recent_file)\n",
    "registered = pd.read_csv(most_recent_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "most_recent_file = max(\n",
    "    (f for f in os.listdir(directory) if f.startswith('Waitlists_') and f.endswith('.csv')),\n",
    "    key=lambda x: datetime.datetime.strptime(x.split('_')[1].split('.')[0], '%m-%d-%y'),\n",
    ")\n",
    "\n",
    "# Load the most recent file\n",
    "most_recent_path = os.path.join(directory, most_recent_file)\n",
    "waitlist = pd.read_csv(most_recent_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code brings in ALL participants, which is key for knowing whether any waitlist only people are virtual or in person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "most_recent_file = max(\n",
    "    (f for f in os.listdir(directory) if f.startswith('Allparticipants_') and f.endswith('.csv')),\n",
    "    key=lambda x: datetime.datetime.strptime(x.split('_')[1].split('.')[0], '%m-%d-%y'),\n",
    ")\n",
    "\n",
    "# Load the most recent file\n",
    "most_recent_path = os.path.join(directory, most_recent_file)\n",
    "all_participants = pd.read_csv(most_recent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "all_participants = all_participants.rename(columns={'Email Address':'Email'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Filter this dataset to just virtual people\n",
    "virtual_only = all_participants.loc[all_participants['Hotel vs. Zoom'] == 'Virtually via Zoom (only available for query letter critiques, manuscript sample critiques, and pitches)', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "del(directory, most_recent_file, most_recent_path)\n",
    "\n",
    "fict_gen = pd.read_excel(f'{current_conference_folder}/List_of_genres_agents_editors.xlsx', sheet_name='fiction')\n",
    "nonfict_gen = pd.read_excel(f'{current_conference_folder}/List_of_genres_agents_editors.xlsx', sheet_name='nonfiction')\n",
    "pubs = pd.read_excel(f'{current_conference_folder}/List_of_genres_agents_editors.xlsx', sheet_name='agents_editors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh gosh, some of the column names are hefty...  Let's fix those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "registered = registered.rename(columns={'Hotel vs. Zoom':'Virtual', \n",
    "                                        \"What fiction genre(s) will you be presenting to agents/editors at the conference? (If you're not signing up for any agent/editor meetings, indicate which genre(s) you write.)\":'Fiction genre', \n",
    "                                        \"What nonfiction topic(s) will you be presenting to agents/editors at the conference? (If you're not signing up for any agent/editor meetings, indicate which topic(s) you write.)\":'Nonfiction genre', \n",
    "                                        'Registration Date (GMT)':'Registration Date',\n",
    "                                        'Email Address':'Email'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "waitlist = waitlist.rename(columns={'Registration Date (GMT)':'Registration Date',\n",
    "                                     'Email Address':'Email'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also fix so that we drop the 'Not applicable --I don't write fiction' and 'Not applicable--I don't write nonfiction'. We'll set them to missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "registered['Fiction genre']= registered['Fiction genre'].replace(\"Not Applicable --I don't write fiction\", np.nan)\n",
    "registered['Nonfiction genre']= registered['Nonfiction genre'].replace(\"Not Applicable--I don't write nonfiction\", np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, there's people who wrote in 'Other',  but for our purposes, we don't care about that info for the purposes of matching to agents/editors. Let's remove those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "def clean_genres(genre_string):\n",
    "    if genre_string is None or pd.isna(genre_string) or \"\":\n",
    "        return \"\"\n",
    "\n",
    "    genres = [genre.strip() for genre in genre_string.split(',')]\n",
    "    cleaned_genres = [genre for genre in genres if not re.match(r\"^Other \\(please specify\\):\", genre)]\n",
    "\n",
    "    return \", \".join(cleaned_genres)\n",
    "\n",
    "registered['Fiction genre'] = registered['Fiction genre'].apply(clean_genres)\n",
    "registered['Nonfiction genre'] = registered['Nonfiction genre'].apply(clean_genres)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's replace a few of the ones that have ' in them, which make things tricky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "registered['Fiction genre'] = registered['Fiction genre'].str.replace(\"Women’s\", \"Women's\")\n",
    "registered['Fiction genre'] = registered['Fiction genre'].str.replace(\"Children’s picture/chapter books\", \"Children's picture/chapter books\")\n",
    "registered['Nonfiction genre'] = registered['Nonfiction genre'].str.replace(\"Women’s issues\", \"Women's issues\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop any unneeded variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop any extraneous variables from the waitlist and registration datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "waitlist.drop(columns=['Registration Date', 'Invitee Status', 'Action', 'Confirmation Number'],axis=1, inplace=True) # columns are 1, rows are 0\n",
    "\n",
    "registered.drop(columns=['Agenda Item Type', 'Registration Date', 'Registration Type', 'Action'],axis=1, inplace=True) # columns are 1, rows are 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create lists with all time-by-room values\n",
    "We need to pull in the start times for each of the time slots for Friday afternoon (query letter critiques), Saturday morning (manuscript critiques), and Saturday afternoon (pitches) sessions. Without worrying about who our timekeepers are, or which agents are assigned to those rooms, we'll create 3 lists with the times-by-room."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "room_fr = pd.read_excel(f'{current_conference_folder}/List_of_genres_agents_editors.xlsx', sheet_name='rooms_friday')\n",
    "room_sat = pd.read_excel(f'{current_conference_folder}/List_of_genres_agents_editors.xlsx', sheet_name='rooms_sat')\n",
    "timeslots = pd.read_excel(f'{current_conference_folder}/List_of_genres_agents_editors.xlsx', sheet_name='timeslots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "rooms_friday = room_fr.loc[:, 'day':'room_name']\n",
    "rooms_saturday = room_sat.loc[:, 'day':'room_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's combine the timeslots dataset with the friday and saturday rooms datasets to get the lists we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "tslist_fri = pd.merge(timeslots.loc[(timeslots['day']=='Friday') & (timeslots['day_session']=='Afternoon'), :], rooms_friday, how='outer', on='day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "rooms_coach = pd.read_excel(f'{current_conference_folder}/List_of_genres_agents_editors.xlsx', sheet_name='coaches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "tslist_coach = pd.merge(timeslots.loc[(timeslots['day']=='Friday') & (timeslots['day_session']=='Coaching'), :], rooms_coach, how='outer', on='day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pairwise agent-editor combos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a dataset that pairs all agents and editors with each other (18x18), so that we get their combined fiction and non-fiction genre listings. We will need this to ensure that the participants assigned to them for the Friday query letter critiques are a good match.\n",
    "\n",
    "We also need this to determine which agents should be paired with which agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "cross_pubs = pd.merge(pubs, pubs, how='cross')\n",
    "\n",
    "# Drop rows where they cross-reference themselves\n",
    "cross_pubs = cross_pubs.loc[cross_pubs['lit_guest_name_x'] != cross_pubs['lit_guest_name_y'], :]\n",
    "\n",
    "# Rename\n",
    "cross_pubs = cross_pubs.rename(columns={'lit_guest_name_x': 'pubname1', 'lit_guest_type_x': 'pubtype1', 'lit_guest_company_x': 'comp1', 'lit_guest_fiction_x': 'fict1', 'lit_guest_nonfiction_x': 'nonfict1', 'lit_guest_name_y': 'pubname2', 'lit_guest_type_y': 'pubtype2', 'lit_guest_company_y': 'comp2', 'lit_guest_fiction_y': 'fict2', 'lit_guest_nonfiction_y': 'nonfict2'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to make two columns that are the full combination of elements in the 'fiction' and 'nonfiction' genre columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    Coming-of-age, Contemporary, Family saga/drama...\n",
      "2    Christian, Coming-of-age, Contemporary, Family...\n",
      "3    Coming-of-age, Contemporary, Fantasy, Humor, L...\n",
      "4    Coming-of-age, Contemporary, Fantasy, Horror/S...\n",
      "5    Coming-of-age, Contemporary, Family saga/drama...\n",
      "Name: combined_fiction, dtype: object\n"
     ]
    }
   ],
   "source": [
    "cross_pubs['combined_fiction'] = cross_pubs.apply(\n",
    "    lambda row: ', '.join(\n",
    "        sorted(set(row['fict1'].split(', ') + row['fict2'].split(', ')))\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(cross_pubs['combined_fiction'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks great! We have all the unique fiction genres now. We'll just do the same for nonfiction, though that has some missing values, so the code below adjusts for that (not every agent or editor represents nonfiction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1                                                 None\n",
      "2    Business/leadership/law, Cooking/food/cookbook...\n",
      "3    Business/leadership/law, Health/diet/wellness,...\n",
      "4    Essay collection, Self-help/relationships, Tru...\n",
      "5    Current events/politics/social commentary, Ess...\n",
      "Name: combined_nonfiction, dtype: object\n"
     ]
    }
   ],
   "source": [
    "cross_pubs['combined_nonfiction'] = cross_pubs.apply(\n",
    "    lambda row: ', '.join(\n",
    "        sorted(\n",
    "            set(\n",
    "                (row['nonfict1'].split(', ') if pd.notna(row['nonfict1']) else []) +\n",
    "                (row['nonfict2'].split(', ') if pd.notna(row['nonfict2']) else [])\n",
    "            )\n",
    "        )\n",
    "    ) if pd.notna(row['nonfict1']) or pd.notna(row['nonfict2']) else None,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(cross_pubs['combined_nonfiction'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Now, just to be certain it worked, let's count up the unique fiction and nonfiction genres for each guest, as well as for their combined list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   num_fict1  num_fict2  num_combined_fict\n",
      "1         14         16                 18\n",
      "2         14         23                 23\n",
      "3         14          6                 16\n",
      "4         14          8                 16\n",
      "5         14         11                 20\n"
     ]
    }
   ],
   "source": [
    "cross_pubs['num_fict1'] = cross_pubs['fict1'].apply(\n",
    "    lambda x: len(x.split(', ')) if pd.notna(x) else 0\n",
    ")\n",
    "cross_pubs['num_fict2'] = cross_pubs['fict2'].apply(\n",
    "    lambda x: len(x.split(', ')) if pd.notna(x) else 0\n",
    ")\n",
    "cross_pubs['num_nonfict1'] = cross_pubs['nonfict1'].apply(\n",
    "    lambda x: len(x.split(', ')) if pd.notna(x) else 0\n",
    ")\n",
    "cross_pubs['num_nonfict2'] = cross_pubs['nonfict2'].apply(\n",
    "    lambda x: len(x.split(', ')) if pd.notna(x) else 0\n",
    ")\n",
    "cross_pubs['num_combined_fict'] = cross_pubs['combined_fiction'].apply(\n",
    "    lambda x: len(x.split(', ')) if pd.notna(x) else 0\n",
    ")\n",
    "cross_pubs['num_combined_nonfict'] = cross_pubs['combined_nonfiction'].apply(\n",
    "    lambda x: len(x.split(', ')) if pd.notna(x) else 0\n",
    ")\n",
    "\n",
    "print(cross_pubs.loc[0:5, ['num_fict1', 'num_fict2', 'num_combined_fict']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome. This worked great, and now the last bit on this step is to calculate the number of *overlapping* fiction and nonfiction genres per pairing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def count_overlapping_genres(df):\n",
    "    df['fict1'] = df['fict1'].str.split(',')\n",
    "    df['fict2'] = df['fict2'].str.split(',')\n",
    "\n",
    "    df['fiction_overlap'] = df.apply(lambda row: \n",
    "                                  len(set(row['fict1']).intersection(set(row['fict2']))), \n",
    "                                  axis=1)\n",
    "    return df\n",
    "\n",
    "fiction_overlaps = count_overlapping_genres(cross_pubs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def count_overlapping_nonfiction(df):\n",
    "\n",
    "    def clean_genres(genre_list):\n",
    "        if pd.isna(genre_list) or genre_list == 'None' or not genre_list:\n",
    "            return []\n",
    "        else:\n",
    "            try:\n",
    "                return genre_list.split(',')\n",
    "            except AttributeError:\n",
    "                # Handle cases where genre_list is not a string \n",
    "                # (e.g., if it's a list or another object)\n",
    "                return [] \n",
    "\n",
    "    df['nonfict1'] = df['nonfict1'].astype(str).apply(clean_genres) \n",
    "    df['nonfict2'] = df['nonfict2'].astype(str).apply(clean_genres) \n",
    "\n",
    "    df['nonfiction_overlap'] = df.apply(lambda row: \n",
    "                                  len(set(row['nonfict1']).intersection(set(row['nonfict2']))), \n",
    "                                  axis=1)\n",
    "    return df\n",
    "\n",
    "final_cross_pubs = count_overlapping_nonfiction(fiction_overlaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect. Now let's drop any unncessary variables and JUST keep both guests names, their types (agent or editor), and their combined lists of fiction and nonfiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "del(cross_pubs, fiction_overlaps)\n",
    "final_cross_pubs = final_cross_pubs.drop(['comp1', 'comp2', 'fict1', 'fict2', 'nonfict1', 'nonfict2', 'num_fict1', 'num_fict2', 'num_nonfict1', 'num_nonfict2'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank publishers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazing! Now we've gotten the number of unique genres in each of these combined fiction and nonfiction lists for all pairings of agent-agent, editor-editor, and editor-agent. This will help us more easily identify which agent-editor, editor-editor, and agent-agent pairings make the most sense, in terms of representing the most genres and being able to meet the greatest amount of participant needs for Friday's query letter critiques.\n",
    "\n",
    "To better help us though, let's rank the pairings. We'll rank pairings according to the number of fiction and nonfiction genres represented between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pubtype1  pubtype2\n",
       "Agent     Editor      81\n",
       "Editor    Agent       81\n",
       "Agent     Agent       72\n",
       "Editor    Editor      72\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_cross_pubs[['pubtype1', 'pubtype2']].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "final_cross_pubs['rank_fiction'] = final_cross_pubs['num_combined_fict'].rank(ascending=False, method='dense')\n",
    "final_cross_pubs['rank_nonfiction'] = final_cross_pubs['num_combined_nonfict'].rank(ascending=False, method='dense')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also check to see what each publisher's average ranking is (it's clear some people who represent a ton of genres will average high). Note that this is the sum of a publisher's rankings across all their agent-editor, editor-editor, and agent-agent pairings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "ranks_per_pub = pd.DataFrame(final_cross_pubs.groupby('pubname1')['rank_fiction'].mean().reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Okay, now let's add a few variables:\n",
    "1) The ratio of total fiction represented across the pairing to the overlap shared between them (# combined fiction genres / # fiction genres overlapping)\n",
    "2) The ratio of total nonfiction genres represented across the pairing to their overlap\n",
    "3) The sum of these two ratios\n",
    "\n",
    "We'll use these to help identify which pairings are best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "final_cross_pubs['ratio_fiction'] = final_cross_pubs['num_combined_fict'].div(final_cross_pubs['fiction_overlap'])\n",
    "final_cross_pubs['ratio_nonfiction'] = final_cross_pubs['num_combined_nonfict'].div(final_cross_pubs['nonfiction_overlap'])\n",
    "final_cross_pubs['sum_ratios'] = final_cross_pubs['ratio_fiction'] + final_cross_pubs['ratio_nonfiction']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now let's just add the avg ranking variable to the final_cross_pubs list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "final_pubs = final_cross_pubs.merge(ranks_per_pub, how= 'outer', on='pubname1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "final_pubs = final_pubs.rename(columns={'rank_fiction_y':'avg_pub_rank',\n",
    "                                        'rank_fiction_x':'rank_fiction'})\n",
    "final_cross_pubs = final_pubs\n",
    "del(final_pubs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pair the publishers for Friday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll use the final_cross_pubs dataset to pair the publishers for Friday's query critiques. We'll do so by starting with the publisher with the highest average ranking (meaning the agent or editor who had the least in common, on average, with all the other editors and agents). \n",
    "\n",
    "So for instance, we'll start with the agent/editor who has the LEAST overlap with the others. Then we'll select their five pairings with the lowest ratio sum. This means we'll be selecting the five other agents/editors who had the MOST overlap with them in both fiction and nonfiction genres (anyone with no overlap is being excluded entirely). We'll then sort this list by the publisher type and ratio sum. If the person with the least in common with everyone else is an editor, we then prioritize to pick among the agents first in this top 5 list, and then if there aren't any, we'll pair them with another editor (and vice versa if they're an agent).\n",
    "\n",
    "Let's set this up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Create an empty list to save the pairings\n",
    "selected_pairs =[]\n",
    "\n",
    "# We'd like to exclude any same-type pairings, so we don't get agent-agent or editor-editor pairings\n",
    "df = final_cross_pubs[final_cross_pubs['pubtype1'] != final_cross_pubs['pubtype2']]\n",
    "\n",
    "# Let's also exclude any rows where the sum_ratio is Infinity - couldn't do this. Meant there weren't rows for certain pairings\n",
    "#df = final_cross_pubs[np.isfinite(final_cross_pubs['sum_ratios'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "top_pubname = df.loc[df['avg_pub_rank'].idxmax(), 'pubname1']\n",
    "\n",
    "# Filter rows for this pubname1\n",
    "filtered = df[df['pubname1'] == top_pubname]\n",
    "\n",
    "pubtype1 = filtered.iloc[0]['pubtype1']\n",
    "if pubtype1 == 'Editor':\n",
    "    filtered = filtered.sort_values(\n",
    "        by=['pubtype2', 'sum_ratios'], ascending=[True, True])\n",
    "else:  # pubtype1 == 'Agent'\n",
    "    filtered = filtered.sort_values(\n",
    "        by=['pubtype2', 'sum_ratios'], ascending=[False, True])\n",
    "\n",
    "check = filtered[['pubname1', 'pubtype1', 'pubname2', 'pubtype2', 'avg_pub_rank', 'sum_ratios']]\n",
    "check2 = check.sort_values(by=['pubtype2', 'sum_ratios'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             pubname1 pubtype1             pubname2 pubtype2\n",
      "104  Joëlle Delbourgo    Agent         Kurt Brackob   Editor\n",
      "76        Jake Lovell    Agent            Grace Gay   Editor\n",
      "187     Micah Brocker    Agent  Foyinsi Adegbonmire   Editor\n",
      "145       Jéla Lewter   Editor      Paloma Hernando    Agent\n",
      "6    Alexandria Brown   Editor       Renée Fountain    Agent\n",
      "133   Jynastie Wilson    Agent          Dianna Vega   Editor\n",
      "216  Monica Rae Brown   Editor  Jenna Satterthwaite    Agent\n",
      "181     Lauren Bieker    Agent        Nicole Luongo   Editor\n",
      "288       Vicky Weber    Agent           Wendy Wong   Editor\n"
     ]
    }
   ],
   "source": [
    "while not df.empty:\n",
    "    # Identify the publisher with the highest rank (regardless of whether they are pubname1 or pubname2)\n",
    "    top_pubname = df.loc[df['avg_pub_rank'].idxmax(), 'pubname1']\n",
    "\n",
    "    # Filter rows for this pubname1\n",
    "    filtered = df[df['pubname1'] == top_pubname]\n",
    "\n",
    "    # Sort these rows dynamically based on `pubtype1` and `pubtype2`\n",
    "    pubtype1 = filtered.iloc[0]['pubtype1']\n",
    "    if pubtype1 == 'Editor':\n",
    "        filtered = filtered.sort_values(by=['pubtype2', 'sum_ratios'], ascending=[True, True])\n",
    "    if pubtype1 == 'Agent':\n",
    "        filtered = filtered.sort_values(by=['pubtype2', 'sum_ratios'], ascending=[False, True])\n",
    "\n",
    "    # Select the first row from the sorted list\n",
    "    selected_row = filtered.iloc[0]\n",
    "    selected_pairs.append(selected_row)\n",
    "\n",
    "    # Drop all rows containing the selected `pubname1` or `pubname2`\n",
    "    df = df[~df['pubname1'].isin([selected_row['pubname1'], selected_row['pubname2']]) &\n",
    "            ~df['pubname2'].isin([selected_row['pubname1'], selected_row['pubname2']])]\n",
    "\n",
    "    # Stop if we have 9 rows in the result\n",
    "    if len(selected_pairs) == 9:\n",
    "        break\n",
    "\n",
    "# Step 4: Create a new DataFrame or list with the selected rows\n",
    "result_df = pd.DataFrame(selected_pairs)\n",
    "result_df = result_df[['pubname1', 'pubtype1', 'pubname2', 'pubtype2']]\n",
    "\n",
    "# Print or save the result\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm we have 9 pairings\n",
    "len(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Now sure why this is happening, but we need to remove white spaces at teh beginning of the series\n",
    "final_cross_pubs['combined_fiction'] = final_cross_pubs['combined_fiction'].str.lstrip()\n",
    "final_cross_pubs['combined_nonfiction'] = final_cross_pubs['combined_nonfiction'].str.lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Now filter to the editor-agent pairs that we actually have, instead of keeping EVERY combo:\n",
    "final_cross_pubs = pd.merge(final_cross_pubs, final_room_pairings_Friday, how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign the paired publishers their rooms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woohoo! These all look good and make sense, so we're good to go for the room pairings for Friday's query letter critiques. Let's just assign these pairings to actual rooms now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "final_room_pairings_Friday = pd.concat([room_fr.reset_index(drop=True), result_df.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazing!! We are now officially done with determining Friday's pairings. Let's just save this info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "final_room_pairings_Friday.to_excel(f\"{current_conference_folder}/Outputs/Finalized Datasets/Editor-agent pairings for Friday.xlsx\", index=False)\n",
    "final_cross_pubs.to_excel(f\"{current_conference_folder}/Outputs/Finalized Datasets/Final editor-agent pairings with combined genres.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, before we finish this tidbit of code, **make sure to note which agents and editors are in which rooms for Saturday**. You'll want to put this in the *timekeeper* sheet of the *List_of_agents_editors.xlsx*, along with the info on rooms and agent pairings for Friday, since we'll need both of these and will want to ensure that every publisher or publisher pairing on both days has an assigned timekeeper.\n",
    "\n",
    "This info won't change (it'll always be coded the same), and none of the code in this entire program will result in different output either, so feel free to rerun this code later if you forgot this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         day       room_name\n",
      "0   Saturday    Board Room I\n",
      "1   Saturday   Board Room II\n",
      "2   Saturday  Board Room III\n",
      "3   Saturday   Board Room IV\n",
      "4   Saturday    Board Room V\n",
      "5   Saturday   Board Room VI\n",
      "6   Saturday    Fayetteville\n",
      "7   Saturday       Riverdale\n",
      "8   Saturday         Dogwood\n",
      "9   Saturday        Gardenia\n",
      "10  Saturday         Jasmine\n",
      "11  Saturday        Magnolia\n",
      "12  Saturday   Cherokee Rose\n",
      "13  Saturday       Atlanta I\n",
      "14  Saturday      Atlanta II\n",
      "15  Saturday     Atlanta III\n",
      "16  Saturday      Atlanta IV\n",
      "17  Saturday  Peachtree City\n"
     ]
    }
   ],
   "source": [
    "print(rooms_saturday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You note down the above??\n",
    "\n",
    "Perfect! No need to run any more code for a little while. The other sections of code don't need to be run until ~1 month before the conference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: We can potentially integrate with Cvent and pull in data directly via SQL queries. Follow this code: https://www.cdata.com/kb/tech/cvent-python-pandas.rst"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "plaintext"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
