{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Room Schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import re\n",
    "\n",
    "#pip install python-docx\n",
    "#pip install pandas python-docx docxtpl\n",
    "import docx\n",
    "from docx.shared import Pt, RGBColor, Cm, Inches\n",
    "from docx.oxml import OxmlElement\n",
    "from docxtpl import DocxTemplate\n",
    "from docx import Document\n",
    "from docx.oxml.ns import qn\n",
    "from docx.enum.style import WD_STYLE_TYPE\n",
    "from docx.enum.table import WD_ALIGN_VERTICAL\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, PatternFill, Border, Side\n",
    "from openpyxl.worksheet.page import PageMargins\n",
    "from openpyxl.worksheet.worksheet import Worksheet\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "today = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Reference the current conference folder we should be pulling and storing all datasets/excel files/templates\n",
    "current_conference_folder= \"May2025\"\n",
    "\n",
    "# Set the conference dates\n",
    "date_str_fri = '2025-05-02'\n",
    "date_str_sat = '2025-05-03'\n",
    "\n",
    "# Make text versions of the dates for some of the word docs\n",
    "text_fri_date = 'May 2nd'\n",
    "text_sat_date = 'May 3rd'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to bring in all our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Make sure to load only the relevant files from the specific date we want\n",
    "run_date = today # Did this so we could always backtrack to an earlier time point, if necessary\n",
    "\n",
    "final_room_pairings_Friday = pd.read_excel(f\"{current_conference_folder}/Outputs/Finalized datasets/Editor-agent pairings for Friday.xlsx\")\n",
    "final_saturday_rooms = pd.read_excel(f\"{current_conference_folder}/Outputs/Finalized datasets/Final saturday rooms.xlsx\")\n",
    "registered = pd.read_excel(f\"{current_conference_folder}/Outputs/Finalized Datasets/Registered_cleaned_{run_date}.xlsx\", dtype={'phone': str})\n",
    "\n",
    "# Schedules\n",
    "final_friday_assignments2 = pd.read_excel(f\"{current_conference_folder}/Outputs/Finalized datasets/Final Friday query letter critique assignments_{run_date}.xlsx\", dtype={'phone': str})\n",
    "final_sataft_assignments2 = pd.read_excel(f\"{current_conference_folder}/Outputs/Finalized datasets/Finalized pitch assignments_{run_date}.xlsx\", dtype={'phone': str})\n",
    "final_satmorn_assignments2 = pd.read_excel(f\"{current_conference_folder}/Outputs/Finalized datasets/Final manuscript critique assignments_{run_date}.xlsx\", dtype={'phone': str})\n",
    "coaching_schedule = pd.read_excel(f\"{current_conference_folder}/Outputs/Finalized datasets/Finalized coaching schedule_{run_date}.xlsx\", dtype={'phone': str})\n",
    "wait_all = pd.read_excel(f\"{current_conference_folder}/Outputs/Finalized Datasets/Waitlist participants_{run_date}.xlsx\", dtype={'phone': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Joelle is now virtual- we need to swap out any instance of Joëlle Delbourgo with (VIRTUAL) after\n",
    "datasets_to_update = [final_room_pairings_Friday, final_saturday_rooms, final_friday_assignments2, final_sataft_assignments2, final_satmorn_assignments2, coaching_schedule, wait_all]\n",
    "\n",
    "for i in range(len(datasets_to_update)):\n",
    "    df = datasets_to_update[i]\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object' or pd.api.types.is_string_dtype(df[col]):\n",
    "            df[col] = df[col].astype(str).str.replace('Joëlle Delbourgo', 'Joëlle Delbourgo (VIRTUAL)', regex=False)\n",
    "    datasets_to_update[i] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Friday - single page print-out\n",
    "\n",
    "This print-out is just so we have a single sheet saying which publisher pairings are located where."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Create Word document for the publisher pairings and their rooms\n",
    "pairings_doc = docx.Document()\n",
    "\n",
    "# Add a header\n",
    "title = pairings_doc.add_heading('Friday Query Letter Critiques', level=1)\n",
    "title.alignment = 1  # Center align\n",
    "for run in title.runs:\n",
    "    run.font.size = Pt(20)\n",
    "    run.font.name = 'Arial'\n",
    "\n",
    "# Add the second part of the header\n",
    "title2 = pairings_doc.add_heading('Publisher Pairings and Room Locations', level=2)\n",
    "title2.alignment = 1  # Center align\n",
    "for run in title2.runs:\n",
    "    run.font.size = Pt(16)\n",
    "    run.font.name = 'Arial'\n",
    "\n",
    "# Add a line break - the title was too close to the table\n",
    "pairings_doc.add_paragraph(\"\")  # Adds an empty paragraph for spacing\n",
    "pairings_doc.add_paragraph(\"\")  # Adds an empty paragraph for spacing\n",
    "\n",
    "# Add a table\n",
    "table = pairings_doc.add_table(rows=1, cols=2)\n",
    "\n",
    "# Format the header row\n",
    "header_cells = table.rows[0].cells\n",
    "header_cells[0].text = \"Publishers\"\n",
    "header_cells[1].text = \"Room Location\"\n",
    "\n",
    "# Set header font style\n",
    "for cell in header_cells:\n",
    "    for paragraph in cell.paragraphs:\n",
    "        for run in paragraph.runs:\n",
    "            run.font.size = Pt(16)\n",
    "            run.font.name = 'Arial'\n",
    "            run.font.bold = True  # Make the header text bold\n",
    "            run.font.color.rgb = RGBColor(0, 0, 0)  # Black text\n",
    "\n",
    "# Adjust column widths (the publisher pairings column needs more space)\n",
    "table.columns[0].width = Inches(4.5)  # Pairing column\n",
    "table.columns[1].width = Inches(1.5)  # Location column\n",
    "\n",
    "# Add rows to the table\n",
    "for _, row in final_room_pairings_Friday.iterrows():\n",
    "    pairing = f\"{row['pubname1']} & {row['pubname2']}\"\n",
    "    location = row['room_name']\n",
    "    row_cells = table.add_row().cells\n",
    "    row_cells[0].text = pairing\n",
    "    row_cells[1].text = location\n",
    "    for cell in row_cells:\n",
    "        for paragraph in cell.paragraphs:\n",
    "            run = paragraph.runs[0]\n",
    "            run.font.size = Pt(16)\n",
    "            run.font.name = \"Arial\"\n",
    "\n",
    "# Remove table borders\n",
    "tbl = table._element\n",
    "tbl_borders = tbl.xpath(\".//w:tblBorders\")\n",
    "for border in tbl_borders:\n",
    "    border.getparent().remove(border)\n",
    "\n",
    "# Save the Word document\n",
    "pairings_doc.save(f\"{current_conference_folder}/Outputs/Print-outs/Friday-pairings_and_rooms.docx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saturday - single page print-out\n",
    "\n",
    "Again, just a single sheet for Saturday showing where all the agents and editors have been assigned rooms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "del(cell, pairing, location, pairings_doc, row_cells, run, title, title2)\n",
    "\n",
    "# Create Word document for the publisher pairings and their rooms\n",
    "pairings_doc = docx.Document()\n",
    "\n",
    "# Change the margins\n",
    "sections = pairings_doc.sections\n",
    "for section in sections:\n",
    "    section.top_margin = Inches(0.5)\n",
    "\n",
    "# Add a header\n",
    "title = pairings_doc.add_heading('Saturday Publishers and Room Locations', level=1)\n",
    "title.alignment = 1  # Center align\n",
    "for run in title.runs:\n",
    "    run.font.size = Pt(20)\n",
    "    run.font.name = 'Arial'\n",
    "\n",
    "# Add a line break - the title was too close to the table\n",
    "pairings_doc.add_paragraph(\"\")  # Adds an empty paragraph for spacing\n",
    "\n",
    "# Add a table\n",
    "table = pairings_doc.add_table(rows=1, cols=2)\n",
    "\n",
    "# Format the header row\n",
    "header_cells = table.rows[0].cells\n",
    "header_cells[0].text = \"Publishers\"\n",
    "header_cells[1].text = \"Room Location\"\n",
    "\n",
    "# Set header font style\n",
    "for cell in header_cells:\n",
    "    for paragraph in cell.paragraphs:\n",
    "        for run in paragraph.runs:\n",
    "            run.font.size = Pt(16)\n",
    "            run.font.name = 'Arial'\n",
    "            run.font.bold = True  # Make the header text bold\n",
    "            run.font.color.rgb = RGBColor(0, 0, 0)  # Black text\n",
    "\n",
    "# Adjust column widths (the publisher pairings column needs more space)\n",
    "table.columns[0].width = Inches(4)  # Pairing column\n",
    "table.columns[1].width = Inches(2)  # Location column\n",
    "\n",
    "# Add rows to the table\n",
    "for _, row in final_saturday_rooms.iterrows():\n",
    "    pairing = row['lit_guest_name']\n",
    "    location = row['room_name']\n",
    "    row_cells = table.add_row().cells\n",
    "    row_cells[0].text = pairing\n",
    "    row_cells[1].text = location\n",
    "    for cell in row_cells:\n",
    "        for paragraph in cell.paragraphs:\n",
    "            run = paragraph.runs[0]\n",
    "            run.font.size = Pt(16)\n",
    "            run.font.name = \"Arial\"\n",
    "\n",
    "# Remove table borders\n",
    "#tbl = table._element\n",
    "#tbl_borders = tbl.xpath(\".//w:tblBorders\")\n",
    "#for border in tbl_borders:\n",
    "#    border.getparent().remove(border)\n",
    "\n",
    "# Save the Word document\n",
    "pairings_doc.save(f\"{current_conference_folder}/Outputs/Print-outs/Saturday-Publishers_and_rooms.docx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Friday individual room schedules (for the doors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now create the word docs (iteratively) with the schedules for each of the rooms. First, we need to add a column that is the start-end time, and we also need to add a row that says 'break' at 3:15-3:30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Create the break timeslot at 3:15\n",
    "break_time = pd.Timestamp(date_str_fri + ' 15:15:00')\n",
    "\n",
    "# Create a dataset with it (should have 9 rows)\n",
    "break_data = {\n",
    "    'timeslot_start': [break_time] * len(final_friday_assignments2['room_name'].unique()),  # Create a break for each room\n",
    "    'room_name': final_friday_assignments2['room_name'].unique(),  # Each room gets the break\n",
    "    'First Name': ['BREAK'] * len(final_friday_assignments2['room_name'].unique()),  # 'Break' for all participants at the break slot\n",
    "}\n",
    "\n",
    "break_df = pd.DataFrame(break_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Append it to the friday_prints\n",
    "friday_prints2 = pd.concat([final_friday_assignments2, break_df], ignore_index=True).sort_values(by=['room_name', 'timeslot_start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Function to format time slots\n",
    "def format_timeslot(ts):\n",
    "    start_time = ts.strftime('%I:%M').lstrip('0')  # Remove leading zero for hours\n",
    "    end_time = (ts + timedelta(minutes=15)).strftime('%I:%M').lstrip('0')  # Add 15 minutes\n",
    "    return f'{start_time}-{end_time}'\n",
    "\n",
    "friday_prints2['formatted_timeslot'] = friday_prints2['timeslot_start'].apply(format_timeslot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Sort by room, then timeslot\n",
    "friday_prints2 = friday_prints2.sort_values(by=['room_name', 'timeslot_start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def create_word_doc(room_df):\n",
    "    for room, room_data in room_df.groupby('room_name'):\n",
    "        doc = docx.Document()\n",
    "\n",
    "        # Get the first valid row for publishers, excluding the break row\n",
    "        room_data_no_break = room_data[room_data['First Name'] != 'BREAK']\n",
    "        pubname1 = room_data_no_break['pubname1'].iloc[0]  # First valid publisher\n",
    "        pubname2 = room_data_no_break['pubname2'].iloc[0]  # First valid publisher\n",
    " \n",
    "        # Room header\n",
    "        title = doc.add_heading(f\"{room}\", level=1)\n",
    "        title.alignment = 1  # Center align\n",
    "        for run in title.runs:\n",
    "            run.font.size = Pt(20)\n",
    "            run.font.name = 'Arial'\n",
    "\n",
    "        title.runs[0].font.color.rgb = RGBColor(0, 0, 0)  # RGB for black\n",
    "\n",
    "        title.paragraph_format.space_after = 0  # Remove space after header\n",
    "        title.paragraph_format.space_before = 0  # Remove space before header\n",
    "      \n",
    "\n",
    "        # Add subheader \n",
    "        title2 = doc.add_heading(\"Query Letter Critique\", level=2)\n",
    "        doc.add_paragraph(\"\")  # Adds an empty paragraph for spacing\n",
    "        title2.runs[0].font.color.rgb = RGBColor(0, 0, 0)  # RGB for black\n",
    "\n",
    "        title3 = doc.add_heading(f\"{pubname1} and {pubname2}\", level=1) # Print out the publishers assigned to that room\n",
    "        #title2.paragraph_format.space_after = 0  # Remove space after header\n",
    "        title2.paragraph_format.space_before = 0  # Remove space before header\n",
    "        title3.paragraph_format.space_after = 0  # Remove space after header\n",
    "        title3.paragraph_format.space_before = 0  # Remove space before header\n",
    "      \n",
    "        title2.alignment = 1  # Center align\n",
    "        for run in title2.runs:\n",
    "            run.font.size = Pt(16)\n",
    "            run.font.name = 'Arial'\n",
    "\n",
    "        title3.alignment = 1  # Center align\n",
    "        for run in title3.runs:\n",
    "            run.font.size = Pt(20)\n",
    "            run.font.name = 'Arial'\n",
    "\n",
    "        title3.runs[0].font.color.rgb = RGBColor(0, 0, 0)  # RGB for black\n",
    "\n",
    "\n",
    "        # Add a line break - the title was too close to the table\n",
    "        doc.add_paragraph(\"\")  # Adds an empty paragraph for spacing\n",
    "\n",
    "        # Iterate over the timeslots and participants\n",
    "        for _, row in room_data.iterrows():\n",
    "            time_slot = row['formatted_timeslot']\n",
    "\n",
    "            if pd.isna(row['Last Name']):  \n",
    "                full_name = \"BREAK\"\n",
    "                para = doc.add_paragraph(f\"{time_slot}\\t\\t{full_name}\")\n",
    "                para.runs[0].bold = True  # Make \"Break\" bold\n",
    "            else:\n",
    "                full_name = f\"{row['First Name']} {row['Last Name']}\"\n",
    "\n",
    "                # Add (ZOOM) if they're virtual\n",
    "                if row['virtual'] == 'Virtual':  # Add (ZOOM) if virtual\n",
    "                    full_name += \" (ZOOM)\"\n",
    "                para = doc.add_paragraph(f\"{time_slot}\\t\\t{full_name}\")\n",
    "            \n",
    "            # Set the font size and font family\n",
    "            run = para.runs[0]\n",
    "            run.font.size = Pt(16)\n",
    "            run.font.name = 'Arial'\n",
    "        \n",
    "        # Save the document with the room name as filename\n",
    "        doc.save(f\"{current_conference_folder}/Outputs/Print-outs/Friday_{room}_meeting_schedule.docx\")\n",
    "\n",
    "# Generate documents\n",
    "for room, room_data in friday_prints2.groupby('room_name'):\n",
    "    create_word_doc(friday_prints2[friday_prints2['room_name'] == room])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Friday Coaching Room Schedule\n",
    "Let's print out the room schedules for the two author coaching sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Create the break timeslot at 14:14\n",
    "break_time = pd.Timestamp(date_str_fri + ' 14:14:00')\n",
    "\n",
    "# Create a dataset with it (should have 9 rows)\n",
    "break_data = {\n",
    "    'timeslot_start': [break_time] * len(coaching_schedule['room_name'].unique()),  # Create a break for each room\n",
    "    'room_name': coaching_schedule['room_name'].unique(),  # Each room gets the break\n",
    "    'First Name': ['BREAK'] * len(coaching_schedule['room_name'].unique()),  # 'Break' for all participants at the break slot\n",
    "}\n",
    "\n",
    "break_df = pd.DataFrame(break_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Append it to the friday_prints\n",
    "coaching_schedule2 = pd.concat([coaching_schedule, break_df], ignore_index=True).sort_values(by=['room_name', 'timeslot_start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#  Use the same function we created earlier to format the times\n",
    "coaching_schedule2['formatted_timeslot'] = coaching_schedule2['timeslot_start'].apply(format_timeslot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Sort by room, then timeslot\n",
    "coaching_schedule2 = coaching_schedule2.sort_values(by=['room_name', 'timeslot_start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Identify virtual participants\n",
    "virtual = registered.loc[registered['Virtual'].str.contains('Zoom', na=False), 'Email']\n",
    "\n",
    "# Add a 'virtual' column to coaching_schedule2: True if email is in the virtual list\n",
    "coaching_schedule2['virtual'] = coaching_schedule2['Email'].isin(virtual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def create_word_doc_coaching(room_df):\n",
    "    for room, room_data in room_df.groupby('room_name'):\n",
    "        doc = docx.Document()\n",
    "\n",
    "        # Get the first valid row for publishers, excluding the break row\n",
    "        room_data_no_break = room_data[room_data['First Name'] != 'BREAK']\n",
    "        publisher = room_data_no_break['publisher'].iloc[0]  # First valid publisher\n",
    " \n",
    "        # Room header\n",
    "        title = doc.add_heading(f\"{room}\", level=1)\n",
    "        title.alignment = 1  # Center align\n",
    "        for run in title.runs:\n",
    "            run.font.size = Pt(20)\n",
    "            run.font.name = 'Arial'\n",
    "\n",
    "        title.runs[0].font.color.rgb = RGBColor(0, 0, 0)  # RGB for black\n",
    "\n",
    "        title.paragraph_format.space_after = 0  # Remove space after header\n",
    "        title.paragraph_format.space_before = 0  # Remove space before header\n",
    "      \n",
    "\n",
    "        # Add subheader \n",
    "        title2 = doc.add_heading(\"Author Coaching\", level=2)\n",
    "        doc.add_paragraph(\"\")  # Adds an empty paragraph for spacing\n",
    "        title2.runs[0].font.color.rgb = RGBColor(0, 0, 0)  # RGB for black\n",
    "\n",
    "        title3 = doc.add_heading(f\"{publisher}\", level=1) # Print out the publishers assigned to that room\n",
    "        #title2.paragraph_format.space_after = 0  # Remove space after header\n",
    "        title2.paragraph_format.space_before = 0  # Remove space before header\n",
    "        title3.paragraph_format.space_after = 0  # Remove space after header\n",
    "        title3.paragraph_format.space_before = 0  # Remove space before header\n",
    "      \n",
    "        title2.alignment = 1  # Center align\n",
    "        for run in title2.runs:\n",
    "            run.font.size = Pt(16)\n",
    "            run.font.name = 'Arial'\n",
    "\n",
    "        title3.alignment = 1  # Center align\n",
    "        for run in title3.runs:\n",
    "            run.font.size = Pt(20)\n",
    "            run.font.name = 'Arial'\n",
    "\n",
    "        title3.runs[0].font.color.rgb = RGBColor(0, 0, 0)  # RGB for black\n",
    "\n",
    "        # Add a line break - the title was too close to the table\n",
    "        doc.add_paragraph(\"\")  # Adds an empty paragraph for spacing\n",
    "\n",
    "        # Iterate over the timeslots and participants\n",
    "        for _, row in room_data.iterrows():\n",
    "            time_slot = row['formatted_timeslot']\n",
    "\n",
    "            if pd.isna(row['Last Name']):  \n",
    "                full_name = \"BREAK\"\n",
    "                para = doc.add_paragraph(f\"{time_slot}\\t\\t\\t{full_name}\")\n",
    "                para.runs[0].bold = True  # Make \"Break\" bold\n",
    "            else:\n",
    "                full_name = f\"{row['First Name']} {row['Last Name']}\"\n",
    "\n",
    "                # Add (ZOOM) if they're virtual\n",
    "                if row['virtual'] == True:  # Add (ZOOM) if virtual\n",
    "                    full_name += \" (ZOOM)\"\n",
    "                para = doc.add_paragraph(f\"{time_slot}\\t\\t\\t{full_name}\")\n",
    "            \n",
    "            # Set the font size and font family\n",
    "            run = para.runs[0]\n",
    "            run.font.size = Pt(16)\n",
    "            run.font.name = 'Arial'\n",
    "        \n",
    "        # Save the document with the room name as filename\n",
    "        doc.save(f\"{current_conference_folder}/Outputs/Print-outs/Friday_Coaching_{room}_meeting_schedule.docx\")\n",
    "\n",
    "# Generate documents\n",
    "for room, room_data in coaching_schedule2.groupby('room_name'):\n",
    "    create_word_doc_coaching(coaching_schedule2[coaching_schedule2['room_name'] == room])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saturday individual room schedules (for the doors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Create the break timeslot at 11:30 on saturday\n",
    "break_time = pd.Timestamp(date_str_sat + ' 11:30:00')\n",
    "\n",
    "# Create a dataset with it (should have 9 rows)\n",
    "break_data = {\n",
    "    'timeslot_start': [break_time] * len(final_satmorn_assignments2['room_name'].unique()),  # Create a break for each room\n",
    "    'room_name': final_satmorn_assignments2['room_name'].unique(),  # Each room gets the break\n",
    "    'First Name': ['BREAK'] * len(final_satmorn_assignments2['room_name'].unique()),  # 'Break' for all participants at the break slot\n",
    "}\n",
    "\n",
    "break_morn = pd.DataFrame(break_data)\n",
    "\n",
    "# Create the break timeslot at 3:15 on Saturday\n",
    "break_time = pd.Timestamp(date_str_sat + ' 15:45:00')\n",
    "\n",
    "# Create a dataset with it (should have 9 rows)\n",
    "break_data = {\n",
    "    'timeslot_start': [break_time] * len(final_sataft_assignments2['room_name'].unique()),  # Create a break for each room\n",
    "    'room_name': final_sataft_assignments2['room_name'].unique(),  # Each room gets the break\n",
    "    'First Name': ['BREAK'] * len(final_sataft_assignments2['room_name'].unique()),  # 'Break' for all participants at the break slot\n",
    "}\n",
    "\n",
    "break_after = pd.DataFrame(break_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Add these break times to their respective datasets and sort by the timeslots in each room\n",
    "sat_morn2 = pd.concat([final_satmorn_assignments2, break_morn], ignore_index=True).sort_values(by=['room_name', 'timeslot_start'])\n",
    "sat_after2 = pd.concat([final_sataft_assignments2, break_after], ignore_index=True).sort_values(by=['room_name', 'timeslot_start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Lastly, format the time variables how we want them:\n",
    "sat_morn2['formatted_timeslot'] = sat_morn2['timeslot_start'].apply(format_timeslot)\n",
    "sat_after2['formatted_timeslot'] = sat_after2['timeslot_start'].apply(format_timeslot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's actually run the code to output the print-outs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def create_word_doc_for_day(morning_df, afternoon_df):\n",
    "    for room in morning_df['room_name'].unique():\n",
    "        doc = docx.Document()\n",
    "\n",
    "        # Room header (title with pubtype1 + room_name)\n",
    "        room_data_no_break = morning_df[\n",
    "            (morning_df['room_name'] == room) & \n",
    "            (morning_df['First Name'] != 'BREAK')\n",
    "        ]\n",
    "        publisher = room_data_no_break['publisher'].iloc[0]\n",
    "\n",
    "        room_header = doc.add_heading(f\"{publisher} {room}\", level=1)\n",
    "        room_header.alignment = 1  # Center-align the header\n",
    "        room_header.paragraph_format.space_after = 0  # Remove space after header\n",
    "        room_header.paragraph_format.space_before = 0  # Remove space before header\n",
    "        run1 = room_header.runs[0]\n",
    "        run1.font.size = Pt(20)\n",
    "        run1.font.name = 'Arial'\n",
    "        run1.font.color.rgb = RGBColor(0, 0, 0)  # RGB for black\n",
    "\n",
    "        \n",
    "        # Add subheader \"Critique Schedule\"\n",
    "        title2 = doc.add_heading(\"Manuscript Critique Schedule\", level=2)\n",
    "        #doc.add_paragraph()  # Add paragraph break\n",
    "        run = title2.runs[0]\n",
    "        run.font.size = Pt(16)\n",
    "        run.font.name = 'Arial'\n",
    "        run.font.color.rgb = RGBColor(0, 0, 0)  # RGB for black\n",
    "\n",
    "        \n",
    "        # Add morning schedule (ms_data) and handle break times\n",
    "        morning_data = morning_df[morning_df['room_name'] == room]\n",
    "        for _, row in morning_data.iterrows():\n",
    "            time_slot = row['formatted_timeslot']\n",
    "            if time_slot == \"11:30-11:45\":  # Break time for morning session\n",
    "                full_name = \"BREAK\"\n",
    "                para = doc.add_paragraph(f\"{time_slot}\\t\\t{full_name}\")\n",
    "                para.runs[0].bold = True  # Make \"Break\" bold\n",
    "            else:\n",
    "                full_name = f\"{row['First Name']} {row['Last Name']}\"\n",
    "                if pd.isna(row['Last Name']):\n",
    "                    full_name = row['First Name']\n",
    "                if row['virtual'] == 'Virtual':  # Add (ZOOM) if virtual\n",
    "                    full_name += \" (ZOOM)\"\n",
    "                if row['Session']=='Pitch':\n",
    "                    full_name += \" (PITCH)\"\n",
    "                para = doc.add_paragraph(f\"{time_slot}\\t\\t{full_name}\")\n",
    "            \n",
    "            para.runs[0].font.size = Pt(16)\n",
    "            para.runs[0].font.name = 'Arial'\n",
    "            para.paragraph_format.space_after = 0  # Remove space after each paragraph\n",
    "            para.paragraph_format.space_before = 0  # Remove space before each paragraph\n",
    "       \n",
    "        \n",
    "        # Add paragraph break before \"Pitch Schedule\"\n",
    "        #doc.add_paragraph()  # Add paragraph break\n",
    "        \n",
    "        # Add subheader \"Pitch Schedule\"\n",
    "        title3 = doc.add_heading(\"Pitch Schedule\", level=2)\n",
    "        run2 = title3.runs[0]\n",
    "        run2.font.size = Pt(16)\n",
    "        run2.font.name = 'Arial'\n",
    "        run2.font.color.rgb = RGBColor(0, 0, 0)  # RGB for black\n",
    "\n",
    "\n",
    "        # Add afternoon schedule (pitch_data) and handle break times\n",
    "        afternoon_data = afternoon_df[afternoon_df['room_name'] == room]\n",
    "        for _, row in afternoon_data.iterrows():\n",
    "            time_slot = row['formatted_timeslot']\n",
    "            if time_slot == \"3:45-4:00\":  # Break time for afternoon session\n",
    "                full_name = \"BREAK\"\n",
    "                para = doc.add_paragraph(f\"{time_slot}\\t\\t\\t{full_name}\")\n",
    "                para.runs[0].bold = True  # Make \"Break\" bold\n",
    "            else:\n",
    "                full_name = f\"{row['First Name']} {row['Last Name']}\"\n",
    "                if pd.isna(row['Last Name']):\n",
    "                    full_name = row['First Name']\n",
    "                if row['virtual'] == 'Virtual':  # Add (ZOOM) if virtual\n",
    "                    full_name += \" (ZOOM)\"\n",
    "                para = doc.add_paragraph(f\"{time_slot}\\t\\t\\t{full_name}\")\n",
    "            \n",
    "            para.runs[0].font.size = Pt(16)\n",
    "            para.runs[0].font.name = 'Arial'\n",
    "            para.paragraph_format.space_after = 0  # Remove space after each paragraph\n",
    "            para.paragraph_format.space_before = 0  # Remove space before each paragraph\n",
    "\n",
    "        # Add footer with event info in blue and bold\n",
    "        section = doc.sections[-1]\n",
    "        footer = section.footer\n",
    "        footer_paragraph = footer.paragraphs[0]\n",
    "        footer_paragraph.text = \"Giveaway Drawings & Award Ceremony in College Park Ballroom at 5:50pm\"\n",
    "        footer_paragraph.runs[0].bold = True\n",
    "        footer_paragraph.runs[0].font.color.rgb = RGBColor(0, 0, 0)  # Set color to black\n",
    "\n",
    "        # Save the document with the room name as filename\n",
    "        doc.save(f\"{current_conference_folder}/Outputs/Print-outs/Saturday_{publisher}_{room}_meeting_schedule.docx\")\n",
    "\n",
    "# Example usage: assuming morning_df and afternoon_df are your datasets\n",
    "# Generate documents for each room\n",
    "for room in sat_morn2['room_name'].unique():\n",
    "    create_word_doc_for_day(sat_morn2, sat_after2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publisher Schedules\n",
    "\n",
    "We'll have these printed for the agents and editors to pick up when they arrive at the Conference. It'll just tell them where to be and when, and give a few other tips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Fix the dataset so that all the pubname1s are editors, and all pubname2s are agents\n",
    "def correct_row(row):\n",
    "    if row['pubtype1'] == 'Agent' and row['pubtype2'] == 'Editor':\n",
    "        # Swap the names and types\n",
    "        row['pubname1'], row['pubname2'] = row['pubname2'], row['pubname1']\n",
    "        row['pubtype1'], row['pubtype2'] = row['pubtype2'], row['pubtype1']\n",
    "    return row\n",
    "\n",
    "# Apply the correction to all rows\n",
    "corrected_data = final_room_pairings_Friday.apply(correct_row, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the actual code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def generate_schedule(row, template_path, output_dir, pubtype):\n",
    "    doc = DocxTemplate(template_path)\n",
    "    context = {\n",
    "        \"pubname1\": row[\"pubname1\"],\n",
    "        \"pubname2\": row[\"pubname2\"],\n",
    "        \"pubtype1\": row[\"pubtype1\"],\n",
    "        \"pubtype2\": row[\"pubtype2\"],\n",
    "        \"room_name\": row[\"room_name\"]\n",
    "    }\n",
    "    if pubtype == 'Agents':\n",
    "        output_path = os.path.join(output_dir, f\"Friday_{row['pubname2']}_schedule.docx\")\n",
    "    if pubtype == \"Editors\":\n",
    "        output_path = os.path.join(output_dir, f\"Friday_{row['pubname1']}_schedule.docx\")\n",
    "\n",
    "    doc.render(context)\n",
    "    doc.save(output_path)\n",
    "\n",
    "# Specify output directory\n",
    "output_dir = f\"{current_conference_folder}/Outputs/Print-outs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Generate schedules for editors\n",
    "for _, row in corrected_data.iterrows():\n",
    "    generate_schedule(row, \"Templates/Friday_editor_schedule.docx\", output_dir, \"Editors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Generate schedules for agents\n",
    "for _, row in corrected_data.iterrows():\n",
    "    generate_schedule(row, \"Templates/Friday_agent_schedule.docx\", output_dir, \"Agents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Now let's do it for Saturday (which is a little easier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def generate_sat_schedule(row, output_dir):\n",
    "\n",
    "    if row['lit_guest_type'] == 'Agent':\n",
    "        template_path = \"Templates/Saturday_agent_schedule.docx\"\n",
    "    else:\n",
    "        template_path = \"Templates/Saturday_editor_schedule.docx\"\n",
    "\n",
    "    doc = DocxTemplate(template_path)\n",
    "    \n",
    "    context = {\n",
    "        \"lit_guest_name\": row[\"lit_guest_name\"],\n",
    "        \"lit_guest_type\": row[\"lit_guest_type\"],\n",
    "        \"room_name\": row[\"room_name\"]\n",
    "    }\n",
    "\n",
    "    output_path = os.path.join(output_dir, f\"Saturday_{row['lit_guest_name']}_schedule.docx\")\n",
    "\n",
    "    doc.render(context)\n",
    "    doc.save(output_path)\n",
    "\n",
    "# Specify output directory\n",
    "output_dir = f\"{current_conference_folder}/Outputs/Print-outs\"\n",
    "\n",
    "# Generate schedules\n",
    "for _, row in final_saturday_rooms.iterrows():\n",
    "    generate_sat_schedule(row, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ballroom Schedule\n",
    "\n",
    "Lastly, we need to print out the friday and saturday schedules for the College Park Ballroom (the miniseminars and workshops)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "fri_talks = pd.read_excel(f'{current_conference_folder}/List_of_genres_agents_editors.xlsx', sheet_name='minis_fri')\n",
    "sat_talks = pd.read_excel(f'{current_conference_folder}/List_of_genres_agents_editors.xlsx', sheet_name='minis_sat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# We need to correct the timeslots to the correct dates and times for both\n",
    "fri_talks['timeslot_start'] = pd.to_datetime(date_str_fri + ' ' + fri_talks['timeslot_start'].astype(str))\n",
    "fri_talks['timeslot_end'] = pd.to_datetime(date_str_fri + ' ' + fri_talks['timeslot_end'].astype(str))\n",
    "\n",
    "# Adjust the times to represent the afternoon (add 12 hours if in AM range)\n",
    "fri_talks['timeslot_start'] = fri_talks['timeslot_start'].apply(\n",
    "    lambda x: x + pd.Timedelta(hours=12) if x.hour < 9 else x\n",
    ")\n",
    "fri_talks['timeslot_end'] = fri_talks['timeslot_end'].apply(\n",
    "    lambda x: x + pd.Timedelta(hours=12) if x.hour < 9 else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "sat_talks['timeslot_start'] = pd.to_datetime(date_str_sat + ' ' + sat_talks['timeslot_start'].astype(str))\n",
    "sat_talks['timeslot_end'] = pd.to_datetime(date_str_sat + ' ' + sat_talks['timeslot_end'].astype(str))\n",
    "\n",
    "# Adjust the times to represent the afternoon (add 12 hours if in AM range)\n",
    "sat_talks['timeslot_start'] = sat_talks['timeslot_start'].apply(\n",
    "    lambda x: x + pd.Timedelta(hours=12) if x.hour < 9 else x\n",
    ")\n",
    "sat_talks['timeslot_end'] = sat_talks['timeslot_end'].apply(\n",
    "    lambda x: x + pd.Timedelta(hours=12) if x.hour < 9 else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "template_path = \"Templates/Schedules for Posting - Friday Talks.docx\"  # Path to your Word template\n",
    "doc = DocxTemplate(template_path)\n",
    "\n",
    "# Create the context\n",
    "context = {\n",
    "    \"mini1\": fri_talks.loc[0, \"topic\"],\n",
    "    \"speaker\": fri_talks.loc[0, \"speaker\"],\n",
    "    \"designation\": fri_talks.loc[0, \"designation\"],\n",
    "    \"mini2\": fri_talks.loc[1, \"topic\"],\n",
    "    \"workshop\": fri_talks.loc[2, \"topic\"],\n",
    "}\n",
    "\n",
    "# Render the template with the context\n",
    "doc.render(context)\n",
    "\n",
    "# Save the populated document\n",
    "output_path = f\"{current_conference_folder}/Outputs/Print-outs/Friday_Schedule_CollegeParkBallrooms.docx\"\n",
    "doc.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "template_path = \"Templates/Schedules for Posting - Saturday Talks.docx\"  # Path to your Word template\n",
    "doc = DocxTemplate(template_path)\n",
    "\n",
    "# Create the context\n",
    "context = {\n",
    "    \"mini1\": sat_talks.loc[0, \"topic\"],\n",
    "    \"mini2\": sat_talks.loc[1, \"topic\"],\n",
    "    \"mini3\": sat_talks.loc[2, \"topic\"],\n",
    "    \"mini4\": sat_talks.loc[3, \"topic\"],\n",
    "    \"speaker1\": sat_talks.loc[0, \"speaker\"],\n",
    "    \"designation1\": sat_talks.loc[0, \"designation\"],\n",
    "    \"speaker2\": sat_talks.loc[2, \"speaker\"],\n",
    "    \"designation2\": sat_talks.loc[2, \"designation\"],\n",
    "}\n",
    "\n",
    "# Render the template with the context\n",
    "doc.render(context)\n",
    "\n",
    "# Save the populated document\n",
    "output_path = f\"{current_conference_folder}/Outputs/Print-outs/Saturday_Schedule_CollegeParkBallrooms.docx\"\n",
    "doc.save(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Participant Schedules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do anything, since we've already dealt with the manuscript critiques, pitches and query critiques, let's drop those rows from the registered dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "fri_workshop = registered[registered['Agenda Item Name'].str.contains('Workshop')]\n",
    "\n",
    "directory = f\"{current_conference_folder}/Cvent_report_downloads\"\n",
    "most_recent_file = max(\n",
    "    (f for f in os.listdir(directory) if f.startswith('Allparticipants_') and f.endswith('.csv')),\n",
    "    key=lambda x: datetime.datetime.strptime(x.split('_')[1].split('.')[0], '%m-%d-%y'),\n",
    ")\n",
    "\n",
    "# Load the most recent file\n",
    "most_recent_path = os.path.join(directory, most_recent_file)\n",
    "all_participants = pd.read_csv(most_recent_path)\n",
    "del(most_recent_file, most_recent_path)\n",
    "\n",
    "all_participants = all_participants.rename(columns={'Email Address':'Email'})\n",
    "virtual_only = all_participants.loc[all_participants['Hotel vs. Zoom'] == 'Virtually via Zoom (only available for query letter critiques, manuscript sample critiques, and pitches)', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "registered2 = registered.loc[(~(registered['Agenda Item Name'].str.contains('Query Letter Critique')) & \n",
    "                             ~(registered['Agenda Item Name'].str.contains('Manuscript Critique')) &\n",
    "                             ~(registered['Agenda Item Name'].str.contains('Pitch [A-Z]'))), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also drop the pre-conference edits, since those have already happened prior to the event and is something George takes care of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "registered3= registered2.loc[(~(registered2['Agenda Item Name'].str.contains('Pre-conference Edit'))), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the 'Virtual' variable to match the 'virtual' variable found in our other datasets (which is formatted more nicely)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-34>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "registered3['virtual'] = registered3['Virtual'].replace(['Virtually via Zoom (only available for query letter critiques, manuscript sample critiques, and pitches)', 'In person at the conference hotel'],\n",
    "                                                              ['Virtual', 'In person'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, since this is for the schedules they'll be picking up at check-in, we can drop the check-in rows. (Also, now that we added the coaching activity, we need to drop that too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "registered3 = registered3.loc[~registered3['Agenda Item Name'].str.contains('Check-in|Coaching')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's separate out into Friday vs Saturday stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agenda Item Name\n",
      "Award Ceremony & Prize Giveaway                                       221\n",
      "Friday Mini-Seminars                                                  221\n",
      "Friday Night Mixer                                                    221\n",
      "Saturday Afternoon Mini-Seminars                                      221\n",
      "Saturday Morning Mini-Seminars                                        221\n",
      "Saturday Agent Q&A Panel                                               96\n",
      "Friday Publisher Q&A Panel                                             92\n",
      "Friday Workshop- Writer Beware: How Writers Can Protect Themselves     68\n",
      "Book Fair Book Selling                                                 10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(registered3['Agenda Item Name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "fri_activities = registered3.loc[(registered3['Agenda Item Name'].str.contains('Friday|Book')), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "sat_activities = registered3.loc[registered3['Agenda Item Name'].str.contains('Saturday|Award'), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome. Let's delete a few of these intermediate datasets and then move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "del(registered3, registered2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Virtual participants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thankfully, there's nothing to print for the virtual participants, so we can ignore them for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In person participants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to print each individual participant's schedules for Friday and Saturday, we need to merge together all our different datasets, but doing so separately for Friday vs Saturday. We're going to restrict these two datasets to people who are IN PERSON.\n",
    "\n",
    "**FRIDAY:**\n",
    "\n",
    "1) Merge the coaching and query letter stuff together, plus information about whether they're doing the workshop, Q&A panel, mini-seminars, or book fair, friday night social, as well as any waitlist information for those activities. Note that check-in is the same for everyone, so we don't need to include that. It'll be in the template. \n",
    "2) We'll filter this full dataset to only in person participants. It's okay to have multiple rows per participant. We just need to make sure the core variables are all named the same, such as 'Session', 'publisher', 'room_name', 'timeslot_start'.\n",
    "3) Once we have that, we'll work to compile it all and print it out to word using a template.\n",
    "\n",
    "**SATURDAY:**\n",
    "\n",
    "1) We'll merge the MS and pitch datasets together, along with the Q&A panel, the mini seminars, and the award ceremony. We'll also include any waitlists for those activities.\n",
    "2) We'll filter this to in person only, and make sure all the variables have the same names in this combined dataset so we can more easily compile it.\n",
    "3) We'll print it to word using a template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# We need to change the session names so they better match what we want to print. We'll call this new variable 'Session' to match the other datasets\n",
    "fri_activities['Session'] = fri_activities['Agenda Item Name'].replace(['Book Fair Book Selling', 'Friday Mini-Seminars', 'Friday Publisher Q&A Panel', 'Friday Workshop- Writer Beware: How Writers Can Protect Themselves'],\n",
    "                                                              ['Selling your book(s) at the Book Fair', 'Mini-seminar', 'Publisher Q&A panel', 'Workshop, \"Writer Beware: How Writers Can Protect Themselves\"'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** for the above: the Book fair people are SELLERS, not buyers. We will apply the book fair to people's schedules as part of the word doc code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "sat_activities['Session']=sat_activities['Agenda Item Name'].replace(['Saturday Afternoon Mini-Seminars', 'Saturday Morning Mini-Seminars', 'Saturday Agent Q&A Panel'],\n",
    "                                                                    ['Mini-seminar', 'Mini-seminar', 'Agent Q&A panel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to deal with the miniseminars. There's two, but in the data file it just shows one. For Friday and Saturday, let's identify anyone who's signed up for the mini-seminars and create a dataset with their rows for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Friday\n",
    "reg_fri_minis = fri_activities.loc[fri_activities['Session']=='Mini-seminar'].merge(fri_talks.loc[fri_talks['type']=='miniseminar'], how=\"cross\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Saturday - note that everyone who has the morning minisemiars also has the afternoon ones, so we don't need to keep both rows and can just link each person once to the four talks\n",
    "reg_sat_minis = sat_activities.loc[sat_activities['Agenda Item Name']=='Saturday Afternoon Mini-Seminars'].merge(sat_talks.loc[sat_talks['type']=='miniseminars'], how=\"cross\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Okay last thing before change is to combine the 'designation' and 'speaker' information into a 'publisher' column.\n",
    "reg_fri_minis['publisher'] = reg_fri_minis['designation'] + \", \" + reg_fri_minis['speaker'] + \", on '\" + reg_fri_minis['topic'] + \"'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "reg_sat_minis['publisher'] = reg_sat_minis['designation'] + \", \" + reg_sat_minis['speaker'] + \", on '\" + reg_sat_minis['topic'] + \"'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Now let's clean up both those datasets so they'll be ready to merge later\n",
    "reg_fri_minis = reg_fri_minis[['Email', 'First Name', 'Last Name', 'Session', 'virtual', 'phone', 'room_name', 'timeslot_start', 'timeslot_end', 'publisher']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "reg_sat_minis = reg_sat_minis[['Email', 'First Name', 'Last Name', 'Session', 'virtual', 'phone', 'room_name', 'timeslot_start', 'timeslot_end', 'publisher']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's do teh same thing for the workshop. Specifically, we want to merge the single workshop information with the participants in the workshops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "reg_workshop = fri_activities.loc[fri_activities['Agenda Item Name'].str.contains('Workshop')].merge(fri_talks.loc[fri_talks['type']=='Friday_workshop'], how=\"cross\")\n",
    "reg_workshop['publisher'] = reg_workshop['designation'] + \" \" + reg_workshop['speaker']\n",
    "reg_workshop = reg_workshop[['Email', 'First Name', 'Last Name', 'Session', 'virtual', 'phone', 'room_name', 'timeslot_start', 'timeslot_end', 'publisher']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Now let's remove those sessions from the friday and saturday activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "fri_activities = fri_activities.loc[~(fri_activities['Session'] =='Mini-seminar') & ~(fri_activities['Session'].str.contains('Workshop'))]\n",
    "sat_activities = sat_activities.loc[~(sat_activities['Session'] =='Mini-seminar')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now we need to clean up the fri_activities and sat_activities datasets so we can merge them with the other stuff for those days. Specifically, we need to add timeslot_start and timeslot_end to everything, as well as room_name. We'll leave 'publisher' blank for these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session\n",
      "Friday Night Mixer                       221\n",
      "Publisher Q&A panel                       92\n",
      "Selling your book(s) at the Book Fair     10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(fri_activities['Session'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add in the timeslot start and end times for everyone for the Friday and Saturday activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-51>:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "<positron-console-cell-51>:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    }
   ],
   "source": [
    "fri_activities['timeslot_start'] = fri_activities['Session'].replace(['Publisher Q&A panel', 'Friday Night Mixer', 'Selling your book(s) at the Book Fair'],\n",
    "                                                                    [pd.to_datetime(date_str_fri + ' 12:30'), pd.to_datetime(date_str_fri + ' 20:00'), pd.to_datetime(date_str_fri + ' 11:00')])\n",
    "\n",
    "fri_activities['timeslot_end'] = fri_activities['Session'].replace(['Publisher Q&A panel', 'Friday Night Mixer', 'Selling your book(s) at the Book Fair'],\n",
    "                                                                   [pd.to_datetime(date_str_fri + ' 1:30'), pd.to_datetime(date_str_fri + ' 23:00'), pd.to_datetime(date_str_fri + ' 16:00')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session\n",
      "Award Ceremony & Prize Giveaway    221\n",
      "Agent Q&A panel                     96\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(sat_activities['Session'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-53>:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "<positron-console-cell-53>:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    }
   ],
   "source": [
    "sat_activities['timeslot_start'] = sat_activities['Session'].replace(['Agent Q&A panel', 'Award Ceremony & Prize Giveaway'],\n",
    "                                                                   [pd.to_datetime(date_str_sat + ' 09:00'), pd.to_datetime(date_str_sat + ' 17:45')])\n",
    "sat_activities['timeslot_end'] = sat_activities['Session'].replace(['Agent Q&A panel', 'Award Ceremony & Prize Giveaway'],\n",
    "                                                                   [pd.to_datetime(date_str_sat + ' 10:00'), pd.to_datetime(date_str_sat + ' 18:30')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's add room info for these activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "fri_activities['room_name'] = fri_activities['Session'].replace(['Publisher Q&A panel', 'Friday Night Mixer', 'Selling your book(s) at the Book Fair'],\n",
    "                                                                    ['College Park Ballroom', 'Candler Room on the 1st floor near the restaurant', 'Peachtree City Ballroom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "sat_activities['room_name'] ='College Park Ballroom'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's add a 'publisher', which is really just going to be a description of these events for the template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "fri_activities['publisher'] = fri_activities['Session'].replace(['Publisher Q&A panel', 'Friday Night Mixer', 'Selling your book(s) at the Book Fair'],\n",
    "                                                                    ['', 'a cash bar, networking-bingo icebreaker and music', ''])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "sat_activities['publisher'] = sat_activities['Session'].replace(['Agent Q&A panel', 'Award Ceremony & Prize Giveaway'],\n",
    "                                                                   ['', 'prize giveaways followed by best manuscript and best pitch awards'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now we need to fix up the other datasets a teensy bit. Specifically, we need to add 'timeslot_end' to all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "final_friday_assignments2['timeslot_end'] = final_friday_assignments2['timeslot_start'] + pd.Timedelta(minutes=15)\n",
    "final_sataft_assignments2['timeslot_end'] = final_sataft_assignments2['timeslot_start'] + pd.Timedelta(minutes=15)\n",
    "final_satmorn_assignments2['timeslot_end'] = final_satmorn_assignments2['timeslot_start'] + pd.Timedelta(minutes=15)\n",
    "coaching_schedule['timeslot_end'] = coaching_schedule['timeslot_start'] + pd.Timedelta(minutes=15) # Note: for the participants, it's 15 minutes. For the actual schedule, there's a 2 minute break after this so the slots are 17 mins each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, next-to-last step is to combine everything into a single 'friday' and 'saturday' dataset with all their activities on these days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "keep_cols = ['Email', 'Session', 'room_name', 'timeslot_start', 'timeslot_end', 'publisher']\n",
    "\n",
    "coaching_schedule['Session'] = 'Author coaching'\n",
    "\n",
    "# Friday needs to combine the coaching sessions, the query letter critiques, the mini seminars, the workshop, and the friday night mixer\n",
    "all_friday = pd.merge(pd.merge(pd.merge(pd.merge(fri_activities[keep_cols], final_friday_assignments2[keep_cols], how=\"outer\"),\n",
    "                      coaching_schedule[keep_cols], how=\"outer\"), reg_workshop[keep_cols], how=\"outer\"), reg_fri_minis[keep_cols], how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Saturday needs to combine the Q&A panel, the mini seminars, the award ceremony, and people's pitches and MS critiques\n",
    "all_saturday = pd.merge(pd.merge(pd.merge(final_sataft_assignments2[keep_cols], final_satmorn_assignments2[keep_cols], how=\"outer\"), reg_sat_minis[keep_cols], how='outer'), sat_activities[keep_cols], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "registered['Virtual'] = registered['Virtual'].replace(['Virtually via Zoom (only available for query letter critiques, manuscript sample critiques, and pitches)', 'In person at the conference hotel'],\n",
    "                                                              ['Virtual', 'In person'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Merge both of these with the registered dataset to pull in 'First Name', 'Last Name', 'phone', 'virtual'\n",
    "all_friday2= pd.merge(all_friday, registered[['Email', 'First Name', 'Last Name', 'phone','Virtual']], how=\"left\", on=\"Email\").drop_duplicates()\n",
    "all_saturday2= pd.merge(all_saturday, registered[['Email', 'First Name', 'Last Name', 'phone','Virtual']], how=\"left\", on=\"Email\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the final step is to drop any virtual people from these lists, and keep only the relevant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "all_friday_inperson = all_friday2.loc[all_friday2['Virtual']=='In person']\n",
    "all_saturday_inperson = all_saturday2.loc[all_saturday2['Virtual']=='In person']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's drop it down to only the variables we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "all_friday_inperson = all_friday_inperson.loc[:, ['Email', 'First Name', 'Last Name', 'phone', 'Session', 'timeslot_start', 'timeslot_end', 'room_name', 'publisher']]\n",
    "all_saturday_inperson = all_saturday_inperson.loc[:, ['Email', 'First Name', 'Last Name', 'phone', 'Session', 'timeslot_start', 'timeslot_end', 'room_name', 'publisher']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, very last thing: we need to add in a row for the Book fair for everyone Friday, and add in lunch for everyone on saturday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "bookfair = all_friday_inperson.drop_duplicates(subset='Email', keep='first').copy()\n",
    "bookfair['Session'] = 'Book fair'\n",
    "bookfair['room_name'] = 'the atrium outside the Peachtree City Room'\n",
    "bookfair['timeslot_start'] = pd.to_datetime(date_str_fri + ' 11:00')\n",
    "bookfair['timeslot_end'] = pd.to_datetime(date_str_fri + ' 16:00')\n",
    "bookfair['publisher'] = 'published authors from the Atlanta Writers Club. Swing by to chat with them about their writing journey, hear more about their books, and buy signed copies.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "lunch = all_saturday_inperson.drop_duplicates(subset='Email', keep='first').copy()\n",
    "lunch['Session'] = \"Free time\"\n",
    "lunch['timeslot_start'] = pd.to_datetime(date_str_sat + ' 13:00')\n",
    "lunch['timeslot_end'] = pd.to_datetime(date_str_sat + ' 14:00')\n",
    "lunch['room_name'] = 'the hotel for lunch'\n",
    "lunch['publisher'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Add these back in\n",
    "all_friday_inperson2 = pd.merge(all_friday_inperson, bookfair, how=\"outer\")\n",
    "all_saturday_inperson2 = pd.merge(all_saturday_inperson, lunch, how=\"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! And now last step is to sort by person (aka email) and timeslot_start, so that everyone's rows are already ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "all_friday_inperson2= all_friday_inperson2.sort_values(['Email', 'timeslot_start'])\n",
    "all_saturday_inperson2= all_saturday_inperson2.sort_values(['Email', 'timeslot_start'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, and now last thing: we need to separate out the waitlist information by Friday vs Saturday, and ideally, sort by their waitlist ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#change the virtual status from In person and Virtual to 'TRUE' or 'FALSE'\n",
    "wait_all['virtual'] = wait_all['Email'].isin(virtual_only['Email'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "wait_fri = wait_all.loc[wait_all['Waitlisted Activity'].str.contains('uery|oach')].sort_values(['Email'])[['Email', 'Waitlisted Activity']] # Currently no Friday waitlists - don't include any book fairs, since those aren't applicable\n",
    "wait_sat = wait_all.loc[wait_all['Waitlisted Activity'].str.contains('Pitch')].sort_values(['Email'])[['Email', 'Waitlisted Activity']] # Only print out the pitch waitlists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Friday In-Person Schedules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I initially made it a bulleted list. However, that didn't format very nicely, so I tried a table code instead, which I think looks nicer. Below is for friday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Define the phone note:\n",
    "def phone_note(phone):\n",
    "    return f\"We have your phone number as {phone}. If this is not your number, please tell a check-in table volunteer so we can update it, as we send automated text reminders in advance of any meetings. **The text will show a 678 area code.**\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# If there are friday waitlists, merge that in\n",
    "if 'wait_fri' in locals() and not wait_fri.empty: # We only want to run this code IF the pitch_allrequests dataset exists\n",
    "    wait_fri2 = wait_fri[['Email', 'Waitlisted Activity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Let's sort all the participants alphabetically, so the print-outs are alphabetical.\n",
    "all_friday_inperson2 = all_friday_inperson2.sort_values(by=['Last Name', 'First Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a QR code\n",
    "import qrcode\n",
    "from io import BytesIO\n",
    "\n",
    "# Generate QR code once for all participants\n",
    "qr_img = qrcode.make(\"https://atlantawritersclub.org/donation\")  # Replace with your real URL\n",
    "qr_stream = BytesIO()\n",
    "qr_img.save(qr_stream, format='PNG')\n",
    "qr_stream.seek(0)  # Reset stream position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def create_word_doc_with_table(participant_df, waitlist_df):\n",
    "    # Create a single Word document for all participants\n",
    "    doc = Document()\n",
    "\n",
    "    # Set default styles for the document\n",
    "    styles = doc.styles\n",
    "\n",
    "    # Modify the Normal style for non-header text\n",
    "    normal_style = styles['Normal']\n",
    "    normal_style.font.name = 'Arial'\n",
    "    normal_style.font.size = Pt(12)\n",
    "\n",
    "    # Modify the default style for tables\n",
    "    table_style = styles.add_style('CustomTable', WD_STYLE_TYPE.TABLE)\n",
    "    table_style.font.name = 'Arial'\n",
    "    table_style.font.size = Pt(12)\n",
    "\n",
    "    # Merge the waitlist data with the participant session data (assuming there are any waitlists)\n",
    "    if waitlist_df is not None and not waitlist_df.empty:\n",
    "        merged_df = pd.merge(participant_df, waitlist_df, \n",
    "                            on='Email', how='left', indicator=True)\n",
    "    else:\n",
    "        merged_df = participant_df.copy()\n",
    "        merged_df['Waitlisted Activity'] = np.nan\n",
    "\n",
    "    first_participant = True  # To track the first participant and skip initial page break\n",
    "    initial_page_breaks = len(doc.element.xpath('//w:br[@w:type=\"page\"]')) # create the initial page break amount\n",
    "\n",
    "    flag_friday = [] # We'll do this to identify anyone whose schedule is more than 1 page\n",
    "    friday_processed = []  # Creating this list so we can easiliy identify all participants who were output in the word doc\n",
    "\n",
    "    for _, participant in participant_df.drop_duplicates(subset=['Email']).iterrows():\n",
    "\n",
    "        # Add participant's email to the processed list\n",
    "        friday_processed.append(participant['Email'])\n",
    "\n",
    "        if not first_participant:\n",
    "            doc.add_page_break()  # Start new page for subsequent participants\n",
    "        first_participant = False\n",
    "\n",
    "        # Add header with the participant's name\n",
    "        header = doc.add_heading(f\"{participant['First Name']} {participant['Last Name']}\", level=1)\n",
    "        header.alignment = 1  # Center alignment\n",
    "        for run in header.runs:\n",
    "            run.font.size = Pt(36)\n",
    "            run.font.name = 'Arial'\n",
    "            run.font.color.rgb = RGBColor(0, 0, 0)  # Set header to black\n",
    "\n",
    "        #doc.add_paragraph(\"\") # Add paragraph break to get more space\n",
    "\n",
    "        # Add session section header\n",
    "        session_header = doc.add_heading(f\"Schedule for Friday, {text_fri_date}:\", level=2)\n",
    "        for run in session_header.runs:\n",
    "            run.font.color.rgb = RGBColor(0, 0, 0)  # Set session header to black\n",
    "            run.font.name = 'Arial'\n",
    "            run.font.size = Pt(14)\n",
    "        session_header.alignment = 1 # center alignment\n",
    "\n",
    "        # Add paragraph break after session_header\n",
    "        small_break = doc.add_paragraph(\"\")\n",
    "\n",
    "        # Create a table for the schedule\n",
    "        table = doc.add_table(rows=0, cols=2)\n",
    "        table.autofit = False\n",
    "\n",
    "        # Set column widths manually\n",
    "        times_column_width = Inches(1.75) \n",
    "        details_column_width = Inches(5.5) \n",
    "\n",
    "        # Add rows to the table\n",
    "        include_phone_note = False\n",
    "\n",
    "        # Note that in the below, the merged_df has duplicated rows for any participants with waitlist spots (because we cross-merged). Let's delete those duplicate rows for this part\n",
    "        for _, session in merged_df[merged_df['Email'] == participant['Email']].drop_duplicates(subset=['Session', 'room_name', 'Email', 'publisher', 'timeslot_start', 'timeslot_end']).iterrows():\n",
    "\n",
    "            timeslot = f\"{session['timeslot_start'].strftime('%I:%M %p')} - {session['timeslot_end'].strftime('%I:%M %p')}\"\n",
    "            if session['publisher']:  # Check if the publisher exists and is not empty\n",
    "                details = f\"{session['Session']} in {session['room_name']} with {session['publisher']}\"\n",
    "            else:\n",
    "                details = f\"{session['Session']} in {session['room_name']}\"\n",
    "\n",
    "            row = table.add_row()\n",
    "            row.cells[0].text = timeslot\n",
    "            row.cells[1].text = details\n",
    "\n",
    "            # Apply widths to each added row as well\n",
    "            row.cells[0].width = times_column_width\n",
    "            row.cells[1].width = details_column_width \n",
    "\n",
    "            # Check if the session includes \"Query\" or \"Coaching\"\n",
    "            if 'Query' in session['Session'] or 'Coaching' in session['Session']:\n",
    "                include_phone_note = True\n",
    "\n",
    "        # Add waitlist information if applicable\n",
    "        if \"_merge\" in merged_df.columns:\n",
    "            waitlist_sessions = merged_df[(merged_df['Email'] == participant['Email']) & (merged_df['_merge'] == 'both')].drop_duplicates(subset=['Email'])\n",
    "            if not waitlist_sessions.empty:\n",
    "                waitlist_header = doc.add_paragraph(\"You're currently waitlisted for:\", style='Heading 3')\n",
    "                for run in waitlist_header.runs:\n",
    "                    run.font.color.rgb = RGBColor(0, 0, 0)  # Set waitlist header to black\n",
    "                    run.font.name = 'Arial'\n",
    "                    run.font.size = Pt(14)\n",
    "\n",
    "                for _, waitlist in waitlist_sessions.iterrows():\n",
    "                    waitlist_info = f\"{waitlist['Waitlisted Activity']}\"\n",
    "                    paragraph = doc.add_paragraph(waitlist_info, style='List Bullet')\n",
    "                    paragraph.paragraph_format.left_indent = Cm(2)  # Indent this a little bit\n",
    "        else:\n",
    "            waitlist_sessions = pd.DataFrame() # create an empty dataframe to prevent errors\n",
    "\n",
    "        # Add phone note and footer text if applicable\n",
    "        if include_phone_note:\n",
    "            note = doc.add_heading(\"Important note about your meeting(s):\", level=2)\n",
    "            for run in note.runs:\n",
    "                run.font.color.rgb = RGBColor(0, 0, 0)  # Set phone note header to black\n",
    "                run.font.name = 'Arial'\n",
    "                run.font.size = Pt(14)\n",
    "\n",
    "            doc.add_paragraph(phone_note(participant['phone']), style='Normal')\n",
    "\n",
    "            # Add italicized footer text\n",
    "            footer_text = doc.add_paragraph(\n",
    "                \"Please arrive 15 minutes early for any query letter critiques or coaching sessions.\"\n",
    "            )\n",
    "            footer_text.runs[0].italic = True  # Make the text italicized\n",
    "            footer_text.runs[0].bold = True  # Make the text italicized\n",
    "\n",
    "        # Track the final page break count\n",
    "        final_page_breaks = len(doc.element.xpath('//w:br[@w:type=\"page\"]'))\n",
    "\n",
    "        # If two or more page breaks were added during this participant's content, flag them\n",
    "        if (final_page_breaks - initial_page_breaks) >= 2:\n",
    "            flag_friday.append(f\"{participant['First Name']} {participant['Last Name']}\")\n",
    "\n",
    "    # Adjust document margins to fit all content on one page\n",
    "    section = doc.sections[0]\n",
    "    section.top_margin = Inches(0.25)\n",
    "    section.bottom_margin = Inches(0.25)\n",
    "    section.left_margin = Inches(0.5)\n",
    "    section.right_margin = Inches(0.5)\n",
    "\n",
    "    # Add QR code and caption to the footer ONCE\n",
    "    section = doc.sections[0]\n",
    "    footer = section.footer\n",
    "    footer_paragraph = footer.paragraphs[0]\n",
    "    footer_paragraph.alignment = WD_ALIGN_PARAGRAPH.RIGHT\n",
    "\n",
    "    # Add the QR image\n",
    "    run = footer_paragraph.add_run()\n",
    "    run.add_picture(qr_stream, width=Inches(1))\n",
    "    qr_stream.seek(0)\n",
    "\n",
    "    # Add the label below the QR code\n",
    "    footer_paragraph.add_run(\"\\nDonate to AWC\").font.size = Pt(10)\n",
    "\n",
    "    # Save the document\n",
    "    doc.save(f\"{current_conference_folder}/Outputs/Print-outs/Friday_In-person_participant_schedules.docx\")\n",
    "\n",
    "    friday_processed = pd.DataFrame(friday_processed, columns=[\"Email\"])\n",
    "    return(friday_processed)\n",
    "\n",
    "    # Let's also print out participants whose content went over a page\n",
    "    if flag_friday:\n",
    "        print(\"The following participants have schedules exceeding one page:\")\n",
    "        for name in flag_friday:\n",
    "            print(name)\n",
    "\n",
    "# Create the Word doc for each participant in the dataset (if wait_fri exists, then does first one; if not, does 2nd one)\n",
    "try:\n",
    "    processed_friday = create_word_doc_with_table(all_friday_inperson2, wait_fri)\n",
    "except NameError:\n",
    "    processed_friday = create_word_doc_with_table(all_friday_inperson2, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that we processed all the people we should have\n",
    "len(all_friday_inperson2.drop_duplicates(subset='Email', keep='first')) == len(processed_friday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! It processed everybody it should've :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saturday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now for **Saturday!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "all_saturday_inperson2 = all_saturday_inperson2.sort_values(by=['Last Name', 'First Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def create_word_doc_saturday(participant_df, waitlist_df):\n",
    "    # Create a single Word document for all participants\n",
    "    doc = Document()\n",
    "\n",
    "    # Set default styles for the document\n",
    "    styles = doc.styles\n",
    "\n",
    "    # Modify the Normal style for non-header text\n",
    "    normal_style = styles['Normal']\n",
    "    normal_style.font.name = 'Arial'\n",
    "    normal_style.font.size = Pt(12)\n",
    "\n",
    "    # Modify the default style for tables\n",
    "    table_style = styles.add_style('CustomTable', WD_STYLE_TYPE.TABLE)\n",
    "    table_style.font.name = 'Arial'\n",
    "    table_style.font.size = Pt(12)\n",
    "\n",
    "    # Merge the waitlist data with the participant session data (if there is any)\n",
    "    if waitlist_df is not None and not waitlist_df.empty:\n",
    "        merged_df = pd.merge(participant_df, waitlist_df, \n",
    "                            on='Email', how='left', indicator=True)\n",
    "    else:\n",
    "        merged_df = participant_df.copy()\n",
    "        merged_df['Waitlisted Activity'] = np.nan\n",
    "\n",
    "    first_participant = True  # To track the first participant and skip initial page break\n",
    "\n",
    "    flag_saturday = [] # We'll do this to identify anyone whose schedule is more than 1 page\n",
    "    initial_page_breaks = len(doc.element.xpath('//w:br[@w:type=\"page\"]')) # create the initial page break amount\n",
    "    saturday_processed = []  # Creating this list so we can easiliy identify all participants who were output in the word doc\n",
    "\n",
    "    for _, participant in participant_df.drop_duplicates(subset=['Email']).iterrows():\n",
    "\n",
    "        # Add participant's email to the processed list\n",
    "        saturday_processed.append(participant['Email'])\n",
    "\n",
    "        if not first_participant:\n",
    "            doc.add_page_break()  # Start new page for subsequent participants\n",
    "        first_participant = False\n",
    "\n",
    "        # Add header with the participant's name\n",
    "        header = doc.add_heading(f\"{participant['First Name']} {participant['Last Name']}\", level=1)\n",
    "        header.alignment = 1  # Center alignment\n",
    "        for run in header.runs:\n",
    "            run.font.size = Pt(28)\n",
    "            run.font.name = 'Arial'\n",
    "            run.font.color.rgb = RGBColor(0, 0, 0)  # Set header to black\n",
    "\n",
    "        #doc.add_paragraph(\"\") # Add paragraph break to get more space\n",
    "\n",
    "        # Add session section header\n",
    "        session_header = doc.add_heading(f\"Schedule for Saturday, {text_sat_date}:\", level=2)\n",
    "        for run in session_header.runs:\n",
    "            run.font.color.rgb = RGBColor(0, 0, 0)  # Set session header to black\n",
    "            run.font.name = 'Arial'\n",
    "            run.font.size = Pt(14)\n",
    "        session_header.alignment = 1 # center alignment\n",
    "\n",
    "        # Add paragraph break after session_header\n",
    "        doc.add_paragraph(\"\") # can't do this for Saturday because there's too much text\n",
    "\n",
    "        # Create a table for the schedule\n",
    "        table = doc.add_table(rows=0, cols=2)\n",
    "        table.autofit = False\n",
    "\n",
    "        # Set column widths manually\n",
    "        times_column_width = Inches(1.75) \n",
    "        details_column_width = Inches(5.5) \n",
    "\n",
    "        # Add rows to the table\n",
    "        include_phone_note = False\n",
    "        \n",
    "        # Note that in the below, the merged_df has duplicated rows for any participants with waitlist spots (because we cross-merged). Let's delete those duplicate rows for this part\n",
    "        for _, session in merged_df[merged_df['Email'] == participant['Email']].drop_duplicates(subset=['Session', 'room_name', 'Email', 'publisher', 'timeslot_start', 'timeslot_end']).iterrows():\n",
    "\n",
    "            timeslot = f\"{session['timeslot_start'].strftime('%I:%M %p')} - {session['timeslot_end'].strftime('%I:%M %p')}\"\n",
    "            if session['publisher']:  # Check if the publisher exists and is not empty\n",
    "                details = f\"{session['Session']} in {session['room_name']} with {session['publisher']}\"\n",
    "            else:\n",
    "                details = f\"{session['Session']} in {session['room_name']}\"\n",
    "\n",
    "            row = table.add_row()\n",
    "            row.cells[0].text = timeslot\n",
    "            row.cells[1].text = details\n",
    "\n",
    "            # Apply widths to each added row as well\n",
    "            row.cells[0].width = times_column_width\n",
    "            row.cells[1].width = details_column_width \n",
    "\n",
    "            # Check if the session includes \"Query\" or \"Coaching\"\n",
    "            if 'Pitch' in session['Session'] or 'Manuscript' in session['Session']:\n",
    "                include_phone_note = True\n",
    "\n",
    "        # Add waitlist information if applicable\n",
    "        if \"_merge\" in merged_df.columns:\n",
    "            waitlist_sessions = merged_df[(merged_df['Email'] == participant['Email']) & (merged_df['_merge'] == 'both')].drop_duplicates(subset=['Email'])\n",
    "            if not waitlist_sessions.empty:\n",
    "                waitlist_header = doc.add_paragraph(\"You're currently waitlisted for:\", style='Heading 3')\n",
    "                for run in waitlist_header.runs:\n",
    "                    run.font.color.rgb = RGBColor(0, 0, 0)  # Set waitlist header to black\n",
    "                    run.font.name = 'Arial'\n",
    "                    run.font.size = Pt(14)\n",
    "\n",
    "                for _, waitlist in waitlist_sessions.iterrows():\n",
    "                    waitlist_info = f\"{waitlist['Waitlisted Activity']}\"\n",
    "                    paragraph = doc.add_paragraph(waitlist_info, style='List Bullet')\n",
    "                    paragraph.paragraph_format.left_indent = Cm(2)  # Indent this a little bit\n",
    "        else:\n",
    "            waitlist_sessions = pd.DataFrame()\n",
    "\n",
    "        # Add phone note and footer text if applicable\n",
    "        if include_phone_note:\n",
    "            note = doc.add_heading(\"Important note about your meeting(s) today:\", level=2)\n",
    "            for run in note.runs:\n",
    "                run.font.color.rgb = RGBColor(0, 0, 0)  # Set phone note header to black\n",
    "                run.font.name = 'Arial'\n",
    "                run.font.size = Pt(14)\n",
    "\n",
    "            doc.add_paragraph(phone_note(participant['phone']), style='Normal')\n",
    "\n",
    "            # Add italicized footer text\n",
    "            footer_text = doc.add_paragraph(\n",
    "                \"Please arrive 15 minutes early for any manuscript critiques or pitches.\"\n",
    "            )\n",
    "            footer_text.runs[0].italic = True  # Make the text italicized\n",
    "            footer_text.runs[0].bold = True # Also make it bold\n",
    "\n",
    "        # Track the final page break count\n",
    "        final_page_breaks = len(doc.element.xpath('//w:br[@w:type=\"page\"]'))\n",
    "\n",
    "        # If two or more page breaks were added during this participant's content, flag them\n",
    "        if (final_page_breaks - initial_page_breaks) >= 2:\n",
    "            flag_saturday.append(f\"{participant['First Name']} {participant['Last Name']}\")\n",
    "\n",
    "\n",
    "    # Adjust document margins to fit all content on one page\n",
    "    section = doc.sections[0]\n",
    "    section.top_margin = Inches(0.25)\n",
    "    section.bottom_margin = Inches(0.25)\n",
    "    section.left_margin = Inches(0.5)\n",
    "    section.right_margin = Inches(0.5)\n",
    "\n",
    "    # Add QR code and caption to the footer ONCE\n",
    "    section = doc.sections[0]\n",
    "    footer = section.footer\n",
    "    footer_paragraph = footer.paragraphs[0]\n",
    "    footer_paragraph.alignment = WD_ALIGN_PARAGRAPH.RIGHT\n",
    "\n",
    "    # Add the QR image\n",
    "    run = footer_paragraph.add_run()\n",
    "    run.add_picture(qr_stream, width=Inches(1))\n",
    "    qr_stream.seek(0)\n",
    "\n",
    "    # Add the label below the QR code\n",
    "    footer_paragraph.add_run(\"\\nDonate to AWC\").font.size = Pt(10)\n",
    "\n",
    "    # Save the document\n",
    "    doc.save(f\"{current_conference_folder}/Outputs/Print-outs/Saturday_In-person_participant_schedules.docx\")\n",
    "\n",
    "    saturday_processed = pd.DataFrame(saturday_processed, columns=[\"Email\"])\n",
    "    return(saturday_processed)\n",
    "\n",
    "    # Let's also print out participants whose content went over a page\n",
    "    if flag_saturday:\n",
    "        print(\"The following participants have schedules exceeding one page:\")\n",
    "        for name in flag_saturday:\n",
    "            print(name)\n",
    "\n",
    "# Create the Word doc for each participant in the dataset\n",
    "try:\n",
    "    processed_saturday = create_word_doc_saturday(all_saturday_inperson2, wait_sat)\n",
    "except NameError:\n",
    "    processed_saturday = create_word_doc_saturday(all_saturday_inperson2, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's again double check that everyone was output who was supposed to be output:\n",
    "len(all_saturday_inperson2.drop_duplicates(subset='Email', keep='first')) == len(processed_saturday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, yay because nobody had more than 1 page!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "del(break_data, break_time, cell, context, doc, header_cells, location, output_dir, output_path, pairing, pairings_doc, paragraph, room, row_cells, run, section,\n",
    "    sections, table, tbl, tbl_borders, template_path, title, correct_row, create_word_doc, create_word_doc_for_day, create_word_doc_saturday, create_word_doc_with_table,\n",
    "    format_timeslot, generate_sat_schedule, generate_schedule, phone_note, \n",
    "    break_after, break_df, break_morn, bookfair, corrected_data, lunch, sat_after2, sat_morn2, sat_talks, row,\n",
    "    room_data, all_friday_inperson, all_saturday_inperson, fri_talks, friday_prints2, final_room_pairings_Friday, all_friday, all_saturday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waitlist Schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Pull out the waitlist #\n",
    "wait_all['Waitlist Number'] = wait_all['Waitlisted Activity'].str.extract(r'Waitlist\\s*#(\\d+)').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll create the waitlist printouts that go on the walls. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from docx.enum.table import WD_CELL_VERTICAL_ALIGNMENT\n",
    "\n",
    "def create_waitlist_document(wait_all):\n",
    "    \"\"\"\n",
    "    Creates a single Word document containing waitlist information for all sessions.\n",
    "    \"\"\"\n",
    "    doc = Document()\n",
    "\n",
    "    # Set default styles\n",
    "    styles = doc.styles\n",
    "    normal_style = styles['Normal']\n",
    "    normal_style.font.name = 'Arial'\n",
    "    normal_style.font.size = Pt(16)\n",
    "\n",
    "    table_style = styles.add_style('CustomTable', WD_STYLE_TYPE.TABLE)\n",
    "    table_style.font.name = 'Arial'\n",
    "    table_style.font.size = Pt(16)\n",
    "\n",
    "    # Add a header for the entire document\n",
    "    for section in doc.sections:\n",
    "        header = section.header\n",
    "        paragraph = header.paragraphs[0] if header.paragraphs else header.add_paragraph()\n",
    "        paragraph.text = \"Waitlist Order\"\n",
    "        paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "        run = paragraph.runs[0]\n",
    "        run.font.name = 'Arial'\n",
    "        run.font.size = Pt(20)\n",
    "\n",
    "    first_session = True  # Track first session for page breaks\n",
    "    sessions = wait_all['Session Name'].unique()\n",
    "\n",
    "    for session in sessions:\n",
    "        if not first_session:\n",
    "            doc.add_page_break()\n",
    "        first_session = False\n",
    "\n",
    "        doc.add_paragraph(\"\")  # Add space before header\n",
    "\n",
    "        # Add session header\n",
    "        header = doc.add_heading({session}, level=1)\n",
    "        header.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "        for run in header.runs:\n",
    "            run.font.size = Pt(24)\n",
    "            run.font.name = 'Arial'\n",
    "            run.font.color.rgb = RGBColor(0, 0, 0)\n",
    "\n",
    "        doc.add_paragraph(\"\")  # Add space after header\n",
    "\n",
    "        # Create table for waitlist\n",
    "        table = doc.add_table(rows=1, cols=3)\n",
    "        table.style = 'Table Grid'\n",
    "        table.autofit = False\n",
    "\n",
    "        # Set column widths manually\n",
    "        num_column_width = Inches(0.25)\n",
    "        name_column_width = Inches(3.5)\n",
    "        phone_column_width = Inches(2)\n",
    "\n",
    "        # Add header row to table\n",
    "        hdr_cells = table.rows[0].cells\n",
    "        hdr_cells[0].text = '#'\n",
    "        hdr_cells[1].text = 'Name'\n",
    "        hdr_cells[2].text = 'Phone'\n",
    "\n",
    "        # Set font for header row\n",
    "        for cell in hdr_cells:\n",
    "            cell.vertical_alignment = WD_CELL_VERTICAL_ALIGNMENT.CENTER # Vertically center header\n",
    "            for paragraph in cell.paragraphs:\n",
    "                for run in paragraph.runs:\n",
    "                    run.font.size = Pt(20)\n",
    "                    run.font.name = 'Arial'\n",
    "                    run.bold = True\n",
    "\n",
    "        # Get relevant data\n",
    "        session_data = wait_all[wait_all['Session Name'] == session]\n",
    "\n",
    "        # Fill up to 15 rows\n",
    "        for i in range(1, 16):\n",
    "            row = table.add_row()\n",
    "            cells = row.cells\n",
    "            cells[0].text = str(i)\n",
    "\n",
    "            # Find the person with this waitlist number\n",
    "            person = session_data[session_data['Waitlist Number'] == i]\n",
    "\n",
    "            if not person.empty:\n",
    "                full_name = f\"{person.iloc[0]['First Name']} {person.iloc[0]['Last Name']}\"\n",
    "                phone = person.iloc[0]['phone']\n",
    "            else:\n",
    "                full_name = \"\"\n",
    "                phone = \"\"\n",
    "\n",
    "            cells[1].text = full_name\n",
    "            cells[2].text = str(phone)\n",
    "\n",
    "            # Set font for each cell and set the column widths\n",
    "            cells[0].width = num_column_width\n",
    "            cells[1].width = name_column_width\n",
    "            cells[2].width = phone_column_width\n",
    "\n",
    "            for cell in cells:\n",
    "                cell.vertical_alignment = WD_CELL_VERTICAL_ALIGNMENT.CENTER # Vertically center cell content\n",
    "                for paragraph in cell.paragraphs:\n",
    "                    paragraph.paragraph_format.line_spacing = 1.5 # 1.5 spacing\n",
    "                    for run in paragraph.runs:\n",
    "                        run.font.size = Pt(16)\n",
    "                        run.font.name = 'Arial'\n",
    "\n",
    "    # Adjust document margins\n",
    "    section = doc.sections[0]\n",
    "    section.top_margin = Inches(0.5)\n",
    "    section.bottom_margin = Inches(0.5)\n",
    "    section.left_margin = Inches(0.75)\n",
    "    section.right_margin = Inches(0.75)\n",
    "\n",
    "    # Save the document\n",
    "    safe_session_name = \"All_Sessions_Waitlist\"\n",
    "    doc.save(f\"{current_conference_folder}/Outputs/Print-outs/{safe_session_name}.docx\")\n",
    "\n",
    "create_waitlist_document(wait_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TablesReady Export (for texts before meetings)\n",
    "\n",
    "We use TablesReady to schedule automated texts that'll arrive 15 minutes prior to a person's upcoming meeting.\n",
    "\n",
    "For TablesReady, we need to create a very specific csv file to import. It needs to have the following:\n",
    "\n",
    "* Date --> ex 10/1/2024\n",
    "* Time --> 6:30pm (no spaces!)\n",
    "* Name --> do first and last name\n",
    "* Size --> set this to 1 for everyone\n",
    "* Phone --> 10-digit code\n",
    "* Notes --> not necessarily needed, but will put the session tag that needs the reminder\n",
    "\n",
    "NOTE: We only send automated text reminders for the QLC, author coaching, manuscript critiques and pitches. This csv file should be restricted to those participants. We will also send it to both virtual and in-person people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "both_days = pd.merge(all_friday_inperson2, all_saturday_inperson2, how=\"outer\").drop_duplicates()\n",
    "\n",
    "# Keep only the rows with the 4 activities, and keep only certain columns\n",
    "both_days = both_days.loc[both_days['Session'].str.contains('Pitch|Critique|oach|Manuscript'), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "both_days['Name'] = both_days['First Name'] + \" \" + both_days['Last Name']\n",
    "both_days['Size'] = 1\n",
    "both_days['Notes'] = both_days['Session'] + \" with \" + both_days['publisher']\n",
    "both_days['Time'] = both_days['timeslot_start'].dt.strftime('%I:%M%p').str.lower()\n",
    "both_days['Date'] = both_days['timeslot_start'].dt.strftime(\"%m/%d/%Y\")\n",
    "both_days['Phone'] = both_days['phone']\n",
    "\n",
    "both_days = both_days[['Date', 'Time', 'Name', 'Size', 'Phone', 'Notes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date     False\n",
      "Time     False\n",
      "Name     False\n",
      "Size     False\n",
      "Phone    False\n",
      "Notes    False\n",
      "dtype: bool\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Filter out anyone with missing phones (if applicable)\n",
    "print(both_days.isnull().any()) #checks column-wise\n",
    "print(both_days.isnull().values.any()) #checks entire DataFrame\n",
    "\n",
    "both_days = both_days.dropna() # Doesn't drop anyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Now let's split up into the pitch-only one and the author, coaching and manuscript one\n",
    "tablesready_pitch = both_days.loc[both_days['Notes'].str.contains('Pitch')]\n",
    "tablesready_batch1 = both_days.loc[~both_days['Notes'].str.contains('Pitch')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Let's sort both of these by date and time\n",
    "tablesready_batch1 = tablesready_batch1.sort_values(by=['Date', 'Time', 'Notes'])\n",
    "tablesready_pitch = tablesready_pitch.sort_values(by=['Date', 'Time', 'Notes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Now print to a csv for upload\n",
    "tablesready_batch1.to_csv(f\"{current_conference_folder}/Outputs/For Mail Merge/Conference May 2025 Tablesready data - Batch 1 - {today}.csv\", index=False)\n",
    "tablesready_pitch.to_csv(f\"{current_conference_folder}/Outputs/For Mail Merge/Conference May 2025 Tablesready data - Batch 2 - {today}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nametags\n",
    "\n",
    "We need to create nametags for everyone! Unfortunately, I couldn't really figure this part out in terms of coding... So we'll just create an excel file with everyone (including waitlist only who will be in person), as well as info on if they're in the Friday workshop or not, so George can do this on his end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Create a nametags dataset that includes everyone who might be in person -  both waitlist-only and any registered people.\n",
    "nametags = pd.merge(wait_all.loc[~wait_all['Email'].isin(virtual_only['Email']), ['First Name', 'Last Name', 'Email']], pd.merge(all_friday_inperson2, all_saturday_inperson2, how=\"outer\"), how=\"outer\").drop_duplicates(subset='Email', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Identify everyone who is in the Friday workshop so we can add a black dot\n",
    "nametags['workshop'] = nametags['Email'].isin(fri_workshop['Email'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Create a single 'Name' field, and only keep that and the workshop thing\n",
    "nametags['Name'] = nametags['First Name'] + \" \" + nametags['Last Name']\n",
    "nametags =  nametags[['First Name', 'Last Name', 'workshop']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# We're gonna just print this out for George... Couldn't manage to get it to work for whatever reason\n",
    "nametags.to_excel(f\"{current_conference_folder}/Outputs/Rosters/Name tags for mail merge.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MailerLite Exports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so this is one is funkier. I tried originally making a single variable that was a list of items, but no matter what I tried, MailerLite will not display this nicely, so the only option is to export individual variables for everything that we need. So in this step, we're going to one giant dataset, for both virtual and in person people, and even including waitlist-only people, with EVERY activity (waitlisted and already paid). We will *exclude* any of the general stuff, like check-in, or the Friday night social, or the free mini-seminars.\n",
    "\n",
    "These are the following \"Fields\" (aka variables) we will create for upload into MailerLite:\n",
    "\n",
    "*General variables to enable email segments*:\n",
    "- Virtual (True/False) --> We'll use this in MailerLite to create our different email segments\n",
    "- Friday_Activities (True/False) --> Participants have registered activities on Friday. This field will have values even for the virtual people, but will **NOT** have values for the waitlist people.\n",
    "- Saturday_Activities (True/False) --> Participants have registered activities on Saturday. This field will have values even for the virtual people, but will **NOT** have values for the waitlist people.\n",
    "- Waitlisted (True/False) --> Participants with any waitlisted items. We'll use this to create a segment (when combined with 'No' above for Friday and Saturday activities) to identify participants who haven't paid for anything and who are ONLY on the waitlist.\n",
    "\n",
    "*Variables to capture scheduling stuff*:\n",
    "\n",
    "The below will appear as \"1:00pm - Pitch with Wendy Wong in Board Room I\", or \"Waitlist #1 - Pitch with Wendy Wong\"\n",
    "- ms1, ms2, ms3 --> Participants can have up to 3 manuscript critiques\n",
    "- wait_ms1, wait_ms2, wait_ms3 --> Participants can have up to 3 MS waitlist spots\n",
    "- pitch1, pitch2, pitch3 \n",
    "- wait_pitch1, wait_pitch2, wait_pitch3\n",
    "- qlc1, qlc2 --> Participants can only sign up for two query letter critiques\n",
    "- wait_qlc1, wait_qlc2 --> They can also only have two waitlist spots for this\n",
    "- coach1, coach2 --> Participants can only sign up for two coaching spots\n",
    "- wait_coach1, wait_coach2\n",
    "- workshop\n",
    "- QApanel_agent, QApanel_editor\n",
    "- bookfair (sellers)\n",
    "- Friday_mixer\n",
    "- Friday_minis (miniseminars) - True/False\n",
    "- Saturday_minis (miniseminars) - True/False\n",
    "- qlc_any, ms_any, pitch_any, coach_any - True/False\n",
    "\n",
    "This results in a total of 27 variables, plus we need to keep email, first and last name, and phone number. (The latter three just for posterity's sake - we likely won't import those fields into MailerLite).\n",
    "\n",
    "Once we have this massive datastep, the next step will be to import it into MailerLite by clicking 'Add Subscribers' and 'import using csv'. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Start with the dataset with ALL participants\n",
    "all_conf_unique_participants = all_participants.drop_duplicates(subset='Email', keep='first')\n",
    "all_conf_unique_participants = all_conf_unique_participants[['Email', 'First Name', 'Last Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "all_friday2['timeslot'] = all_friday2['timeslot_start'].dt.strftime('%I:%M %p') + \" - \" + all_friday2['timeslot_end'].dt.strftime('%I:%M %p')\n",
    "all_friday2['details'] = all_friday2.apply(lambda session: f\"{session['Session']} in {session['room_name']} with {session['publisher']}\" if session['publisher'] else f\"{session['Session']} in {session['room_name']}\", axis=1)\n",
    "all_friday2['output'] = all_friday2['timeslot'] + \": \" + all_friday2['details']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "all_conf_unique_participants = all_conf_unique_participants.merge(all_friday2.loc[all_friday2['Session'] == 'Workshop, \"Writer Beware: How Writers Can Protect Themselves\"', ['Email', 'output']], how='left').rename(columns={'output':'workshop'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Awesome, now we need to add each of these variables by session type into the dataset\n",
    "all_conf_unique_participants = all_conf_unique_participants.merge(all_friday2.loc[all_friday2['Session'] == \"Selling your book(s) at the Book Fair\", ['Email', 'Session', 'output']], how='left').rename(columns={'output': 'bookfair'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Create datasets with the people in the QA panels\n",
    "qapanel_editor = registered.loc[registered['Agenda Item Name'].str.contains('Publisher Q&A')]\n",
    "qapanel_agent = registered.loc[registered['Agenda Item Name'].str.contains('Agent Q&A')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Add in the different flag variables\n",
    "\n",
    "    # Virtual flag\n",
    "all_conf_unique_participants['virtual'] = all_conf_unique_participants['Email'].isin(virtual_only['Email'])\n",
    "\n",
    "    # If have any Friday activities (regardless if virtual or not -  but NOT set if they're waitlist only)\n",
    "all_conf_unique_participants['friday_activities'] = all_conf_unique_participants['Email'].isin(coaching_schedule['Email']) | all_conf_unique_participants['Email'].isin(final_friday_assignments2['Email']) | all_conf_unique_participants['bookfair'] | all_conf_unique_participants['Email'].isin(fri_workshop['Email']) | all_conf_unique_participants['Email'].isin(qapanel_editor['Email'])\n",
    "\n",
    "    # If have any saturday activities (regardless of if virtual or not - but NOT set if they're waitlist only)\n",
    "all_conf_unique_participants['saturday_activities'] = all_conf_unique_participants['Email'].isin(final_satmorn_assignments2['Email']) | all_conf_unique_participants['Email'].isin(final_sataft_assignments2['Email']) | all_conf_unique_participants['Email'].isin(qapanel_agent['Email'])\n",
    "\n",
    "    # Identify anyone with waitlist items\n",
    "all_conf_unique_participants['waitlisted'] = all_conf_unique_participants['Email'].isin(wait_all['Email'])\n",
    "\n",
    "    # Identify anyone with registered activities\n",
    "all_conf_unique_participants['registered'] = all_conf_unique_participants['Email'].isin(registered['Email'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "friday_activities  registered\n",
      "True               True          133\n",
      "False              True           88\n",
      "Name: count, dtype: int64\n",
      "saturday_activities  registered\n",
      "True                 True          189\n",
      "False                True           32\n",
      "Name: count, dtype: int64\n",
      "saturday_activities\n",
      "True     189\n",
      "False     32\n",
      "Name: count, dtype: int64\n",
      "saturday_activities  friday_activities\n",
      "True                 True                 109\n",
      "                     False                 80\n",
      "False                True                  24\n",
      "                     False                  8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Double check the friday and saturday stuff with registered\n",
    "print(all_conf_unique_participants[['friday_activities', 'registered']].value_counts())\n",
    "print(all_conf_unique_participants[['saturday_activities', 'registered']].value_counts())\n",
    "print(all_conf_unique_participants['saturday_activities'].value_counts())\n",
    "print(all_conf_unique_participants[['saturday_activities', 'friday_activities']].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Okay let's just double check this more precisely:\n",
    "any_friday_activities = registered.loc[registered['Agenda Item Name'].str.contains('Query|oaching|Fair|Publisher Q&A|Workshop'), ['Email', 'phone']].drop_duplicates()\n",
    "any_saturday_activities = registered.loc[registered['Agenda Item Name'].str.contains('Pitch|Manuscript|Agent Q&A'), ['Email', 'phone']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Okay cool cool - indeed, everyone who registered for Friday is also registered for Saturday.\n",
    "del(any_friday_activities, any_saturday_activities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Repeat for the publisher Q&A Panel\n",
    "all_conf_unique_participants = all_conf_unique_participants.merge(all_friday2.loc[all_friday2['Session'] == 'Publisher Q&A panel', ['Email', 'output']], how='left').rename(columns={'output':'QApanel_editor'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Repeat for the Friday night mixer\n",
    "all_conf_unique_participants = all_conf_unique_participants.merge(all_friday2.loc[all_friday2['Session'] == 'Friday Night Mixer', ['Email', 'output']], how='left').rename(columns={'output':'Friday_mixer'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session\n",
      "Mini-seminar                                                     444\n",
      "Friday Night Mixer                                               222\n",
      "Query Letter Critiques                                           108\n",
      "Publisher Q&A panel                                               92\n",
      "Workshop, \"Writer Beware: How Writers Can Protect Themselves\"     68\n",
      "Author coaching                                                   28\n",
      "Selling your book(s) at the Book Fair                             10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(all_friday2['Session'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Okay, we'll ignore the mini seminars (we'll automatically include those in the templates based on certain criteria). But now let's deal with the query critiques. People can have up to 2 of them\n",
    "all_conf_unique_participants = all_conf_unique_participants.merge(all_friday2.loc[all_friday2['Session'] == 'Query Letter Critiques', ['Email', 'output']].drop_duplicates(subset='Email', keep='first'), how='left').rename(columns={'output':'qlc1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "all_conf_unique_participants = all_conf_unique_participants.merge(all_friday2.loc[all_friday2['Session'] == 'Query Letter Critiques', ['Email', 'output']].drop_duplicates(subset='Email', keep='last'), how='left').rename(columns={'output':'qlc2'})\n",
    "# Now delete any qlc2 that equals qlc1\n",
    "all_conf_unique_participants.loc[all_conf_unique_participants['qlc2'] == all_conf_unique_participants['qlc1'], 'qlc2'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# We're gonna create a single a single flag for people with miniseminars\n",
    "all_conf_unique_participants['Friday_minis'] = all_conf_unique_participants['Email'].isin(reg_fri_minis['Email'])\n",
    "all_conf_unique_participants['Saturday_minis'] = all_conf_unique_participants['Email'].isin(reg_sat_minis['Email'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Create the coaching variables now\n",
    "all_conf_unique_participants = all_conf_unique_participants.merge(all_friday2.loc[all_friday2['Session'].str.contains('coach'), ['Email', 'output']].drop_duplicates(subset='Email', keep='first'), how='left').rename(columns={'output':'coach1'})\n",
    "all_conf_unique_participants = all_conf_unique_participants.merge(all_friday2.loc[all_friday2['Session'].str.contains('coach'), ['Email', 'output']].drop_duplicates(subset='Email', keep='last'), how='left').rename(columns={'output':'coach2'})\n",
    "all_conf_unique_participants.loc[all_conf_unique_participants['coach2'] == all_conf_unique_participants['coach1'], 'coach2'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's move on to adding in the saturday activities and info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "all_saturday2['timeslot'] = all_saturday2['timeslot_start'].dt.strftime('%I:%M %p') + \" - \" + all_saturday2['timeslot_end'].dt.strftime('%I:%M %p')\n",
    "all_saturday2['details'] = all_saturday2.apply(lambda session: f\"{session['Session']} in {session['room_name']} with {session['publisher']}\" if session['publisher'] else f\"{session['Session']} in {session['room_name']}\", axis=1)\n",
    "all_saturday2['output'] = all_saturday2['timeslot'] + \": \" + all_saturday2['details']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Code for the Agent Q&A\n",
    "all_conf_unique_participants = all_conf_unique_participants.merge(all_saturday2.loc[all_saturday2['Session'] == 'Agent Q&A panel', ['Email', 'output']], how='left').rename(columns={'output':'QApanel_agent'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "ms = all_saturday2.loc[all_saturday2['Session'] == 'Manuscript critique', ['Email', 'output']]\n",
    "\n",
    "# we need to pivot this table so we can get a dataset with one row per person and 3 variables\n",
    "ms['ms_index'] = ms.groupby('Email').cumcount() + 1  # This will create a 1, 2, 3 for each person\n",
    "\n",
    "# Pivot the data, creating separate columns for ms1, ms2, ms3\n",
    "pivoted_ms = ms.pivot_table(index='Email', columns='ms_index', values='output', aggfunc='first')\n",
    "\n",
    "# Rename columns to ms1, ms2, ms3\n",
    "pivoted_ms.columns = [f'ms{i}' for i in range(1, 4)]\n",
    "\n",
    "# Reset index to bring 'Email' as a column\n",
    "pivoted_ms = pivoted_ms.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Do the same for the pitches\n",
    "pitches = all_saturday2.loc[all_saturday2['Session'] == 'Pitch', ['Email', 'output']]\n",
    "\n",
    "# we need to pivot this table so we can get a dataset with one row per person and 3 variables\n",
    "pitches['pitch_index'] = pitches.groupby('Email').cumcount() + 1  # This will create a 1, 2, 3 for each person\n",
    "\n",
    "# Pivot the data, creating separate columns for pitch1, pitch2, pitch3\n",
    "pivoted_pitch = pitches.pivot_table(index='Email', columns='pitch_index', values='output', aggfunc='first')\n",
    "\n",
    "# Rename columns to ms1, ms2, ms3\n",
    "pivoted_pitch.columns = [f'pitch{i}' for i in range(1, 4)]\n",
    "\n",
    "# Reset index to bring 'Email' as a column\n",
    "pivoted_pitch = pivoted_pitch.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-113>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<positron-console-cell-113>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Do the same for the waitlisted pitches\n",
    "wait_pitch = wait_all.loc[wait_all['Waitlisted Activity'].str.contains('Pitch')]\n",
    "wait_pitch['pitch_index'] = wait_pitch.groupby('Email').cumcount() + 1  # This will create a 1, 2, 3 for each person\n",
    "wait_pitch['Waitlisted Activity'] = wait_pitch['Waitlisted Activity'].str.replace(r'Pitch [ABC]', 'Pitch', regex=True)\n",
    "\n",
    "# Pivot the data, creating separate columns for pitch1, pitch2, pitch3\n",
    "pivoted_wait_pitch = wait_pitch.pivot_table(index='Email', columns='pitch_index', values='Waitlisted Activity', aggfunc='first')\n",
    "\n",
    "# Rename columns to ms1, ms2, ms3\n",
    "pivoted_wait_pitch.columns = [f'pitch{i}' for i in range(1, 4)]\n",
    "\n",
    "# Reset index to bring 'Email' as a column\n",
    "pivoted_wait_pitch = pivoted_wait_pitch.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-114>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<positron-console-cell-114>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Do the same for the waitlisted manuscripts\n",
    "wait_ms = wait_all.loc[wait_all['Waitlisted Activity'].str.contains('Manuscript')]\n",
    "wait_ms['ms_index'] = wait_ms.groupby('Email').cumcount() + 1  # This will create a 1, 2, 3 for each person\n",
    "wait_ms['Waitlisted Activity'] = wait_ms['Waitlisted Activity'].str.replace(r'Critique [ABC]', 'Critique', regex=True)\n",
    "\n",
    "# Pivot the data, creating separate columns for ms1, ms2, ms3\n",
    "pivoted_wait_ms = wait_ms.pivot_table(index='Email', columns='ms_index', values='Waitlisted Activity', aggfunc='first')\n",
    "\n",
    "# Rename columns to ms1, ms2, ms3\n",
    "pivoted_wait_ms.columns = [f'ms{i}' for i in range(1, 4)]\n",
    "\n",
    "# Reset index to bring 'Email' as a column\n",
    "pivoted_wait_ms = pivoted_wait_ms.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "wait_qlc = wait_all.loc[wait_all['Waitlisted Activity'].str.contains('Query')]\n",
    "wait_coach = wait_all.loc[wait_all['Waitlisted Activity'].str.contains('oach')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Do the coaching waitlists now\n",
    "all_conf_unique_participants = all_conf_unique_participants.merge(wait_coach[['Email', 'Waitlisted Activity']].drop_duplicates(subset='Email', keep='first'), how='left').rename(columns={'Waitlisted Activity':'wl_coach1'})\n",
    "all_conf_unique_participants = all_conf_unique_participants.merge(wait_coach[['Email', 'Waitlisted Activity']].drop_duplicates(subset='Email', keep='last'), how='left').rename(columns={'Waitlisted Activity':'wl_coach2'})\n",
    "all_conf_unique_participants.loc[all_conf_unique_participants['wl_coach2'] == all_conf_unique_participants['wl_coach1'], 'wl_coach2'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Now let's add all of these into the dataset\n",
    "all_conf_unique_participants = all_conf_unique_participants.merge(pivoted_ms, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "all_conf_unique_participants = all_conf_unique_participants.merge(pivoted_pitch, how='outer')\n",
    "all_conf_unique_participants = all_conf_unique_participants.merge(pivoted_wait_ms.rename(columns={'ms1':'wl_ms1', 'ms2':'wl_ms2', 'ms3':'wl_ms3'}), how='outer')\n",
    "all_conf_unique_participants = all_conf_unique_participants.merge(pivoted_wait_pitch.rename(columns={'pitch1':'wl_pitch1', 'pitch2':'wl_pitch2', 'pitch3':'wl_pitch3'}), how='outer')\n",
    "all_conf_unique_participants = all_conf_unique_participants.merge(wait_qlc[['Email','First Name', 'Last Name', 'virtual', 'Waitlisted Activity']].rename(columns={'Waitlisted Activity':'wl_qlc'}), how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Book fair waitlists\n",
    "wait_bookfair = wait_all.loc[wait_all['Waitlisted Activity'].str.contains('Book Fair')]\n",
    "\n",
    "all_conf_unique_participants = all_conf_unique_participants.merge(wait_bookfair[['Email', 'Waitlisted Activity']].drop_duplicates(subset='Email', keep='first'), how='left').rename(columns={'Waitlisted Activity':'wl_bookfair'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Very final thing: add in the phone\n",
    "all_conf_unique_participants = all_conf_unique_participants.merge(registered[['Email', 'phone']].drop_duplicates(), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# just in case there are waitlist only people who need phones brought in too, bring in that\n",
    "all_conf_unique_participants = all_conf_unique_participants.merge(wait_all[['Email', 'phone']].drop_duplicates(), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "timekeepers = pd.read_excel(f'{current_conference_folder}/List_of_genres_agents_editors.xlsx', sheet_name='timekeepers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Also need to add a few more true/false ones:\n",
    "all_conf_unique_participants['qlc_any'] = all_conf_unique_participants['Email'].isin(final_friday_assignments2['Email']) | all_conf_unique_participants['Email'].isin(wait_qlc['Email'])\n",
    "all_conf_unique_participants['ms_any'] = all_conf_unique_participants['Email'].isin(final_satmorn_assignments2['Email']) | all_conf_unique_participants['Email'].isin(wait_ms['Email'])\n",
    "all_conf_unique_participants['pitch_any'] = all_conf_unique_participants['Email'].isin(final_sataft_assignments2['Email']) | all_conf_unique_participants['Email'].isin(wait_pitch['Email'])\n",
    "all_conf_unique_participants['coach_any'] = all_conf_unique_participants['Email'].isin(coaching_schedule['Email']) | all_conf_unique_participants['Email'].isin(wait_coach['Email'])\n",
    "all_conf_unique_participants['timekeeper'] = all_conf_unique_participants['Email'].isin(timekeepers['Email'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Lastly, let's explicitly say which days of the conference they're attending\n",
    "all_conf_unique_participants['days_attending'] = all_conf_unique_participants.apply(\n",
    "    lambda row: 'Both' if row['friday_activities'] and row['saturday_activities']\n",
    "    else 'Friday' if row['friday_activities']\n",
    "    else 'Saturday' if row['saturday_activities']\n",
    "    else 'Waitlist only',\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_attending\n",
      "Both             109\n",
      "Saturday          83\n",
      "Friday            24\n",
      "Waitlist only      8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(all_conf_unique_participants['days_attending'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# lastly, drop Session from the output\n",
    "all_conf_unique_participants = all_conf_unique_participants.drop(columns=['Session'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Very last thing - we need to add in entirely blank rows for anyone who has since canceled their registration. We only want to keep email, phone, last and first name\n",
    "import glob\n",
    "files = glob.glob(f\"{current_conference_folder}/Outputs/Finalized datasets/Registered_cleaned*.xlsx\")\n",
    "\n",
    "dfs = []\n",
    "for file in files:\n",
    "    # Extract date from filename using regex\n",
    "    match = re.search(r'Registered_cleaned_(\\d{4}-\\d{2}-\\d{2})\\.xlsx', file)\n",
    "    if match:\n",
    "        file_date = datetime.datetime.strptime(match.group(1), \"%Y-%m-%d\")\n",
    "        df = pd.read_excel(file, dtype={'phone': str})\n",
    "        df['file_date'] = file_date\n",
    "        dfs.append(df)\n",
    "\n",
    "# Step 3: Combine all into a single DataFrame\n",
    "all_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Step 4: Keep only the most recent entry for each email\n",
    "# (Assumes column is called 'email', adjust if needed)\n",
    "latest_data = all_data.sort_values('file_date').drop_duplicates('Email', keep='last')\n",
    "\n",
    "# Step 5: Reset index and save the result\n",
    "latest_data = latest_data.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Now drop anyone who's in the all_conference_unique_participants\n",
    "latest_data = latest_data[~latest_data['Email'].isin(all_conf_unique_participants['Email'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#Merge these two people into the other dataset\n",
    "all_conf_unique_participants2 = pd.merge(all_conf_unique_participants, latest_data[['Email', 'phone', 'First Name', 'Last Name']], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-130>:3: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n"
     ]
    }
   ],
   "source": [
    "# Lastly, because MailerLite is super annoying and is making me feisty as heck because of all the problems it causes with Boolean values,\n",
    "# let's convert all TRUE/FALSE values to 'Yes' and 'No'.\n",
    "all_conf_unique_participants2 = all_conf_unique_participants2.applymap(lambda x: 'Yes' if x is True else ('No' if x is False else x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay!! We did it!! Now let's export this to a csv file, and then we're done and ready for upload into MailerLite!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "all_conf_unique_participants2.to_csv(f\"{current_conference_folder}/Outputs/For Mail Merge/MailerLite_update_all_custom_fields_{today}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zoom Roster\n",
    "\n",
    "Kim needs this to be able to see who should have zoom meetings when, so she can let them in from the breakrooms to their particular meetings. This only applies to virtual-only people receiving author coaching, QLC, manuscript critique, or pitch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "zoompeeps = pd.merge(all_friday2.loc[all_friday2['Session'].str.contains('Critique|Author'), ['Email', 'First Name', 'Last Name', 'phone', 'Virtual', 'timeslot_start', 'Session', 'publisher']], \n",
    "                    all_saturday2.loc[all_saturday2['Session'].str.contains('Manuscript|Pitch'), ['Email', 'First Name', 'Last Name', 'phone', 'Virtual', 'timeslot_start', 'Session', 'publisher']], \n",
    "                    how=\"outer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the below isn't necessary, even if we have publishers who are virtual. There will be computers in those rooms, and the publisher will already be on it, and the room's timekeeper will manage entry into the actual zoom meeting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Look for anyone who has 'VIRTUAL' in their publisher name\n",
    "zoompeeps = zoompeeps.loc[(zoompeeps['Virtual']=='Virtual'), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Order by timeslot (which is a date-time variable)\n",
    "zoompeeps = zoompeeps.sort_values(by=\"timeslot_start\")\n",
    "zoompeeps['Date'] = zoompeeps['timeslot_start'].dt.strftime(\"%m/%d/%Y\")\n",
    "zoompeeps['Time'] = zoompeeps['timeslot_start'].dt.strftime('%I:%M%p').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Print to excel file for Kim\n",
    "zoompeeps[['Email', 'First Name', 'Last Name', 'phone', 'Date', 'Time', 'Session', 'publisher']].to_excel(f\"{current_conference_folder}/Outputs/Rosters/Roster of Zoom meetings for Kim.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conference Roster\n",
    "\n",
    "We want one ginormous excel file with a row for every single activity, alphabetically sorted by person, then date/time. A person will have as many rows as they have activities.\n",
    "\n",
    "* First and Last Name\n",
    "* Cell # (phone)\n",
    "* Locale (Hotel vs ZOOM)\n",
    "* Conference Activity ('output)\n",
    "\n",
    "Make sure to remove any duplicate rows (e.g., mini seminars stuff maybe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Add a virtual variable to the waitlist dataset\n",
    "wait_all['Virtual'] = wait_all['Email'].apply(\n",
    "    lambda email: 'Virtual' if email in virtual_only['Email'] else 'In Person'\n",
    ")\n",
    "\n",
    "wait_all['Session'] = wait_all['Waitlisted Activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Drop the MS critique waitlists (since those aren't applicable)\n",
    "wait_all = wait_all.loc[~wait_all['Waitlisted Activity'].str.contains('Manuscript')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-138>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# For the waitlits, ew need to extract the publisher(s) so we can link the waitlisted info with the rooms (when applicable)\n",
    "def extract_agent(activity):\n",
    "    if 'Pitch with' in activity:\n",
    "        return activity.split('Pitch with')[-1].strip()\n",
    "    return None\n",
    "\n",
    "# Apply to create new column in wait_all\n",
    "wait_all['lit_guest_name'] = wait_all['Waitlisted Activity'].apply(extract_agent)\n",
    "\n",
    "# Step 2: Merge with final_saturday_room to get room_name\n",
    "wait_all = wait_all.merge(final_saturday_rooms[['lit_guest_name', 'room_name']], \n",
    "                          on='lit_guest_name', \n",
    "                          how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "conf_roster = pd.merge(pd.merge(all_friday2[['Email', 'First Name', 'Last Name', 'phone', 'Virtual', 'Session', 'timeslot_start', 'publisher', 'room_name']], \n",
    "                        all_saturday2[['Email', 'First Name', 'Last Name', 'phone', 'Virtual', 'Session', 'timeslot_start', 'publisher', 'room_name']],\n",
    "                        how=\"outer\"), wait_all[['Email', 'First Name', 'Last Name', 'phone', 'Virtual', 'Session', 'room_name']], how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session\n",
      "Mini-seminar                                 1332\n",
      "Award Ceremony & Prize Giveaway               222\n",
      "Friday Night Mixer                            222\n",
      "Pitch                                         213\n",
      "Manuscript critique                           162\n",
      "                                             ... \n",
      "Waitlist #4 - Pitch with Wendy Wong             1\n",
      "Waitlist #2 - Pitch with Nicole Luongo          1\n",
      "Waitlist #8 - Query letter critique             1\n",
      "Waitlist #2 - Query letter critique             1\n",
      "Waitlist #2 - Pitch with Alexandria Brown       1\n",
      "Name: count, Length: 106, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(conf_roster['Session'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# We also need to drop any of the 'freebies\" -- CHECk THIS\n",
    "conf_roster = conf_roster.loc[~conf_roster['Session'].str.contains('Award|Mini-seminar|Mixer')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Change some of the variables\n",
    "conf_roster['Locale'] = conf_roster['Virtual'].apply(\n",
    "    lambda virt: 'ZOOM' if virt=='Virtual' else 'Hotel'\n",
    ")\n",
    "\n",
    "conf_roster['Cell #'] = conf_roster['phone']\n",
    "conf_roster['Room'] = conf_roster['room_name']\n",
    "\n",
    "conf_roster['Time'] = conf_roster['timeslot_start'].dt.strftime('%I:%M%p').str.lower()\n",
    "\n",
    "conf_roster['pub'] = conf_roster.apply(\n",
    "    lambda row: row['publisher'] if isinstance(row['Session'], str) and \n",
    "    ('Pitch' in row['Session'] or 'Manuscript' in row['Session'] or 'coach' in row['Session'] or 'Critique' in row['Session']) \n",
    "    else np.nan, axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def combine_variables(var1, var2, var3):\n",
    "    if pd.notna(var1) and pd.notna(var2) and pd.notna(var3):  # Check for NaN values\n",
    "        return f\"{var1} - {var2} @ {var3}\"\n",
    "    if pd.notna(var1) and pd.notna(var2) and pd.isna(var3) :  # Check for NaN values\n",
    "        return f\"{var1} - {var2}\"\n",
    "    return var1\n",
    "\n",
    "conf_roster['Conference Activity'] = conf_roster.apply(lambda row: combine_variables(row['Session'], row['pub'], row['Time']), axis=1)\n",
    "\n",
    "del combine_variables  # Delete function after use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Awesome! Now let's organize by person (last, then first) and the date/time of activity\n",
    "conf_roster = conf_roster.sort_values(by=['Last Name', 'First Name', 'timeslot_start'])\n",
    "conf_roster = conf_roster[['First Name', 'Last Name', 'Cell #',  'Locale' ,'Conference Activity', 'Room']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Rename the candler room one to just 'Candler Room'\n",
    "conf_roster['Room'] = conf_roster['Room'].replace('Candler Room on the 1st floor near the restaurant', 'Candler Room')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted Excel file saved as May2025/Outputs/Rosters/Conference Roster - to print.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Blank out 'First Name' and 'Last Name' except for the first occurrence of each person\n",
    "conf_roster.loc[conf_roster.duplicated(subset=['First Name', 'Last Name']), ['First Name', 'Last Name', 'Cell #', 'Locale']] = ''\n",
    "\n",
    "# Create a new Excel writer using openpyxl\n",
    "output_filename = f\"{current_conference_folder}/Outputs/Rosters/Conference Roster - to print.xlsx\"\n",
    "with pd.ExcelWriter(output_filename, engine='openpyxl') as writer:\n",
    "    conf_roster.to_excel(writer, index=False, sheet_name=\"Activities\")\n",
    "\n",
    "    # Load the workbook and worksheet\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets[\"Activities\"]\n",
    "\n",
    "    # Define styles\n",
    "    bold_font = Font(bold=True)\n",
    "    grey_font = Font(color=\"808080\")  # Dark grey color\n",
    "    thin_border = Border(left=Side(style=\"thin\", color=\"D3D3D3\"),\n",
    "                         right=Side(style=\"thin\", color=\"D3D3D3\"),\n",
    "                         top=Side(style=\"thin\", color=\"D3D3D3\"),\n",
    "                         bottom=Side(style=\"thin\", color=\"D3D3D3\"))\n",
    "\n",
    "    # Bold the headers\n",
    "    for cell in worksheet[1]:\n",
    "        cell.font = bold_font\n",
    "\n",
    "    # Bold 'First Name' and 'Last Name' and apply activity text color formatting\n",
    "    for row in worksheet.iter_rows(min_row=2, max_row=worksheet.max_row):\n",
    "        first_name_cell, last_name_cell, activity_cell = row[0], row[1], row[4]  # Adjust column indexes as needed\n",
    "        first_name_cell.font = bold_font\n",
    "        last_name_cell.font = bold_font\n",
    "\n",
    "        # Change activity text to grey if it doesn't contain specific words\n",
    "        if not any(word in str(activity_cell.value) for word in [\"Manuscript\", \"Pitch\", \"Critique\", \"Author\"]):\n",
    "            activity_cell.font = grey_font\n",
    "\n",
    "        # Apply borders to all cells\n",
    "        for cell in row:\n",
    "            cell.border = thin_border\n",
    "\n",
    "    # Apply borders to header row\n",
    "    for cell in worksheet[1]:\n",
    "        cell.border = thin_border\n",
    "\n",
    "     # Auto-adjust column widths accurately\n",
    "    for col_idx, col_cells in enumerate(worksheet.columns, start=1):\n",
    "        max_length = max(len(str(cell.value)) if cell.value else 0 for cell in col_cells)\n",
    "        adjusted_width = max_length * 1.2  # Scale factor for better accuracy in Excel\n",
    "        worksheet.column_dimensions[get_column_letter(col_idx)].width = adjusted_width\n",
    "\n",
    "    # Set print settings for landscape mode\n",
    "    worksheet.page_setup.orientation = \"landscape\"\n",
    "    worksheet.page_setup.fitToWidth = 1  # Fit to page width\n",
    "    worksheet.page_margins = PageMargins(left=0.5, right=0.5, top=0.5, bottom=0.5)  # Set margins\n",
    "\n",
    "    # Save the workbook\n",
    "    workbook.save(output_filename)\n",
    "\n",
    "print(f\"Formatted Excel file saved as {output_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "plaintext"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
