{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Participant and Room Schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to bring in all our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Make sure to load only the relevant files from the specific date we want\n",
    "run_date = '2025-02-13'\n",
    "\n",
    "final_room_pairings_Friday = pd.read_excel(f\"Outputs/Finalized datasets/Editor-agent pairings for Friday_{run_date}.xlsx\")\n",
    "final_saturday_rooms = pd.read_excel(f\"Outputs/Finalized datasets/Final saturday rooms_{run_date}.xlsx\")\n",
    "registered = pd.read_excel(f\"Outputs/Finalized Datasets/Registered_cleaned_{run_date}.xlsx\", dtype={'phone': str})\n",
    "\n",
    "# Schedules\n",
    "final_friday_assignments2 = pd.read_excel(f\"Outputs/Finalized datasets/Friday query letter critique assignments_{run_date}.xlsx\", dtype={'phone': str})\n",
    "final_sataft_assignments2 = pd.read_excel(f\"Outputs/Finalized datasets/Saturday pitch assignments_{run_date}.xlsx\", dtype={'phone': str})\n",
    "final_satmorn_assignments2 = pd.read_excel(f\"Outputs/Finalized datasets/Saturday manuscript critique assignments_{run_date}.xlsx\", dtype={'phone': str})\n",
    "coaching_schedule = pd.read_excel(f\"Outputs/Finalized datasets/Finalized coaching schedule_{run_date}.xlsx\", dtype={'phone': str})\n",
    "wait_all = pd.read_excel(f\"Outputs/Finalized Datasets/Waitlist participants.xlsx\", dtype={'phone': str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Publishers and Rooms on both days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Print-outs of all 9 rooms on Friday and their schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import docx\n",
    "from docx.shared import Pt, RGBColor\n",
    "from docx.oxml import OxmlElement\n",
    "from docx.shared import Inches\n",
    "\n",
    "# Create Word document for the publisher pairings and their rooms\n",
    "pairings_doc = docx.Document()\n",
    "\n",
    "# Add a header\n",
    "title = pairings_doc.add_heading('Friday Query Letter Critiques', level=1)\n",
    "title.alignment = 1  # Center align\n",
    "for run in title.runs:\n",
    "    run.font.size = Pt(20)\n",
    "    run.font.name = 'Arial'\n",
    "\n",
    "# Add the second part of the header\n",
    "title2 = pairings_doc.add_heading('Publisher Pairings and Room Locations', level=2)\n",
    "title2.alignment = 1  # Center align\n",
    "for run in title2.runs:\n",
    "    run.font.size = Pt(16)\n",
    "    run.font.name = 'Arial'\n",
    "\n",
    "# Add a line break - the title was too close to the table\n",
    "pairings_doc.add_paragraph(\"\")  # Adds an empty paragraph for spacing\n",
    "pairings_doc.add_paragraph(\"\")  # Adds an empty paragraph for spacing\n",
    "\n",
    "# Add a table\n",
    "table = pairings_doc.add_table(rows=1, cols=2)\n",
    "\n",
    "# Format the header row\n",
    "header_cells = table.rows[0].cells\n",
    "header_cells[0].text = \"Publishers\"\n",
    "header_cells[1].text = \"Room Location\"\n",
    "\n",
    "# Set header font style\n",
    "for cell in header_cells:\n",
    "    for paragraph in cell.paragraphs:\n",
    "        for run in paragraph.runs:\n",
    "            run.font.size = Pt(16)\n",
    "            run.font.name = 'Arial'\n",
    "            run.font.bold = True  # Make the header text bold\n",
    "            run.font.color.rgb = RGBColor(0, 0, 0)  # Black text\n",
    "\n",
    "# Adjust column widths (the publisher pairings column needs more space)\n",
    "table.columns[0].width = Inches(4.5)  # Pairing column\n",
    "table.columns[1].width = Inches(1.5)  # Location column\n",
    "\n",
    "# Add rows to the table\n",
    "for _, row in final_room_pairings_Friday.iterrows():\n",
    "    pairing = f\"{row['pubname1']} & {row['pubname2']}\"\n",
    "    location = row['room_name']\n",
    "    row_cells = table.add_row().cells\n",
    "    row_cells[0].text = pairing\n",
    "    row_cells[1].text = location\n",
    "    for cell in row_cells:\n",
    "        for paragraph in cell.paragraphs:\n",
    "            run = paragraph.runs[0]\n",
    "            run.font.size = Pt(16)\n",
    "            run.font.name = \"Arial\"\n",
    "\n",
    "# Remove table borders\n",
    "tbl = table._element\n",
    "tbl_borders = tbl.xpath(\".//w:tblBorders\")\n",
    "for border in tbl_borders:\n",
    "    border.getparent().remove(border)\n",
    "\n",
    "# Save the Word document\n",
    "pairings_doc.save(\"Outputs/Print-outs/Friday-pairings_and_rooms.docx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Now onto...\n",
    "\n",
    "2) Saturday Rooms Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "del(cell, pairing, location, pairings_doc, row_cells, run, title, title2)\n",
    "\n",
    "# Create Word document for the publisher pairings and their rooms\n",
    "pairings_doc = docx.Document()\n",
    "\n",
    "# Change the margins\n",
    "sections = pairings_doc.sections\n",
    "for section in sections:\n",
    "    section.top_margin = Inches(0.5)\n",
    "\n",
    "# Add a header\n",
    "title = pairings_doc.add_heading('Saturday Publishers and Room Locations', level=1)\n",
    "title.alignment = 1  # Center align\n",
    "for run in title.runs:\n",
    "    run.font.size = Pt(20)\n",
    "    run.font.name = 'Arial'\n",
    "\n",
    "# Add a line break - the title was too close to the table\n",
    "pairings_doc.add_paragraph(\"\")  # Adds an empty paragraph for spacing\n",
    "\n",
    "# Add a table\n",
    "table = pairings_doc.add_table(rows=1, cols=2)\n",
    "\n",
    "# Format the header row\n",
    "header_cells = table.rows[0].cells\n",
    "header_cells[0].text = \"Publishers\"\n",
    "header_cells[1].text = \"Room Location\"\n",
    "\n",
    "# Set header font style\n",
    "for cell in header_cells:\n",
    "    for paragraph in cell.paragraphs:\n",
    "        for run in paragraph.runs:\n",
    "            run.font.size = Pt(16)\n",
    "            run.font.name = 'Arial'\n",
    "            run.font.bold = True  # Make the header text bold\n",
    "            run.font.color.rgb = RGBColor(0, 0, 0)  # Black text\n",
    "\n",
    "# Adjust column widths (the publisher pairings column needs more space)\n",
    "table.columns[0].width = Inches(4)  # Pairing column\n",
    "table.columns[1].width = Inches(2)  # Location column\n",
    "\n",
    "# Add rows to the table\n",
    "for _, row in final_saturday_rooms.iterrows():\n",
    "    pairing = row['lit_guest_name']\n",
    "    location = row['room_name']\n",
    "    row_cells = table.add_row().cells\n",
    "    row_cells[0].text = pairing\n",
    "    row_cells[1].text = location\n",
    "    for cell in row_cells:\n",
    "        for paragraph in cell.paragraphs:\n",
    "            run = paragraph.runs[0]\n",
    "            run.font.size = Pt(16)\n",
    "            run.font.name = \"Arial\"\n",
    "\n",
    "# Remove table borders\n",
    "#tbl = table._element\n",
    "#tbl_borders = tbl.xpath(\".//w:tblBorders\")\n",
    "#for border in tbl_borders:\n",
    "#    border.getparent().remove(border)\n",
    "\n",
    "# Save the Word document\n",
    "pairings_doc.save(\"Outputs/Print-outs/Saturday-Publishers_and_rooms.docx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Schedules for each individual room on Friday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now create the word docs (iteratively) with the schedules for each of the rooms. First, we need to add a column that is the start-end time, and we also need to add a row that says 'break' at 3:15-3:30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Create the break timeslot at 3:15\n",
    "break_time = pd.Timestamp('2025-05-02 15:15:00')\n",
    "\n",
    "# Create a dataset with it (should have 9 rows)\n",
    "break_data = {\n",
    "    'timeslot_start': [break_time] * len(final_friday_assignments2['room_name'].unique()),  # Create a break for each room\n",
    "    'room_name': final_friday_assignments2['room_name'].unique(),  # Each room gets the break\n",
    "    'First Name': ['BREAK'] * len(final_friday_assignments2['room_name'].unique()),  # 'Break' for all participants at the break slot\n",
    "}\n",
    "\n",
    "break_df = pd.DataFrame(break_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Append it to the friday_prints\n",
    "friday_prints2 = pd.concat([final_friday_assignments2, break_df], ignore_index=True).sort_values(by=['room_name', 'timeslot_start'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "# Function to format time slots\n",
    "def format_timeslot(ts):\n",
    "    start_time = ts.strftime('%I:%M').lstrip('0')  # Remove leading zero for hours\n",
    "    end_time = (ts + timedelta(minutes=15)).strftime('%I:%M').lstrip('0')  # Add 15 minutes\n",
    "    return f'{start_time}-{end_time}'\n",
    "\n",
    "friday_prints2['formatted_timeslot'] = friday_prints2['timeslot_start'].apply(format_timeslot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Sort by room, then timeslot\n",
    "friday_prints2 = friday_prints2.sort_values(by=['room_name', 'timeslot_start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def create_word_doc(room_df):\n",
    "    for room, room_data in room_df.groupby('room_name'):\n",
    "        doc = docx.Document()\n",
    "\n",
    "        # Get the first valid row for publishers, excluding the break row\n",
    "        room_data_no_break = room_data[room_data['First Name'] != 'BREAK']\n",
    "        pubname1 = room_data_no_break['pubname1'].iloc[0]  # First valid publisher\n",
    "        pubname2 = room_data_no_break['pubname2'].iloc[0]  # First valid publisher\n",
    " \n",
    "        # Room header\n",
    "        title = doc.add_heading(f\"{room}\", level=1)\n",
    "        title.alignment = 1  # Center align\n",
    "        for run in title.runs:\n",
    "            run.font.size = Pt(20)\n",
    "            run.font.name = 'Arial'\n",
    "\n",
    "        title.runs[0].font.color.rgb = RGBColor(0, 0, 0)  # RGB for black\n",
    "\n",
    "        title.paragraph_format.space_after = 0  # Remove space after header\n",
    "        title.paragraph_format.space_before = 0  # Remove space before header\n",
    "      \n",
    "\n",
    "        # Add subheader \n",
    "        title2 = doc.add_heading(\"Query Letter Critique\", level=2)\n",
    "        doc.add_paragraph(\"\")  # Adds an empty paragraph for spacing\n",
    "        title2.runs[0].font.color.rgb = RGBColor(0, 0, 0)  # RGB for black\n",
    "\n",
    "        title3 = doc.add_heading(f\"{pubname1} and {pubname2}\", level=1) # Print out the publishers assigned to that room\n",
    "        #title2.paragraph_format.space_after = 0  # Remove space after header\n",
    "        title2.paragraph_format.space_before = 0  # Remove space before header\n",
    "        title3.paragraph_format.space_after = 0  # Remove space after header\n",
    "        title3.paragraph_format.space_before = 0  # Remove space before header\n",
    "      \n",
    "        title2.alignment = 1  # Center align\n",
    "        for run in title2.runs:\n",
    "            run.font.size = Pt(16)\n",
    "            run.font.name = 'Arial'\n",
    "\n",
    "        title3.alignment = 1  # Center align\n",
    "        for run in title3.runs:\n",
    "            run.font.size = Pt(20)\n",
    "            run.font.name = 'Arial'\n",
    "\n",
    "        title3.runs[0].font.color.rgb = RGBColor(0, 0, 0)  # RGB for black\n",
    "\n",
    "\n",
    "        # Add a line break - the title was too close to the table\n",
    "        doc.add_paragraph(\"\")  # Adds an empty paragraph for spacing\n",
    "\n",
    "        # Iterate over the timeslots and participants\n",
    "        for _, row in room_data.iterrows():\n",
    "            time_slot = row['formatted_timeslot']\n",
    "\n",
    "            if pd.isna(row['Last Name']):  \n",
    "                full_name = \"BREAK\"\n",
    "                para = doc.add_paragraph(f\"{time_slot}\\t\\t{full_name}\")\n",
    "                para.runs[0].bold = True  # Make \"Break\" bold\n",
    "            else:\n",
    "                full_name = f\"{row['First Name']} {row['Last Name']}\"\n",
    "\n",
    "                # Add (ZOOM) if they're virtual\n",
    "                if row['virtual'] == 'Virtual':  # Add (ZOOM) if virtual\n",
    "                    full_name += \" (ZOOM)\"\n",
    "                para = doc.add_paragraph(f\"{time_slot}\\t\\t{full_name}\")\n",
    "            \n",
    "            # Set the font size and font family\n",
    "            run = para.runs[0]\n",
    "            run.font.size = Pt(16)\n",
    "            run.font.name = 'Arial'\n",
    "        \n",
    "        # Save the document with the room name as filename\n",
    "        doc.save(f\"Outputs/Print-outs/Friday_{room}_meeting_schedule.docx\")\n",
    "\n",
    "# Generate documents\n",
    "for room, room_data in friday_prints2.groupby('room_name'):\n",
    "    create_word_doc(friday_prints2[friday_prints2['room_name'] == room])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Create the break timeslot at 3:15\n",
    "break_time = pd.Timestamp('2025-05-03 11:30:00')\n",
    "\n",
    "# Create a dataset with it (should have 9 rows)\n",
    "break_data = {\n",
    "    'timeslot_start': [break_time] * len(final_satmorn_assignments2['room_name'].unique()),  # Create a break for each room\n",
    "    'room_name': final_satmorn_assignments2['room_name'].unique(),  # Each room gets the break\n",
    "    'First Name': ['BREAK'] * len(final_satmorn_assignments2['room_name'].unique()),  # 'Break' for all participants at the break slot\n",
    "}\n",
    "\n",
    "break_morn = pd.DataFrame(break_data)\n",
    "\n",
    "# Create the break timeslot at 3:15\n",
    "break_time = pd.Timestamp('2025-05-03 15:45:00')\n",
    "\n",
    "# Create a dataset with it (should have 9 rows)\n",
    "break_data = {\n",
    "    'timeslot_start': [break_time] * len(final_sataft_assignments2['room_name'].unique()),  # Create a break for each room\n",
    "    'room_name': final_sataft_assignments2['room_name'].unique(),  # Each room gets the break\n",
    "    'First Name': ['BREAK'] * len(final_sataft_assignments2['room_name'].unique()),  # 'Break' for all participants at the break slot\n",
    "}\n",
    "\n",
    "break_after = pd.DataFrame(break_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Add these break times to their respective datasets and sort by the timeslots in each room\n",
    "sat_morn2 = pd.concat([final_satmorn_assignments2, break_morn], ignore_index=True).sort_values(by=['room_name', 'timeslot_start'])\n",
    "sat_after2 = pd.concat([final_sataft_assignments2, break_after], ignore_index=True).sort_values(by=['room_name', 'timeslot_start'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Lastly, format the time variables how we want them:\n",
    "sat_morn2['formatted_timeslot'] = sat_morn2['timeslot_start'].apply(format_timeslot)\n",
    "sat_after2['formatted_timeslot'] = sat_after2['timeslot_start'].apply(format_timeslot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's actually run the code to output the print-outs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def create_word_doc_for_day(morning_df, afternoon_df):\n",
    "    for room in morning_df['room_name'].unique():\n",
    "        doc = docx.Document()\n",
    "\n",
    "        # Room header (title with pubtype1 + room_name)\n",
    "        room_data_no_break = morning_df[morning_df['First Name'] != 'BREAK']\n",
    "        publisher = room_data_no_break['publisher'].iloc[0]  # First valid publisher\n",
    "\n",
    "        room_header = doc.add_heading(f\"{publisher} {room}\", level=1)\n",
    "        room_header.alignment = 1  # Center-align the header\n",
    "        room_header.paragraph_format.space_after = 0  # Remove space after header\n",
    "        room_header.paragraph_format.space_before = 0  # Remove space before header\n",
    "        run1 = room_header.runs[0]\n",
    "        run1.font.size = Pt(20)\n",
    "        run1.font.name = 'Arial'\n",
    "        run1.font.color.rgb = RGBColor(0, 0, 0)  # RGB for black\n",
    "\n",
    "        \n",
    "        # Add subheader \"Critique Schedule\"\n",
    "        title2 = doc.add_heading(\"Manuscript Critique Schedule\", level=2)\n",
    "        #doc.add_paragraph()  # Add paragraph break\n",
    "        run = title2.runs[0]\n",
    "        run.font.size = Pt(16)\n",
    "        run.font.name = 'Arial'\n",
    "        run.font.color.rgb = RGBColor(0, 0, 0)  # RGB for black\n",
    "\n",
    "        \n",
    "        # Add morning schedule (ms_data) and handle break times\n",
    "        morning_data = morning_df[morning_df['room_name'] == room]\n",
    "        for _, row in morning_data.iterrows():\n",
    "            time_slot = row['formatted_timeslot']\n",
    "            if time_slot == \"11:30-11:45\":  # Break time for morning session\n",
    "                full_name = \"BREAK\"\n",
    "                para = doc.add_paragraph(f\"{time_slot}\\t\\t{full_name}\")\n",
    "                para.runs[0].bold = True  # Make \"Break\" bold\n",
    "            else:\n",
    "                full_name = f\"{row['First Name']} {row['Last Name']}\"\n",
    "                if pd.isna(row['Last Name']):\n",
    "                    full_name = row['First Name']\n",
    "                if row['virtual'] == 'Virtual':  # Add (ZOOM) if virtual\n",
    "                    full_name += \" (ZOOM)\"\n",
    "                para = doc.add_paragraph(f\"{time_slot}\\t\\t{full_name}\")\n",
    "            \n",
    "            para.runs[0].font.size = Pt(16)\n",
    "            para.runs[0].font.name = 'Arial'\n",
    "            para.paragraph_format.space_after = 0  # Remove space after each paragraph\n",
    "            para.paragraph_format.space_before = 0  # Remove space before each paragraph\n",
    "       \n",
    "        \n",
    "        # Add paragraph break before \"Pitch Schedule\"\n",
    "        #doc.add_paragraph()  # Add paragraph break\n",
    "        \n",
    "        # Add subheader \"Pitch Schedule\"\n",
    "        title3 = doc.add_heading(\"Pitch Schedule\", level=2)\n",
    "        run2 = title3.runs[0]\n",
    "        run2.font.size = Pt(16)\n",
    "        run2.font.name = 'Arial'\n",
    "        run2.font.color.rgb = RGBColor(0, 0, 0)  # RGB for black\n",
    "\n",
    "\n",
    "        # Add afternoon schedule (pitch_data) and handle break times\n",
    "        afternoon_data = afternoon_df[afternoon_df['room_name'] == room]\n",
    "        for _, row in afternoon_data.iterrows():\n",
    "            time_slot = row['formatted_timeslot']\n",
    "            if time_slot == \"3:45-4:00\":  # Break time for afternoon session\n",
    "                full_name = \"BREAK\"\n",
    "                para = doc.add_paragraph(f\"{time_slot}\\t\\t\\t{full_name}\")\n",
    "                para.runs[0].bold = True  # Make \"Break\" bold\n",
    "            else:\n",
    "                full_name = f\"{row['First Name']} {row['Last Name']}\"\n",
    "                if pd.isna(row['Last Name']):\n",
    "                    full_name = row['First Name']\n",
    "                if row['virtual'] == 'Virtual':  # Add (ZOOM) if virtual\n",
    "                    full_name += \" (ZOOM)\"\n",
    "                para = doc.add_paragraph(f\"{time_slot}\\t\\t\\t{full_name}\")\n",
    "            \n",
    "            para.runs[0].font.size = Pt(16)\n",
    "            para.runs[0].font.name = 'Arial'\n",
    "            para.paragraph_format.space_after = 0  # Remove space after each paragraph\n",
    "            para.paragraph_format.space_before = 0  # Remove space before each paragraph\n",
    "\n",
    "        # Add footer with event info in blue and bold\n",
    "        section = doc.sections[-1]\n",
    "        footer = section.footer\n",
    "        footer_paragraph = footer.paragraphs[0]\n",
    "        footer_paragraph.text = \"Giveaway Drawings & Award Ceremony in College Park Ballroom at 5:50pm\"\n",
    "        footer_paragraph.runs[0].bold = True\n",
    "        footer_paragraph.runs[0].font.color.rgb = RGBColor(0, 0, 0)  # Set color to black\n",
    "\n",
    "        # Save the document with the room name as filename\n",
    "        doc.save(f\"Outputs/Print-outs/Saturday_{publisher}_{room}_meeting_schedule.docx\")\n",
    "\n",
    "# Example usage: assuming morning_df and afternoon_df are your datasets\n",
    "# Generate documents for each room\n",
    "for room in sat_morn2['room_name'].unique():\n",
    "    create_word_doc_for_day(sat_morn2, sat_after2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll 4) print out the individual agent and editor schedules for Friday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#pip install pandas python-docx docxtpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# We have templates for this particular one. Let's load the required packages\n",
    "import pandas as pd\n",
    "from docxtpl import DocxTemplate\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Fix the dataset so that all the pubname1s are editors, and all pubname2s are agents\n",
    "def correct_row(row):\n",
    "    if row['pubtype1'] == 'Agent' and row['pubtype2'] == 'Editor':\n",
    "        # Swap the names and types\n",
    "        row['pubname1'], row['pubname2'] = row['pubname2'], row['pubname1']\n",
    "        row['pubtype1'], row['pubtype2'] = row['pubtype2'], row['pubtype1']\n",
    "    return row\n",
    "\n",
    "# Apply the correction to all rows\n",
    "corrected_data = final_room_pairings_Friday.apply(correct_row, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the actual code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def generate_schedule(row, template_path, output_dir, pubtype):\n",
    "    doc = DocxTemplate(template_path)\n",
    "    context = {\n",
    "        \"pubname1\": row[\"pubname1\"],\n",
    "        \"pubname2\": row[\"pubname2\"],\n",
    "        \"pubtype1\": row[\"pubtype1\"],\n",
    "        \"pubtype2\": row[\"pubtype2\"],\n",
    "        \"room_name\": row[\"room_name\"]\n",
    "    }\n",
    "    if pubtype == 'Agents':\n",
    "        output_path = os.path.join(output_dir, f\"Friday_{row['pubname2']}_schedule.docx\")\n",
    "    if pubtype == \"Editors\":\n",
    "        output_path = os.path.join(output_dir, f\"Friday_{row['pubname1']}_schedule.docx\")\n",
    "\n",
    "    doc.render(context)\n",
    "    doc.save(output_path)\n",
    "\n",
    "# Specify output directory\n",
    "output_dir = \"Outputs/Print-outs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Generate schedules for editors\n",
    "for _, row in corrected_data.iterrows():\n",
    "    generate_schedule(row, \"Templates/Friday_editor_schedule.docx\", output_dir, \"Editors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Generate schedules for agents\n",
    "for _, row in corrected_data.iterrows():\n",
    "    generate_schedule(row, \"Templates/Friday_agent_schedule.docx\", output_dir, \"Agents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Now let's do it for Saturday (which is a little easier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def generate_sat_schedule(row, output_dir):\n",
    "\n",
    "    if row['lit_guest_type'] == 'Agent':\n",
    "        template_path = \"Templates/Saturday_agent_schedule.docx\"\n",
    "    else:\n",
    "        template_path = \"Templates/Saturday_editor_schedule.docx\"\n",
    "\n",
    "    doc = DocxTemplate(template_path)\n",
    "    \n",
    "    context = {\n",
    "        \"lit_guest_name\": row[\"lit_guest_name\"],\n",
    "        \"lit_guest_type\": row[\"lit_guest_type\"],\n",
    "        \"room_name\": row[\"room_name\"]\n",
    "    }\n",
    "\n",
    "    output_path = os.path.join(output_dir, f\"Saturday_{row['lit_guest_name']}_schedule.docx\")\n",
    "\n",
    "    doc.render(context)\n",
    "    doc.save(output_path)\n",
    "\n",
    "# Specify output directory\n",
    "output_dir = \"Outputs/Print-outs\"\n",
    "\n",
    "# Generate schedules\n",
    "for _, row in final_saturday_rooms.iterrows():\n",
    "    generate_sat_schedule(row, output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly for printouts, we need to print out the friday and saturday schedules for the College Park Ballroom (the miniseminars and workshops)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "fri_talks = pd.read_excel('List_of_genres_agents_editors.xlsx', sheet_name='minis_fri')\n",
    "sat_talks = pd.read_excel('List_of_genres_agents_editors.xlsx', sheet_name='minis_sat')\n",
    "\n",
    "# Set the conference dates\n",
    "date_str_fri = '2025-05-02'\n",
    "date_str_sat = '2025-05-03'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# We need to correct the timeslots to the correct dates and times for both\n",
    "fri_talks['timeslot_start'] = pd.to_datetime(date_str_fri + ' ' + fri_talks['timeslot_start'].astype(str))\n",
    "fri_talks['timeslot_end'] = pd.to_datetime(date_str_fri + ' ' + fri_talks['timeslot_end'].astype(str))\n",
    "\n",
    "# Adjust the times to represent the afternoon (add 12 hours if in AM range)\n",
    "fri_talks['timeslot_start'] = fri_talks['timeslot_start'].apply(\n",
    "    lambda x: x + pd.Timedelta(hours=12) if x.hour < 9 else x\n",
    ")\n",
    "fri_talks['timeslot_end'] = fri_talks['timeslot_end'].apply(\n",
    "    lambda x: x + pd.Timedelta(hours=12) if x.hour < 9 else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "sat_talks['timeslot_start'] = pd.to_datetime(date_str_sat + ' ' + sat_talks['timeslot_start'].astype(str))\n",
    "sat_talks['timeslot_end'] = pd.to_datetime(date_str_sat + ' ' + sat_talks['timeslot_end'].astype(str))\n",
    "\n",
    "# Adjust the times to represent the afternoon (add 12 hours if in AM range)\n",
    "sat_talks['timeslot_start'] = sat_talks['timeslot_start'].apply(\n",
    "    lambda x: x + pd.Timedelta(hours=12) if x.hour < 9 else x\n",
    ")\n",
    "sat_talks['timeslot_end'] = sat_talks['timeslot_end'].apply(\n",
    "    lambda x: x + pd.Timedelta(hours=12) if x.hour < 9 else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "template_path = \"Templates/Schedules for Posting - Friday Talks.docx\"  # Path to your Word template\n",
    "doc = DocxTemplate(template_path)\n",
    "\n",
    "# Create the context\n",
    "context = {\n",
    "    \"mini1\": fri_talks.loc[0, \"topic\"],\n",
    "    \"speaker\": fri_talks.loc[0, \"speaker\"],\n",
    "    \"designation\": fri_talks.loc[0, \"designation\"],\n",
    "    \"mini2\": fri_talks.loc[1, \"topic\"],\n",
    "    \"workshop\": fri_talks.loc[2, \"topic\"],\n",
    "}\n",
    "\n",
    "# Render the template with the context\n",
    "doc.render(context)\n",
    "\n",
    "# Save the populated document\n",
    "output_path = \"Outputs/Print-outs/Friday_Schedule_CollegeParkBallrooms.docx\"\n",
    "doc.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "template_path = \"Templates/Schedules for Posting - Saturday Talks.docx\"  # Path to your Word template\n",
    "doc = DocxTemplate(template_path)\n",
    "\n",
    "# Create the context\n",
    "context = {\n",
    "    \"mini1\": sat_talks.loc[0, \"topic\"],\n",
    "    \"mini2\": sat_talks.loc[1, \"topic\"],\n",
    "    \"mini3\": sat_talks.loc[2, \"topic\"],\n",
    "    \"mini4\": sat_talks.loc[3, \"topic\"],\n",
    "    \"speaker1\": sat_talks.loc[0, \"speaker\"],\n",
    "    \"designation1\": sat_talks.loc[0, \"designation\"],\n",
    "    \"speaker2\": sat_talks.loc[2, \"speaker\"],\n",
    "    \"designation2\": sat_talks.loc[2, \"designation\"],\n",
    "}\n",
    "\n",
    "# Render the template with the context\n",
    "doc.render(context)\n",
    "\n",
    "# Save the populated document\n",
    "output_path = \"Outputs/Print-outs/Saturday_Schedule_CollegeParkBallrooms.docx\"\n",
    "doc.save(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Participant Schedules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do anything, since we've already dealt with the manuscript critiques, pitches and query critiques, let's drop those rows from the registered dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "fri_workshop = registered[registered['Agenda Item Name']=='Friday Workshop- Writer Beware: How Writers Can Protect Themselves']\n",
    "\n",
    "import datetime\n",
    "\n",
    "directory = 'May2025_reports'\n",
    "most_recent_file = max(\n",
    "    (f for f in os.listdir(directory) if f.startswith('Allparticipants_') and f.endswith('.csv')),\n",
    "    key=lambda x: datetime.datetime.strptime(x.split('_')[1].split('.')[0], '%m-%d-%y'),\n",
    ")\n",
    "\n",
    "# Load the most recent file\n",
    "most_recent_path = os.path.join(directory, most_recent_file)\n",
    "all_participants = pd.read_csv(most_recent_path)\n",
    "del(most_recent_file, most_recent_path)\n",
    "\n",
    "all_participants = all_participants.rename(columns={'Email Address':'Email'})\n",
    "virtual_only = all_participants.loc[all_participants['Hotel vs. Zoom'] == 'Virtually via Zoom (only available for query letter critiques, manuscript sample critiques, and pitches)', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "registered2 = registered.loc[(~(registered['Agenda Item Name'].str.contains('Query Letter Critique')) & \n",
    "                             ~(registered['Agenda Item Name'].str.contains('Manuscript Critique')) &\n",
    "                             ~(registered['Agenda Item Name'].str.contains('Pitch [A-Z]'))), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also drop the pre-conference edits, since those have already happened prior to the event and is something George takes care of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "registered3= registered2.loc[(~(registered2['Agenda Item Name'].str.contains('Pre-conference Edit'))), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the 'Virtual' variable to match the 'virtual' variable found in our other datasets (which is formatted more nicely)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-31>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "registered3['virtual'] = registered3['Virtual'].replace(['Virtually via Zoom (only available for query letter critiques, manuscript sample critiques, and pitches)', 'In person at the conference hotel'],\n",
    "                                                              ['Virtual', 'In person'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, since this is for the schedules they'll be picking up at check-in, we can drop the check-in rows. (Also, now that we added the coaching activity, we need to drop that too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "registered3 = registered3.loc[~registered3['Agenda Item Name'].str.contains('Check-in|Coaching')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's separate out into Friday vs Saturday stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agenda Item Name\n",
      "Award Ceremony & Prize Giveaway                                       172\n",
      "Friday Mini-Seminars                                                  172\n",
      "Friday Night Mixer                                                    172\n",
      "Saturday Afternoon Mini-Seminars                                      172\n",
      "Saturday Morning Mini-Seminars                                        172\n",
      "Friday Publisher Q&A Panel                                             60\n",
      "Saturday Agent Q&A Panel                                               58\n",
      "Friday Workshop- Writer Beware: How Writers Can Protect Themselves     43\n",
      "Book Fair Book Selling                                                 10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(registered3['Agenda Item Name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "fri_activities = registered3.loc[(registered3['Agenda Item Name'].str.contains('Friday|Book')), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "sat_activities = registered3.loc[registered3['Agenda Item Name'].str.contains('Saturday|Award'), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome. Let's delete a few of these intermediate datasets and then move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "del(registered3, registered2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Virtual participants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thankfully, there's nothing to print for the virtual participants, so we can ignore them for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In person participants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to print each individual participant's schedules for Friday and Saturday, we need to merge together all our different datasets, but doing so separately for Friday vs Saturday. We're going to restrict these two datasets to people who are IN PERSON.\n",
    "\n",
    "**FRIDAY:**\n",
    "\n",
    "1) Merge the coaching and query letter stuff together, plus information about whether they're doing the workshop, Q&A panel, mini-seminars, or book fair, friday night social, as well as any waitlist information for those activities. Note that check-in is the same for everyone, so we don't need to include that. It'll be in the template. \n",
    "2) We'll filter this full dataset to only in person participants. It's okay to have multiple rows per participant. We just need to make sure the core variables are all named the same, such as 'Session', 'publisher', 'room_name', 'timeslot_start'.\n",
    "3) Once we have that, we'll work to compile it all and print it out to word using a template.\n",
    "\n",
    "**SATURDAY:**\n",
    "\n",
    "1) We'll merge the MS and pitch datasets together, along with the Q&A panel, the mini seminars, and the award ceremony. We'll also include any waitlists for those activities.\n",
    "2) We'll filter this to in person only, and make sure all the variables have the same names in this combined dataset so we can more easily compile it.\n",
    "3) We'll print it to word using a template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# We need to change the session names so they better match what we want to print. We'll call this new variable 'Session' to match the other datasets\n",
    "fri_activities['Session'] = fri_activities['Agenda Item Name'].replace(['Book Fair Book Selling', 'Friday Mini-Seminars', 'Friday Publisher Q&A Panel', 'Friday Workshop- Writer Beware: How Writers Can Protect Themselves'],\n",
    "                                                              ['Selling your book(s) at the Book Fair', 'Mini-seminar', 'Publisher Q&A panel', 'Workshop, \"Writer Beware: How Writers Can Protect Themselves\"'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** for the above: the Book fair people are SELLERS, not buyers. We will apply the book fair to people's schedules as part of the word doc code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "sat_activities['Session']=sat_activities['Agenda Item Name'].replace(['Saturday Afternoon Mini-Seminars', 'Saturday Morning Mini-Seminars', 'Saturday Agent Q&A Panel'],\n",
    "                                                                    ['Mini-seminar', 'Mini-seminar', 'Agent Q&A panel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to deal with the miniseminars. There's two, but in the data file it just shows one. For Friday and Saturday, let's identify anyone who's signed up for the mini-seminars and create a dataset with their rows for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Friday\n",
    "reg_fri_minis = fri_activities.loc[fri_activities['Session']=='Mini-seminar'].merge(fri_talks.loc[fri_talks['type']=='miniseminar'], how=\"cross\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Saturday - note that everyone who has the morning minisemiars also has the afternoon ones, so we don't need to keep both rows and can just link each person once to the four talks\n",
    "reg_sat_minis = sat_activities.loc[sat_activities['Agenda Item Name']=='Saturday Afternoon Mini-Seminars'].merge(sat_talks.loc[sat_talks['type']=='miniseminars'], how=\"cross\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Okay last thing before change is to combine the 'designation' and 'speaker' information into a 'publisher' column.\n",
    "reg_fri_minis['publisher'] = reg_fri_minis['designation'] + \", \" + reg_fri_minis['speaker'] + \", on '\" + reg_fri_minis['topic'] + \"'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "reg_sat_minis['publisher'] = reg_sat_minis['designation'] + \", \" + reg_sat_minis['speaker'] + \", on '\" + reg_sat_minis['topic'] + \"'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Now let's clean up both those datasets so they'll be ready to merge later\n",
    "reg_fri_minis = reg_fri_minis[['Email', 'First Name', 'Last Name', 'Session', 'virtual', 'phone', 'room_name', 'timeslot_start', 'timeslot_end', 'publisher']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "reg_sat_minis = reg_sat_minis[['Email', 'First Name', 'Last Name', 'Session', 'virtual', 'phone', 'room_name', 'timeslot_start', 'timeslot_end', 'publisher']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's do teh same thing for the workshop. Specifically, we want to merge the single workshop information with the participants in the workshops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "reg_workshop = fri_activities.loc[fri_activities['Agenda Item Name'].str.contains('Workshop')].merge(fri_talks.loc[fri_talks['type']=='Friday_workshop'], how=\"cross\")\n",
    "reg_workshop['publisher'] = reg_workshop['designation'] + \" \" + reg_workshop['speaker']\n",
    "reg_workshop = reg_workshop[['Email', 'First Name', 'Last Name', 'Session', 'virtual', 'phone', 'room_name', 'timeslot_start', 'timeslot_end', 'publisher']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Now let's remove those sessions from the friday and saturday activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "fri_activities = fri_activities.loc[~(fri_activities['Session'] =='Mini-seminar') & ~(fri_activities['Session'].str.contains('Workshop'))]\n",
    "sat_activities = sat_activities.loc[~(sat_activities['Session'] =='Mini-seminar')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now we need to clean up the fri_activities and sat_activities datasets so we can merge them with the other stuff for those days. Specifically, we need to add timeslot_start and timeslot_end to everything, as well as room_name. We'll leave 'publisher' blank for these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session\n",
      "Friday Night Mixer                       172\n",
      "Publisher Q&A panel                       60\n",
      "Selling your book(s) at the Book Fair     10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(fri_activities['Session'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add in the timeslot start and end times for everyone for the Friday and Saturday activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-48>:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "<positron-console-cell-48>:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    }
   ],
   "source": [
    "fri_activities['timeslot_start'] = fri_activities['Session'].replace(['Publisher Q&A panel', 'Friday Night Mixer', 'Selling your book(s) at the Book Fair'],\n",
    "                                                                    [pd.to_datetime(date_str_fri + ' 12:30'), pd.to_datetime(date_str_fri + ' 20:00'), pd.to_datetime(date_str_fri + ' 11:00')])\n",
    "\n",
    "fri_activities['timeslot_end'] = fri_activities['Session'].replace(['Publisher Q&A panel', 'Friday Night Mixer', 'Selling your book(s) at the Book Fair'],\n",
    "                                                                   [pd.to_datetime(date_str_fri + ' 1:30'), pd.to_datetime(date_str_fri + ' 23:00'), pd.to_datetime(date_str_fri + ' 16:00')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session\n",
      "Award Ceremony & Prize Giveaway    172\n",
      "Agent Q&A panel                     58\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(sat_activities['Session'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-50>:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "<positron-console-cell-50>:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    }
   ],
   "source": [
    "sat_activities['timeslot_start'] = sat_activities['Session'].replace(['Agent Q&A panel', 'Award Ceremony & Prize Giveaway'],\n",
    "                                                                   [pd.to_datetime(date_str_sat + ' 09:00'), pd.to_datetime(date_str_sat + ' 17:45')])\n",
    "sat_activities['timeslot_end'] = sat_activities['Session'].replace(['Agent Q&A panel', 'Award Ceremony & Prize Giveaway'],\n",
    "                                                                   [pd.to_datetime(date_str_sat + ' 10:00'), pd.to_datetime(date_str_sat + ' 18:30')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's add room info for these activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "fri_activities['room_name'] = fri_activities['Session'].replace(['Publisher Q&A panel', 'Friday Night Mixer', 'Selling your book(s) at the Book Fair'],\n",
    "                                                                    ['College Park Ballroom', 'Candler Room on the 1st floor near the restaurant', 'Peachtree City'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "sat_activities['room_name'] ='College Park Ballroom'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's add a 'publisher', which is really just going to be a description of these events for the template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "fri_activities['publisher'] = fri_activities['Session'].replace(['Publisher Q&A panel', 'Friday Night Mixer', 'Selling your book(s) at the Book Fair'],\n",
    "                                                                    ['', 'a cash bar, networking-bingo icebreaker and music', ''])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "sat_activities['publisher'] = sat_activities['Session'].replace(['Agent Q&A panel', 'Award Ceremony & Prize Giveaway'],\n",
    "                                                                   ['', 'prize giveaways, such as free lifetime Atlanta Writers Club memberships, followed by each agent and editor awarding certificates to participants for best manuscript sample submitted for critique and best pitch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now we need to fix up the other datasets a teensy bit. Specifically, we need to add 'timeslot_end' to all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "final_friday_assignments2['timeslot_end'] = final_friday_assignments2['timeslot_start'] + pd.Timedelta(minutes=15)\n",
    "final_sataft_assignments2['timeslot_end'] = final_sataft_assignments2['timeslot_start'] + pd.Timedelta(minutes=15)\n",
    "final_satmorn_assignments2['timeslot_end'] = final_satmorn_assignments2['timeslot_start'] + pd.Timedelta(minutes=15)\n",
    "coaching_schedule['timeslot_end'] = coaching_schedule['timeslot_start'] + pd.Timedelta(minutes=15) # Note: for the participants, it's 15 minutes. For the actual schedule, there's a 2 minute break after this so the slots are 17 mins each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, next-to-last step is to combine everything into a single 'friday' and 'saturday' dataset with all their activities on these days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Friday needs to combine the coaching sessions, the query letter critiques, the mini seminars, the workshop, and the friday night mixer\n",
    "all_friday = pd.merge(pd.merge(pd.merge(pd.merge(fri_activities, final_friday_assignments2, how=\"outer\"), \n",
    "                        coaching_schedule, how=\"outer\"), reg_workshop, how=\"outer\"), reg_fri_minis, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Saturday needs to combine the Q&A panel, the mini seminars, the award ceremony, and people's pitches and MS critiques\n",
    "all_saturday = pd.merge(pd.merge(pd.merge(final_sataft_assignments2, final_satmorn_assignments2, how=\"outer\"), reg_sat_minis, how='outer'), sat_activities, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the final step is to drop any virtual people from these lists, and keep only the relevant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "all_friday_inperson = all_friday.loc[all_friday['virtual']=='In person']\n",
    "all_saturday_inperson = all_saturday.loc[all_saturday['virtual']=='In person']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's drop it down to only the variables we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "all_friday_inperson = all_friday_inperson.loc[:, ['Email', 'First Name', 'Last Name', 'phone', 'Session', 'timeslot_start', 'timeslot_end', 'room_name', 'publisher']]\n",
    "all_saturday_inperson = all_saturday_inperson.loc[:, ['Email', 'First Name', 'Last Name', 'phone', 'Session', 'timeslot_start', 'timeslot_end', 'room_name', 'publisher']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, very last thing: we need to add in a row for the Book fair for everyone Friday, and add in lunch for everyone on saturday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-60>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<positron-console-cell-60>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<positron-console-cell-60>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<positron-console-cell-60>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<positron-console-cell-60>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "bookfair = all_friday_inperson.drop_duplicates(subset='Email', keep='first')\n",
    "bookfair['Session'] = 'Book fair'\n",
    "bookfair['room_name'] = 'Peachtree City'\n",
    "bookfair['timeslot_start'] = pd.to_datetime(date_str_fri + ' 11:00')\n",
    "bookfair['timeslot_end'] = pd.to_datetime(date_str_fri + ' 16:00')\n",
    "bookfair['publisher'] = 'published authors from the Atlanta Writers Club. Swing by to chat with them about their writing journey, hear more about their books, and buy signed copies.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-61>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<positron-console-cell-61>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<positron-console-cell-61>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<positron-console-cell-61>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<positron-console-cell-61>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "lunch = all_saturday_inperson.drop_duplicates(subset='Email', keep='first')\n",
    "lunch['Session'] = \"Lead sponsor presentation/Free time\"\n",
    "lunch['timeslot_start'] = pd.to_datetime(date_str_sat + ' 13:00')\n",
    "lunch['timeslot_end'] = pd.to_datetime(date_str_sat + ' 14:00')\n",
    "lunch['room_name'] = 'College Park Ballroom'\n",
    "lunch['publisher'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Add these back in\n",
    "all_friday_inperson2 = pd.merge(all_friday_inperson, bookfair, how=\"outer\")\n",
    "all_saturday_inperson2 = pd.merge(all_saturday_inperson, lunch, how=\"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! And now last step is to sort by person (aka email) and timeslot_start, so that everyone's rows are already ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "all_friday_inperson2= all_friday_inperson2.sort_values(['Email', 'timeslot_start'])\n",
    "all_saturday_inperson2= all_saturday_inperson2.sort_values(['Email', 'timeslot_start'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, and now last thing: we need to separate out the waitlist information by Friday vs Saturday, and ideally, sort by their waitlist ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "wait_all['Waitlist_Number'] = wait_all['Agenda Item Name'].str.extract(r'Waitlist #(\\d+)').astype(int)\n",
    "wait_fri = wait_all.loc[wait_all['Agenda Item Name'].str.contains('Query|Coach')].sort_values(['Email', 'Waitlist_Number'])\n",
    "wait_sat = wait_all.loc[wait_all['Agenda Item Name'].str.contains('Pitch|Manuscript')].sort_values(['Email', 'Waitlist_Number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print out the in-person schedules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I initially made it a bulleted list. However, that didn't format very nicely, so I tried a table code instead, which I think looks nicer. Below is for friday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Define the phone note:\n",
    "def phone_note(phone):\n",
    "    return f\"We have your phone number listed as {phone}. If this is not your number, please tell a check-in table volunteer so we can update it, as send automated text reminders in advance of any meetings. **The text will show a 678 area code.**\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Friday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from docx.shared import Cm\n",
    "from docx.oxml.ns import qn\n",
    "from docx.oxml import OxmlElement\n",
    "from docx.shared import Pt, RGBColor, Inches\n",
    "from docx.enum.style import WD_STYLE_TYPE\n",
    "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
    "\n",
    "def create_word_doc_with_table(participant_df, waitlist_df):\n",
    "    # Create a single Word document for all participants\n",
    "    doc = Document()\n",
    "\n",
    "    # Set default styles for the document\n",
    "    styles = doc.styles\n",
    "\n",
    "    # Modify the Normal style for non-header text\n",
    "    normal_style = styles['Normal']\n",
    "    normal_style.font.name = 'Arial'\n",
    "    normal_style.font.size = Pt(12)\n",
    "\n",
    "    # Modify the default style for tables\n",
    "    table_style = styles.add_style('CustomTable', WD_STYLE_TYPE.TABLE)\n",
    "    table_style.font.name = 'Arial'\n",
    "    table_style.font.size = Pt(12)\n",
    "\n",
    "    # Merge the waitlist data with the participant session data\n",
    "    merged_df = pd.merge(participant_df, waitlist_df[['Email', 'Agenda Item Name']], \n",
    "                         on='Email', how='left', indicator=True)\n",
    "\n",
    "    first_participant = True  # To track the first participant and skip initial page break\n",
    "    initial_page_breaks = len(doc.element.xpath('//w:br[@w:type=\"page\"]')) # create the initial page break amount\n",
    "\n",
    "    flag_friday = [] # We'll do this to identify anyone whose schedule is more than 1 page\n",
    "    friday_processed = []  # Creating this list so we can easiliy identify all participants who were output in the word doc\n",
    "\n",
    "    for _, participant in participant_df.drop_duplicates(subset=['Email']).iterrows():\n",
    "\n",
    "        # Add participant's email to the processed list\n",
    "        friday_processed.append(participant['Email'])\n",
    "\n",
    "        if not first_participant:\n",
    "            doc.add_page_break()  # Start new page for subsequent participants\n",
    "        first_participant = False\n",
    "\n",
    "        # Add header with the participant's name\n",
    "        header = doc.add_heading(f\"{participant['First Name']} {participant['Last Name']}\", level=1)\n",
    "        header.alignment = 1  # Center alignment\n",
    "        for run in header.runs:\n",
    "            run.font.size = Pt(36)\n",
    "            run.font.name = 'Arial'\n",
    "            run.font.color.rgb = RGBColor(0, 0, 0)  # Set header to black\n",
    "\n",
    "        doc.add_paragraph(\"\") # Add paragraph break to get more space\n",
    "\n",
    "        # Add session section header\n",
    "        session_header = doc.add_heading(\"Your schedule for Friday, May 2nd:\", level=2)\n",
    "        for run in session_header.runs:\n",
    "            run.font.color.rgb = RGBColor(0, 0, 0)  # Set session header to black\n",
    "            run.font.name = 'Arial'\n",
    "            run.font.size = Pt(14)\n",
    "        session_header.alignment = 1 # center alignment\n",
    "\n",
    "        # Add paragraph break after session_header\n",
    "        small_break = doc.add_paragraph(\"\")\n",
    "\n",
    "        # Create a table for the schedule\n",
    "        table = doc.add_table(rows=0, cols=2)\n",
    "        table.autofit = False\n",
    "\n",
    "        # Set column widths manually\n",
    "        times_column_width = Inches(1.75) \n",
    "        details_column_width = Inches(5) \n",
    "\n",
    "        # Add rows to the table\n",
    "        include_phone_note = False\n",
    "\n",
    "        # Note that in the below, the merged_df has duplicated rows for any participants with waitlist spots (because we cross-merged). Let's delete those duplicate rows for this part\n",
    "        for _, session in merged_df[merged_df['Email'] == participant['Email']].drop_duplicates(subset=['Session', 'room_name', 'Email', 'publisher', 'timeslot_start', 'timeslot_end']).iterrows():\n",
    "\n",
    "            timeslot = f\"{session['timeslot_start'].strftime('%I:%M %p')} - {session['timeslot_end'].strftime('%I:%M %p')}\"\n",
    "            if session['publisher']:  # Check if the publisher exists and is not empty\n",
    "                details = f\"{session['Session']} in {session['room_name']} with {session['publisher']}\"\n",
    "            else:\n",
    "                details = f\"{session['Session']} in {session['room_name']}\"\n",
    "\n",
    "            row = table.add_row()\n",
    "            row.cells[0].text = timeslot\n",
    "            row.cells[1].text = details\n",
    "\n",
    "            # Apply widths to each added row as well\n",
    "            row.cells[0].width = times_column_width\n",
    "            row.cells[1].width = details_column_width \n",
    "\n",
    "            # Check if the session includes \"Query\" or \"Coaching\"\n",
    "            if 'Query' in session['Session'] or 'Coaching' in session['Session']:\n",
    "                include_phone_note = True\n",
    "\n",
    "        # Add waitlist information if applicable\n",
    "        waitlist_sessions = merged_df[(merged_df['Email'] == participant['Email']) & (merged_df['_merge'] == 'both')].drop_duplicates(subset=['Agenda Item Name', 'Email'])\n",
    "        if not waitlist_sessions.empty:\n",
    "            waitlist_header = doc.add_paragraph(\"You're currently waitlisted for:\", style='Heading 3')\n",
    "            for run in waitlist_header.runs:\n",
    "                run.font.color.rgb = RGBColor(0, 0, 0)  # Set waitlist header to black\n",
    "                run.font.name = 'Arial'\n",
    "                run.font.size = Pt(14)\n",
    "\n",
    "            for _, waitlist in waitlist_sessions.iterrows():\n",
    "                waitlist_info = f\"- {waitlist['Agenda Item Name']}\"\n",
    "                paragraph = doc.add_paragraph(waitlist_info, style='List Bullet')\n",
    "                paragraph.paragraph_format.left_indent = Cm(2)  # Indent this a little bit\n",
    "\n",
    "        # Add phone note and footer text if applicable\n",
    "        if include_phone_note:\n",
    "            note = doc.add_heading(\"Important note about your meeting(s):\", level=2)\n",
    "            for run in note.runs:\n",
    "                run.font.color.rgb = RGBColor(0, 0, 0)  # Set phone note header to black\n",
    "                run.font.name = 'Arial'\n",
    "                run.font.size = Pt(14)\n",
    "\n",
    "            doc.add_paragraph(phone_note(participant['phone']), style='Normal')\n",
    "\n",
    "            # Add italicized footer text\n",
    "            footer_text = doc.add_paragraph(\n",
    "                \"Please arrive 15 minutes early for any query letter critiques or coaching sessions.\"\n",
    "            )\n",
    "            footer_text.runs[0].italic = True  # Make the text italicized\n",
    "\n",
    "        # Track the final page break count\n",
    "        final_page_breaks = len(doc.element.xpath('//w:br[@w:type=\"page\"]'))\n",
    "\n",
    "        # If two or more page breaks were added during this participant's content, flag them\n",
    "        if (final_page_breaks - initial_page_breaks) >= 2:\n",
    "            flag_friday.append(f\"{participant['First Name']} {participant['Last Name']}\")\n",
    "\n",
    "    # Adjust document margins to fit all content on one page\n",
    "    section = doc.sections[0]\n",
    "    section.top_margin = Inches(0.5)\n",
    "    section.bottom_margin = Inches(0.5)\n",
    "    section.left_margin = Inches(0.75)\n",
    "    section.right_margin = Inches(0.75)\n",
    "\n",
    "    # Save the document\n",
    "    doc.save(\"Outputs/Print-outs/Friday_In-person_participant_schedules.docx\")\n",
    "\n",
    "    friday_processed = pd.DataFrame(friday_processed, columns=[\"Email\"])\n",
    "    return(friday_processed)\n",
    "\n",
    "    # Let's also print out participants whose content went over a page\n",
    "    if flag_friday:\n",
    "        print(\"The following participants have schedules exceeding one page:\")\n",
    "        for name in flag_friday:\n",
    "            print(name)\n",
    "\n",
    "# Create the Word doc for each participant in the dataset\n",
    "processed_friday = create_word_doc_with_table(all_friday_inperson2, wait_fri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that we processed all the peopel we should have\n",
    "len(all_friday_inperson2.drop_duplicates(subset='Email', keep='first')) == len(processed_friday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! It processed everybody it should've :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saturday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now for **Saturday!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def create_word_doc_saturday(participant_df, waitlist_df):\n",
    "    # Create a single Word document for all participants\n",
    "    doc = Document()\n",
    "\n",
    "    # Set default styles for the document\n",
    "    styles = doc.styles\n",
    "\n",
    "    # Modify the Normal style for non-header text\n",
    "    normal_style = styles['Normal']\n",
    "    normal_style.font.name = 'Arial'\n",
    "    normal_style.font.size = Pt(12)\n",
    "\n",
    "    # Modify the default style for tables\n",
    "    table_style = styles.add_style('CustomTable', WD_STYLE_TYPE.TABLE)\n",
    "    table_style.font.name = 'Arial'\n",
    "    table_style.font.size = Pt(12)\n",
    "\n",
    "    # Merge the waitlist data with the participant session data\n",
    "    merged_df = pd.merge(participant_df, waitlist_df[['Email', 'Agenda Item Name']], \n",
    "                         on='Email', how='left', indicator=True)\n",
    "\n",
    "    first_participant = True  # To track the first participant and skip initial page break\n",
    "\n",
    "    flag_saturday = [] # We'll do this to identify anyone whose schedule is more than 1 page\n",
    "    initial_page_breaks = len(doc.element.xpath('//w:br[@w:type=\"page\"]')) # create the initial page break amount\n",
    "    saturday_processed = []  # Creating this list so we can easiliy identify all participants who were output in the word doc\n",
    "\n",
    "    # Add a  header for everyone\n",
    "    for section in doc.sections:\n",
    "        header = section.header\n",
    "        paragraph = header.paragraphs[0] if header.paragraphs else header.add_paragraph()\n",
    "        paragraph.text = \"Schedule for Saturday, May 3rd\"\n",
    "        paragraph.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER  # Center-align the header text\n",
    "\n",
    "        # Set the font and size for the header\n",
    "        run = paragraph.runs[0]\n",
    "        run.font.name = 'Arial'\n",
    "        run.font.size = Pt(10)\n",
    "\n",
    "    for _, participant in participant_df.drop_duplicates(subset=['Email']).iterrows():\n",
    "\n",
    "        # Add participant's email to the processed list\n",
    "        saturday_processed.append(participant['Email'])\n",
    "\n",
    "        if not first_participant:\n",
    "            doc.add_page_break()  # Start new page for subsequent participants\n",
    "        first_participant = False\n",
    "\n",
    "        # Add header with the participant's name\n",
    "        header = doc.add_heading(f\"{participant['First Name']} {participant['Last Name']}\", level=1)\n",
    "        header.alignment = 1  # Center alignment\n",
    "        for run in header.runs:\n",
    "            run.font.size = Pt(28)\n",
    "            run.font.name = 'Arial'\n",
    "            run.font.color.rgb = RGBColor(0, 0, 0)  # Set header to black\n",
    "\n",
    "        doc.add_paragraph(\"\") # Add paragraph break to get more space\n",
    "\n",
    "        # Add session section header\n",
    "        #session_header = doc.add_heading(\"Your schedule for Saturday, May 3rd:\", level=2)\n",
    "        #for run in session_header.runs:\n",
    "        #    run.font.color.rgb = RGBColor(0, 0, 0)  # Set session header to black\n",
    "        #    run.font.name = 'Arial'\n",
    "        #    run.font.size = Pt(14)\n",
    "        #session_header.alignment = 1 # center alignment\n",
    "\n",
    "        # Add paragraph break after session_header\n",
    "        #doc.add_paragraph(\"\") # can't do this for Saturday because there's too much text\n",
    "\n",
    "        # Create a table for the schedule\n",
    "        table = doc.add_table(rows=0, cols=2)\n",
    "        table.autofit = False\n",
    "\n",
    "        # Set column widths manually\n",
    "        times_column_width = Inches(1.75) \n",
    "        details_column_width = Inches(5) \n",
    "\n",
    "        # Add rows to the table\n",
    "        include_phone_note = False\n",
    "        \n",
    "        # Note that in the below, the merged_df has duplicated rows for any participants with waitlist spots (because we cross-merged). Let's delete those duplicate rows for this part\n",
    "        for _, session in merged_df[merged_df['Email'] == participant['Email']].drop_duplicates(subset=['Session', 'room_name', 'Email', 'publisher', 'timeslot_start', 'timeslot_end']).iterrows():\n",
    "\n",
    "            timeslot = f\"{session['timeslot_start'].strftime('%I:%M %p')} - {session['timeslot_end'].strftime('%I:%M %p')}\"\n",
    "            if session['publisher']:  # Check if the publisher exists and is not empty\n",
    "                details = f\"{session['Session']} in {session['room_name']} with {session['publisher']}\"\n",
    "            else:\n",
    "                details = f\"{session['Session']} in {session['room_name']}\"\n",
    "\n",
    "            row = table.add_row()\n",
    "            row.cells[0].text = timeslot\n",
    "            row.cells[1].text = details\n",
    "\n",
    "            # Apply widths to each added row as well\n",
    "            row.cells[0].width = times_column_width\n",
    "            row.cells[1].width = details_column_width \n",
    "\n",
    "            # Check if the session includes \"Query\" or \"Coaching\"\n",
    "            if 'Pitch' in session['Session'] or 'Manuscript' in session['Session']:\n",
    "                include_phone_note = True\n",
    "\n",
    "        # Add waitlist information if applicable\n",
    "        waitlist_sessions = merged_df[(merged_df['Email'] == participant['Email']) & (merged_df['_merge'] == 'both')].drop_duplicates(subset=['Agenda Item Name', 'Email'])\n",
    "        if not waitlist_sessions.empty:\n",
    "            waitlist_header = doc.add_paragraph(\"You're currently waitlisted for:\", style='Heading 3')\n",
    "            for run in waitlist_header.runs:\n",
    "                run.font.color.rgb = RGBColor(0, 0, 0)  # Set waitlist header to black\n",
    "                run.font.name = 'Arial'\n",
    "                run.font.size = Pt(14)\n",
    "\n",
    "            for _, waitlist in waitlist_sessions.iterrows():\n",
    "                waitlist_info = f\"{waitlist['Agenda Item Name']}\"\n",
    "                paragraph = doc.add_paragraph(waitlist_info, style='List Bullet')\n",
    "                paragraph.paragraph_format.left_indent = Cm(2)  # Indent this a little bit\n",
    "\n",
    "\n",
    "        # Add phone note and footer text if applicable\n",
    "        if include_phone_note:\n",
    "            note = doc.add_heading(\"Important note about your meeting(s) today:\", level=2)\n",
    "            for run in note.runs:\n",
    "                run.font.color.rgb = RGBColor(0, 0, 0)  # Set phone note header to black\n",
    "                run.font.name = 'Arial'\n",
    "                run.font.size = Pt(14)\n",
    "\n",
    "            doc.add_paragraph(phone_note(participant['phone']), style='Normal')\n",
    "\n",
    "            # Add italicized footer text\n",
    "            footer_text = doc.add_paragraph(\n",
    "                \"Please arrive 15 minutes early for any manuscript critiques or pitches.\"\n",
    "            )\n",
    "            footer_text.runs[0].italic = True  # Make the text italicized\n",
    "\n",
    "        # Track the final page break count\n",
    "        final_page_breaks = len(doc.element.xpath('//w:br[@w:type=\"page\"]'))\n",
    "\n",
    "        # If two or more page breaks were added during this participant's content, flag them\n",
    "        if (final_page_breaks - initial_page_breaks) >= 2:\n",
    "            flag_saturday.append(f\"{participant['First Name']} {participant['Last Name']}\")\n",
    "\n",
    "\n",
    "    # Adjust document margins to fit all content on one page\n",
    "    section = doc.sections[0]\n",
    "    section.top_margin = Inches(0.5)\n",
    "    section.bottom_margin = Inches(0.5)\n",
    "    section.left_margin = Inches(0.75)\n",
    "    section.right_margin = Inches(0.75)\n",
    "\n",
    "    # Save the document\n",
    "    doc.save(\"Outputs/Print-outs/Saturday_In-person_participant_schedules.docx\")\n",
    "\n",
    "    saturday_processed = pd.DataFrame(saturday_processed, columns=[\"Email\"])\n",
    "    return(saturday_processed)\n",
    "\n",
    "    # Let's also print out participants whose content went over a page\n",
    "    if flag_saturday:\n",
    "        print(\"The following participants have schedules exceeding one page:\")\n",
    "        for name in flag_saturday:\n",
    "            print(name)\n",
    "\n",
    "# Create the Word doc for each participant in the dataset\n",
    "processed_saturday = create_word_doc_saturday(all_saturday_inperson2, wait_sat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's again double check that everyone was output who was supposed to be output:\n",
    "len(all_saturday_inperson2.drop_duplicates(subset='Email', keep='first')) == len(processed_saturday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, yay because nobody had more than 1 page!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "del(break_data, break_time, cell, context, doc, header_cells, location, output_dir, output_path, pairing, pairings_doc, paragraph, room, row_cells, run, section,\n",
    "    sections, table, tbl, tbl_borders, template_path, title, correct_row, create_word_doc, create_word_doc_for_day, create_word_doc_saturday, create_word_doc_with_table,\n",
    "    Document, format_timeslot, generate_sat_schedule, generate_schedule, OxmlElement,  phone_note, qn, Cm, DocxTemplate, Inches, Pt, RGBColor, WD_PARAGRAPH_ALIGNMENT, \n",
    "    WD_STYLE_TYPE, break_after, break_df, break_morn, bookfair, corrected_data, lunch, sat_after2, sat_morn2, sat_talks, row,\n",
    "    room_data, all_friday_inperson, all_saturday_inperson, fri_talks, friday_prints2, final_saturday_rooms, final_room_pairings_Friday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waitlist Schedules - TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll create the waitlist printouts that go on the walls. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TablesReady Export\n",
    "\n",
    "We need to create a very specific csv file to import into TablesReady. It needs to have the following:\n",
    "\n",
    "* Date --> ex 10/1/2024\n",
    "* Time --> 6:30pm (no spaces!)\n",
    "* Name --> do first and last name\n",
    "* Size --> set this to 1 for everyone\n",
    "* Phone --> 10-digit code\n",
    "* Notes --> not necessarily needed, but will put the session tag that needs the reminder\n",
    "\n",
    "NOTE: We only send automated text reminders for the QLC, author coaching, manuscript critiques and pitches. This csv file should be restricted to those participants. We will also send it to both virtual and in-person people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "both_days = pd.merge(all_friday_inperson2, all_saturday_inperson2, how=\"outer\")\n",
    "\n",
    "# Keep only the rows with the 4 activities, and keep only certain columns\n",
    "both_days = both_days.loc[both_days['Session'].str.contains('Pitch|Critique|Coach|Manuscript'), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "both_days['Name'] = both_days['First Name'] + \" \" + both_days['Last Name']\n",
    "both_days['Size'] = 1\n",
    "both_days['Notes'] = both_days['Session'] + \" with \" + both_days['publisher']\n",
    "both_days['Time'] = both_days['timeslot_start'].dt.strftime('%I:%M%p').str.lower()\n",
    "both_days['Date'] = both_days['timeslot_start'].dt.strftime(\"%m/%d/%Y\")\n",
    "both_days['Phone'] = both_days['phone']\n",
    "\n",
    "both_days = both_days[['Date', 'Time', 'Name', 'Size', 'Phone', 'Notes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date     False\n",
      "Time     False\n",
      "Name     False\n",
      "Size     False\n",
      "Phone     True\n",
      "Notes    False\n",
      "dtype: bool\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Filter out anyone with missing phones (if applicable)\n",
    "print(both_days.isnull().any()) #checks column-wise\n",
    "print(both_days.isnull().values.any()) #checks entire DataFrame\n",
    "\n",
    "both_days = both_days.dropna() # Drops 5 people\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Now print to a csv for upload\n",
    "today = datetime.date.today().strftime('%Y-%m-%d') # Let's save today's date for when writing excel files\n",
    "both_days.to_csv(f\"Outputs/For Mail Merge/TablesReady_import_csv_{today}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Nametags\n",
    "\n",
    "We need to create nametags for everyone! For this, we need to create the full list of people from the roster (including waitlist only), and simply print people's first and last names onto the page. We also want to put a little black dot at the bottom of everyone's nametags if they signed up for the Friday workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Create a nametags dataset that includes everyone who might be in person -  both waitlist-only and any registered people.\n",
    "nametags = pd.merge(wait_all.loc[~wait_all['Email'].isin(virtual_only['Email']), ['First Name', 'Last Name', 'Email']], pd.merge(all_friday_inperson2, all_saturday_inperson2, how=\"outer\"), how=\"outer\").drop_duplicates(subset='Email', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Identify everyone who is in the Friday workshop so we can add a black dot\n",
    "nametags['workshop'] = nametags['Email'].isin(fri_workshop['Email'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Create a single 'Name' field, and only keep that and the workshop thing\n",
    "nametags['Name'] = nametags['First Name'] + \" \" + nametags['Last Name']\n",
    "nametags =  nametags[['First Name', 'Last Name', 'workshop']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# We're gonna just print this out for George... Couldn't manage to get it to work for whatever reason\n",
    "nametags.to_excel('Outputs/Rosters/Name tags for mail merge.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Change all workshop things from True False to * or missing\n",
    "nametags['flag'] = nametags['workshop'].apply(\n",
    "    lambda x:  \"*\" if x else \"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay,  I spent literally 7 hours on this... I could not figure out how to just print the name tags using a template, or just printing to a word doc, etc. It drove me  insane and I finally had to give up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MailerLite Exports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so this is one is funkier. I tried originally making a single variable that was a list of items, but no matter what I tried, MailerLite will not display this nicely, so the only option is to export individual variables for everything that we need. So in this step, we're going to one giant dataset, for both virtual and in person people, and even including waitlist-only people, with EVERY activity (waitlisted and already paid). We will *exclude* any of the general stuff, like check-in, or the Friday night social, or the free mini-seminars.\n",
    "\n",
    "These are the following \"Fields\" (aka variables) we will create for upload into MailerLite:\n",
    "\n",
    "*General variables to enable email segments*:\n",
    "- Virtual (True/False) --> We'll use this in MailerLite to create our different email segments\n",
    "- Friday_Activities (True/False) --> Participants have registered activities on Friday. This field will have values even for the virtual people, but will **NOT** have values for the waitlist people.\n",
    "- Saturday_Activities (True/False) --> Participants have registered activities on Saturday. This field will have values even for the virtual people, but will **NOT** have values for the waitlist people.\n",
    "- Waitlisted (True/False) --> Participants with any waitlisted items. We'll use this to create a segment (when combined with 'No' above for Friday and Saturday activities) to identify participants who haven't paid for anything and who are ONLY on the waitlist.\n",
    "\n",
    "*Variables to capture scheduling stuff*:\n",
    "\n",
    "The below will appear as \"1:00pm - Pitch with Wendy Wong in Board Room I\", or \"Waitlist #1 - Pitch with Wendy Wong\"\n",
    "- ms1, ms2, ms3 --> Participants can have up to 3 manuscript critiques\n",
    "- wait_ms1, wait_ms2, wait_ms3 --> Participants can have up to 3 MS waitlist spots\n",
    "- pitch1, pitch2, pitch3 \n",
    "- wait_pitch1, wait_pitch2, wait_pitch3\n",
    "- qlc1, qlc2 --> Participants can only sign up for two query letter critiques\n",
    "- wait_qlc1, wait_qlc2 --> They can also only have two waitlist spots for this\n",
    "- coach1, coach2 --> Participants can only sign up for two coaching spots\n",
    "- wait_coach1, wait_coach2\n",
    "- workshop\n",
    "- QApanel_agent, QApanel_editor\n",
    "- bookfair (sellers)\n",
    "- Friday_mixer\n",
    "- Friday_minis (miniseminars) - True/False\n",
    "- Saturday_minis (miniseminars) - True/False\n",
    "\n",
    "This results in a total of 27 variables, plus we need to keep email, first and last name, and phone number. (The latter three just for posterity's sake - we likely won't import those fields into MailerLite).\n",
    "\n",
    "Once we have this massive datastep, the next step will be to import it into MailerLite by clicking 'Add Subscribers' and 'import using csv'. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Start with the dataset with ALL participants\n",
    "all_conf_unique_participants = all_participants.drop_duplicates(subset='Email', keep='first')\n",
    "all_conf_unique_participants = all_conf_unique_participants[['Email', 'First Name', 'Last Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "all_friday['timeslot'] = all_friday['timeslot_start'].dt.strftime('%I:%M %p') + \" - \" + all_friday['timeslot_end'].dt.strftime('%I:%M %p')\n",
    "all_friday['details'] = all_friday.apply(lambda session: f\"{session['Session']} in {session['room_name']} with {session['publisher']}\" if session['publisher'] else f\"{session['Session']} in {session['room_name']}\", axis=1)\n",
    "all_friday['output'] = all_friday['timeslot'] + \": \" + all_friday['details']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "all_conf_unique_participants = all_conf_unique_participants.merge(all_friday.loc[all_friday['Session'] == 'Workshop, \"Writer Beware: How Writers Can Protect Themselves\"', ['Email', 'output']], how='left').rename(columns={'output':'workshop'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Awesome, now we need to add each of these variables by session type into the dataset\n",
    "all_conf_unique_participants = all_conf_unique_participants.merge(all_friday.loc[all_friday['Session'] == \"Selling your book(s) at the Book Fair\", ['Email', 'Session', 'output']], how='left').rename(columns={'output': 'bookfair'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Add in the different flag variables\n",
    "\n",
    "    # Virtual flag\n",
    "all_conf_unique_participants['virtual'] = all_conf_unique_participants['Email'].isin(virtual_only['Email'])\n",
    "\n",
    "    # If have any Friday activities (regardless if virtual or not -  but NOT set if they're waitlist only)\n",
    "all_conf_unique_participants['friday_activities'] = all_conf_unique_participants['Email'].isin(coaching_schedule['Email']) | all_conf_unique_participants['Email'].isin(final_friday_assignments2['Email']) | all_conf_unique_participants['bookfair'] | all_conf_unique_participants['Email'].isin(fri_workshop['Email']) | all_conf_unique_participants['Email'].isin(reg_fri_minis['Email'])\n",
    "\n",
    "    # If have any saturday activities (regardless of if virtual or not - but NOT set if they're waitlist only)\n",
    "all_conf_unique_participants['saturday_activities'] = all_conf_unique_participants['Email'].isin(final_satmorn_assignments2['Email']) | all_conf_unique_participants['Email'].isin(final_sataft_assignments2['Email']) | all_conf_unique_participants['Email'].isin(reg_sat_minis['Email'])\n",
    "\n",
    "    # Identify anyone with waitlist items\n",
    "all_conf_unique_participants['waitlisted'] = all_conf_unique_participants['Email'].isin(wait_all['Email'])\n",
    "\n",
    "    # Identify anyone with registered activities\n",
    "all_conf_unique_participants['registered'] = all_conf_unique_participants['Email'].isin(registered['Email'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "friday_activities  registered\n",
      "True               True          171\n",
      "Name: count, dtype: int64\n",
      "saturday_activities  registered\n",
      "True                 True          171\n",
      "Name: count, dtype: int64\n",
      "saturday_activities\n",
      "True    171\n",
      "Name: count, dtype: int64\n",
      "saturday_activities  friday_activities\n",
      "True                 True                 171\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Double check the friday and saturday stuff with registered\n",
    "print(all_conf_unique_participants[['friday_activities', 'registered']].value_counts())\n",
    "print(all_conf_unique_participants[['saturday_activities', 'registered']].value_counts())\n",
    "print(all_conf_unique_participants['saturday_activities'].value_counts())\n",
    "print(all_conf_unique_participants[['saturday_activities', 'friday_activities']].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Okay let's just double check this more precisely:\n",
    "any_friday_activities = registered.loc[registered['Agenda Item Name'].str.contains('Query|Coaching|Friday|Fair'), ['Email', 'phone']].drop_duplicates()\n",
    "any_saturday_activities = registered.loc[registered['Agenda Item Name'].str.contains('Pitch|Manuscript|Saturday'), ['Email', 'phone']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Okay cool cool - indeed, everyone who registered for Friday is also registered for Saturday.\n",
    "del(any_friday_activities, any_saturday_activities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Repeat for the publisher Q&A Panel\n",
    "all_conf_unique_participants = all_conf_unique_participants.merge(all_friday.loc[all_friday['Session'] == 'Publisher Q&A panel', ['Email', 'output']], how='left').rename(columns={'output':'QApanel_editor'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Repeat for the Friday night mixer\n",
    "all_conf_unique_participants = all_conf_unique_participants.merge(all_friday.loc[all_friday['Session'] == 'Friday Night Mixer', ['Email', 'output']], how='left').rename(columns={'output':'Friday_mixer'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session\n",
      "Mini-seminar                                                     344\n",
      "Friday Night Mixer                                               172\n",
      "Query Letter Critiques                                            65\n",
      "Publisher Q&A panel                                               60\n",
      "Workshop, \"Writer Beware: How Writers Can Protect Themselves\"     43\n",
      "Selling your book(s) at the Book Fair                             10\n",
      "Author Coaching with Jessica Handler                               7\n",
      "Author Coaching with Mickey Dubrow                                 4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(all_friday['Session'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Okay, we'll ignore the mini seminars (we'll automatically include those in the templates based on certain criteria). But now let's deal with the query critiques. People can have up to 2 of them\n",
    "all_conf_unique_participants = all_conf_unique_participants.merge(all_friday.loc[all_friday['Session'] == 'Query Letter Critiques', ['Email', 'output']].drop_duplicates(subset='Email', keep='first'), how='left').rename(columns={'output':'qlc1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "all_conf_unique_participants = all_conf_unique_participants.merge(all_friday.loc[all_friday['Session'] == 'Query Letter Critiques', ['Email', 'output']].drop_duplicates(subset='Email', keep='last'), how='left').rename(columns={'output':'qlc2'})\n",
    "# Now delete any qlc2 that equals qlc1\n",
    "all_conf_unique_participants.loc[all_conf_unique_participants['qlc2'] == all_conf_unique_participants['qlc1'], 'qlc2'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# We're gonna create a single a single flag for people with miniseminars\n",
    "all_conf_unique_participants['Friday_minis'] = all_conf_unique_participants['Email'].isin(reg_fri_minis['Email'])\n",
    "all_conf_unique_participants['Saturday_minis'] = all_conf_unique_participants['Email'].isin(reg_sat_minis['Email'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'> UNCOMMENT THIS CODE</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Let's do the waitlists for the query letters now:\n",
    "# **NOTE**: There are none\n",
    "#all_conf_unique_participants = all_conf_unique_participants.merge(wait_query['Email', 'output'].drop_duplicates(subset='Email', keep='first'), how='left').rename(columns={'output':'wl_qlc1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#all_conf_unique_participants = all_conf_unique_participants.merge(wait_query['Email', 'output'].drop_duplicates(subset='Email', keep='last'), how='left').rename(columns={'output':'wl_qlc2'})\n",
    "#all_conf_unique_participants.loc[all_conf_unique_participants['wl_qlc2'] == all_conf_unique_participants['wl_qlc1'], 'wl_qlc2'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Do the coaching waitlists now\n",
    "#all_conf_unique_participants = all_conf_unique_participants.merge(wait_coach['Email', 'output'].drop_duplicates(subset='Email', keep='first'), how='left').rename(columns={'output':'wl_coach1'})\n",
    "#all_conf_unique_participants = all_conf_unique_participants.merge(wait_coach['Email', 'output'].drop_duplicates(subset='Email', keep='last'), how='left').rename(columns={'output':'wl_coach2'})\n",
    "#all_conf_unique_participants.loc[all_conf_unique_participants['wl_coach2'] == all_conf_unique_participants['wl_coach1'], 'wl_coach2'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Create the coaching variables now\n",
    "all_conf_unique_participants = all_conf_unique_participants.merge(all_friday.loc[all_friday['Session'].str.contains('Coaching'), ['Email', 'output']].drop_duplicates(subset='Email', keep='first'), how='left').rename(columns={'output':'coach1'})\n",
    "all_conf_unique_participants = all_conf_unique_participants.merge(all_friday.loc[all_friday['Session'].str.contains('Coaching'), ['Email', 'output']].drop_duplicates(subset='Email', keep='last'), how='left').rename(columns={'output':'coach2'})\n",
    "all_conf_unique_participants.loc[all_conf_unique_participants['coach2'] == all_conf_unique_participants['coach1'], 'coach2'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's move on to adding in the saturday activities and info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "all_saturday['timeslot'] = all_saturday['timeslot_start'].dt.strftime('%I:%M %p') + \" - \" + all_saturday['timeslot_end'].dt.strftime('%I:%M %p')\n",
    "all_saturday['details'] = all_saturday.apply(lambda session: f\"{session['Session']} in {session['room_name']} with {session['publisher']}\" if session['publisher'] else f\"{session['Session']} in {session['room_name']}\", axis=1)\n",
    "all_saturday['output'] = all_saturday['timeslot'] + \": \" + all_saturday['details']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Code for the Agent Q&A\n",
    "all_conf_unique_participants = all_conf_unique_participants.merge(all_saturday.loc[all_saturday['Session'] == 'Agent Q&A panel', ['Email', 'output']], how='left').rename(columns={'output':'QApanel_agent'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "ms = all_saturday.loc[all_saturday['Session'] == 'Manuscript critique', ['Email', 'output']]\n",
    "\n",
    "# we need to pivot this table so we can get a dataset with one row per person and 3 variables\n",
    "ms['ms_index'] = ms.groupby('Email').cumcount() + 1  # This will create a 1, 2, 3 for each person\n",
    "\n",
    "# Pivot the data, creating separate columns for ms1, ms2, ms3\n",
    "pivoted_ms = ms.pivot_table(index='Email', columns='ms_index', values='output', aggfunc='first')\n",
    "\n",
    "# Rename columns to ms1, ms2, ms3\n",
    "pivoted_ms.columns = [f'ms{i}' for i in range(1, 4)]\n",
    "\n",
    "# Reset index to bring 'Email' as a column\n",
    "pivoted_ms = pivoted_ms.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Do the same for the pitches\n",
    "pitches = all_saturday.loc[all_saturday['Session'] == 'Pitch', ['Email', 'output']]\n",
    "\n",
    "# we need to pivot this table so we can get a dataset with one row per person and 3 variables\n",
    "pitches['pitch_index'] = pitches.groupby('Email').cumcount() + 1  # This will create a 1, 2, 3 for each person\n",
    "\n",
    "# Pivot the data, creating separate columns for ms1, ms2, ms3\n",
    "pivoted_pitch = pitches.pivot_table(index='Email', columns='pitch_index', values='output', aggfunc='first')\n",
    "\n",
    "# Rename columns to ms1, ms2, ms3\n",
    "pivoted_pitch.columns = [f'pitch{i}' for i in range(1, 4)]\n",
    "\n",
    "# Reset index to bring 'Email' as a column\n",
    "pivoted_pitch = pivoted_pitch.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-443>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Do the same for the waitlisted pitches\n",
    "wait_pitch = wait_all.loc[wait_all['Agenda Item Name'].str.contains('Pitch')]\n",
    "wait_pitch['pitch_index'] = wait_pitch.groupby('Email').cumcount() + 1  # This will create a 1, 2, 3 for each person\n",
    "\n",
    "# Pivot the data, creating separate columns for ms1, ms2, ms3\n",
    "pivoted_wait_pitch = wait_pitch.pivot_table(index='Email', columns='pitch_index', values='Agenda Item Name', aggfunc='first')\n",
    "\n",
    "# Rename columns to ms1, ms2, ms3\n",
    "pivoted_wait_pitch.columns = [f'pitch{i}' for i in range(1, 4)]\n",
    "\n",
    "# Reset index to bring 'Email' as a column\n",
    "pivoted_wait_pitch = pivoted_wait_pitch.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-444>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Do the same for the waitlisted manuscripts\n",
    "wait_ms = wait_all.loc[wait_all['Agenda Item Name'].str.contains('Manuscript')]\n",
    "wait_ms['ms_index'] = wait_ms.groupby('Email').cumcount() + 1  # This will create a 1, 2, 3 for each person\n",
    "\n",
    "# Pivot the data, creating separate columns for ms1, ms2, ms3\n",
    "pivoted_wait_ms = wait_ms.pivot_table(index='Email', columns='ms_index', values='Agenda Item Name', aggfunc='first')\n",
    "\n",
    "# Rename columns to ms1, ms2, ms3\n",
    "pivoted_wait_ms.columns = [f'ms{i}' for i in range(1, 4)]\n",
    "\n",
    "# Reset index to bring 'Email' as a column\n",
    "pivoted_wait_ms = pivoted_wait_ms.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Now let's add all of these into the dataset\n",
    "all_conf_unique_participants = all_conf_unique_participants.merge(pivoted_ms, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "all_conf_unique_participants = all_conf_unique_participants.merge(pivoted_pitch, how='outer')\n",
    "all_conf_unique_participants = all_conf_unique_participants.merge(pivoted_wait_ms.rename(columns={'ms1':'wl_ms1', 'ms2':'wl_ms2', 'ms3':'wl_ms3'}), how='outer')\n",
    "all_conf_unique_participants = all_conf_unique_participants.merge(pivoted_wait_pitch.rename(columns={'pitch1':'wl_pitch1', 'pitch2':'wl_pitch2', 'pitch3':'wl_pitch3'}), how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "## Will need to add in any bookfair waitlists - none yet\n",
    "\n",
    "#all_conf_unique_participants = all_conf_unique_participants.merge(wait_bookfair['Email', 'output'].drop_duplicates(subset='Email', keep='first'), how='left').rename(columns={'output':'wl_bookfair'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Very final thing: add in the phone\n",
    "all_conf_unique_participants = all_conf_unique_participants.merge(registered[['Email', 'phone']].drop_duplicates(), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# just in case there are waitlist only people who need phones brought in too, bring in that\n",
    "all_conf_unique_participants = all_conf_unique_participants.merge(wait_all[['Email', 'phone']].drop_duplicates(), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "timekeepers = pd.read_excel('List_of_genres_agents_editors.xlsx', sheet_name='timekeepers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Also need to add a few more true/false ones:\n",
    "all_conf_unique_participants['qlc_any'] = all_conf_unique_participants['Email'].isin(final_friday_assignments2['Email'])\n",
    "all_conf_unique_participants['ms_any'] = all_conf_unique_participants['Email'].isin(final_satmorn_assignments2['Email'])\n",
    "all_conf_unique_participants['pitch_any'] = all_conf_unique_participants['Email'].isin(final_sataft_assignments2['Email'])\n",
    "all_conf_unique_participants['timekeeper'] = all_conf_unique_participants['Email'].isin(timekeepers['Email'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Lastly, let's explicitly say which days of the conference they're attending\n",
    "all_conf_unique_participants['days_attending'] = all_conf_unique_participants.apply(\n",
    "    lambda row: 'Both' if row['friday_activities'] and row['saturday_activities']\n",
    "    else 'Friday' if row['friday_activities']\n",
    "    else 'Saturday' if row['saturday_activities']\n",
    "    else 'Waitlist only',\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_attending\n",
      "Both    171\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(all_conf_unique_participants['days_attending'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay!! We did it!! Now let's export this to a csv file, and then we're done and ready for upload into MailerLite!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "today = datetime.date.today().strftime('%Y-%m-%d') # Let's save today's date for when writing excel files\n",
    "all_conf_unique_participants.to_csv(f\"Outputs/For Mail Merge/MailerLite_update_all_custom_fields_{today}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on out, no more coding! Head out to MailerLite for the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zoom Roster\n",
    "\n",
    "Kim needs this to be able to see who should have zoom meetings when, so she can let them in from the breakrooms to their particular meetings. This only applies to virtual-only people receiving author coaching, QLC, manuscript critique, or pitch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "zoompeeps = pd.merge(all_friday.loc[all_friday['Session'].str.contains('Critique|Coach'), ['Email', 'First Name', 'Last Name', 'phone', 'virtual', 'timeslot_start', 'Session', 'publisher']], \n",
    "                    all_saturday.loc[all_saturday['Session'].str.contains('Critique|Pitch'), ['Email', 'First Name', 'Last Name', 'phone', 'virtual', 'timeslot_start', 'Session', 'publisher']], \n",
    "                    how=\"outer\")\n",
    "zoompeeps = zoompeeps.loc[zoompeeps['virtual']=='Virtual', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Order by timeslot (which is a date-time variable)\n",
    "zoompeeps = zoompeeps.sort_values(by=\"timeslot_start\")\n",
    "zoompeeps['Date'] = zoompeeps['timeslot_start'].dt.strftime(\"%m/%d/%Y\")\n",
    "zoompeeps['Time'] = zoompeeps['timeslot_start'].dt.strftime('%I:%M%p').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Print to excel file for Kim\n",
    "zoompeeps[['Email', 'First Name', 'Last Name', 'phone', 'Date', 'Time', 'Session', 'publisher']].to_excel(\"Outputs/Rosters/Roster of Zoom meetings for Kim.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conference Roster\n",
    "\n",
    "We want one ginormous excel file with a row for every single activity, alphabetically sorted by person, then date/time. A person will have as many rows as they have activities.\n",
    "\n",
    "* First and Last Name\n",
    "* Cell # (phone)\n",
    "* Locale (Hotel vs ZOOM)\n",
    "* Conference Activity ('output)\n",
    "\n",
    "Make sure to remove any duplicate rows (e.g., mini seminars stuff maybe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Add a virtual variable to the waitlist dataset\n",
    "wait_all['virtual'] = wait_all['Email'].apply(\n",
    "    lambda email: 'Virtual' if email in virtual_only['Email'] else 'In Person'\n",
    ")\n",
    "\n",
    "wait_all['Session'] = wait_all['Agenda Item Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "conf_roster = pd.merge(pd.merge(all_friday[['Email', 'First Name', 'Last Name', 'phone', 'virtual', 'Session', 'timeslot_start', 'publisher']], \n",
    "                        all_saturday[['Email', 'First Name', 'Last Name', 'phone', 'virtual', 'Session', 'timeslot_start', 'publisher']],\n",
    "                        how=\"outer\"), wait_all[['Email', 'First Name', 'Last Name', 'phone', 'virtual', 'Session']], how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Change some of the variables\n",
    "conf_roster['Locale'] = conf_roster['virtual'].apply(\n",
    "    lambda virt: 'ZOOM' if virt=='Virtual' else 'Hotel'\n",
    ")\n",
    "\n",
    "conf_roster['Cell #'] = conf_roster['phone']\n",
    "\n",
    "conf_roster['Time'] = conf_roster['timeslot_start'].dt.strftime('%I:%M%p').str.lower()\n",
    "\n",
    "conf_roster['pub'] = conf_roster.apply(\n",
    "    lambda row: row['publisher'] if isinstance(row['Session'], str) and \n",
    "    ('Pitch' in row['Session'] or 'Manuscript' in row['Session'] or 'Coach' in row['Session'] or 'Critique' in row['Session']) \n",
    "    else np.nan, axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def combine_variables(var1, var2, var3):\n",
    "    if pd.notna(var1) and pd.notna(var2) and pd.notna(var3):  # Check for NaN values\n",
    "        return f\"{var1} - {var2} @ {var3}\"\n",
    "    if pd.notna(var1) and pd.notna(var2) and pd.isna(var3) :  # Check for NaN values\n",
    "        return f\"{var1} - {var2}\"\n",
    "    return var1\n",
    "\n",
    "conf_roster['Conference Activity'] = conf_roster.apply(lambda row: combine_variables(row['Session'], row['pub'], row['Time']), axis=1)\n",
    "\n",
    "del combine_variables  # Delete function after use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Awesome! Now let's organize by person (last, then first) and the date/time of activity\n",
    "conf_roster = conf_roster.sort_values(by=['Last Name', 'First Name', 'timeslot_start'])\n",
    "conf_roster = conf_roster[['First Name', 'Last Name', 'Cell #',  'Locale' ,'Conference Activity']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted Excel file saved as Outputs/Rosters/Conference Roster - to print.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Let's format the excel file as we need it for printing\n",
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, PatternFill, Border, Side\n",
    "from openpyxl.worksheet.page import PageMargins\n",
    "from openpyxl.worksheet.worksheet import Worksheet\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "# Blank out 'First Name' and 'Last Name' except for the first occurrence of each person\n",
    "conf_roster.loc[conf_roster.duplicated(subset=['First Name', 'Last Name']), ['First Name', 'Last Name']] = ''\n",
    "\n",
    "# Create a new Excel writer using openpyxl\n",
    "output_filename = \"Outputs/Rosters/Conference Roster - to print.xlsx\"\n",
    "with pd.ExcelWriter(output_filename, engine='openpyxl') as writer:\n",
    "    conf_roster.to_excel(writer, index=False, sheet_name=\"Activities\")\n",
    "\n",
    "    # Load the workbook and worksheet\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets[\"Activities\"]\n",
    "\n",
    "    # Define styles\n",
    "    bold_font = Font(bold=True)\n",
    "    grey_font = Font(color=\"808080\")  # Dark grey color\n",
    "    thin_border = Border(left=Side(style=\"thin\", color=\"D3D3D3\"),\n",
    "                         right=Side(style=\"thin\", color=\"D3D3D3\"),\n",
    "                         top=Side(style=\"thin\", color=\"D3D3D3\"),\n",
    "                         bottom=Side(style=\"thin\", color=\"D3D3D3\"))\n",
    "\n",
    "    # Bold the headers\n",
    "    for cell in worksheet[1]:\n",
    "        cell.font = bold_font\n",
    "\n",
    "    # Bold 'First Name' and 'Last Name' and apply activity text color formatting\n",
    "    for row in worksheet.iter_rows(min_row=2, max_row=worksheet.max_row):\n",
    "        first_name_cell, last_name_cell, activity_cell = row[0], row[1], row[4]  # Adjust column indexes as needed\n",
    "        first_name_cell.font = bold_font\n",
    "        last_name_cell.font = bold_font\n",
    "\n",
    "        # Change activity text to grey if it doesn't contain specific words\n",
    "        if not any(word in str(activity_cell.value) for word in [\"Manuscript\", \"Pitch\", \"Critique\", \"Coach\"]):\n",
    "            activity_cell.font = grey_font\n",
    "\n",
    "        # Apply borders to all cells\n",
    "        for cell in row:\n",
    "            cell.border = thin_border\n",
    "\n",
    "    # Apply borders to header row\n",
    "    for cell in worksheet[1]:\n",
    "        cell.border = thin_border\n",
    "\n",
    "     # Auto-adjust column widths accurately\n",
    "    for col_idx, col_cells in enumerate(worksheet.columns, start=1):\n",
    "        max_length = max(len(str(cell.value)) if cell.value else 0 for cell in col_cells)\n",
    "        adjusted_width = max_length * 1.2  # Scale factor for better accuracy in Excel\n",
    "        worksheet.column_dimensions[get_column_letter(col_idx)].width = adjusted_width\n",
    "\n",
    "    # Set print settings for landscape mode\n",
    "    worksheet.page_setup.orientation = \"landscape\"\n",
    "    worksheet.page_setup.fitToWidth = 1  # Fit to page width\n",
    "    worksheet.page_margins = PageMargins(left=0.5, right=0.5, top=0.5, bottom=0.5)  # Set margins\n",
    "\n",
    "    # Save the workbook\n",
    "    workbook.save(output_filename)\n",
    "\n",
    "print(f\"Formatted Excel file saved as {output_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "plaintext"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
